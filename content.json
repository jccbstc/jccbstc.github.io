{"meta":{"title":"业余的日落患者","subtitle":"","description":"","author":"及川彻","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2022-11-27T12:56:47.586Z","updated":"2022-11-27T12:56:47.586Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-11-27T12:57:09.450Z","updated":"2022-11-27T12:57:09.450Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标题","date":"2022-11-28T07:05:15.343Z","updated":"2022-11-28T07:05:15.343Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis 常见数据类型和应用场景","slug":"Redis/Redis 常见数据类型和应用场景","date":"2023-04-03T11:36:32.932Z","updated":"2023-04-03T11:37:12.870Z","comments":true,"path":"2023/04/03/Redis/Redis 常见数据类型和应用场景/","link":"","permalink":"http://example.com/2023/04/03/Redis/Redis%20%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"Redis 常见数据类型和应用场景常见数据类型介绍与实现StringString 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。 SDS 不仅可以保存文本数据，还可以保存二进制数据。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。 **SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。 Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。 字符串对象的内部编码（encoding）有 3 种 ：int、raw和 embstr。 int raw embstr embstr和raw编码都会使用SDS来保存值，但不同之处在于embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS，而raw编码会通过调用两次内存分配函数来分别分配两块空间来保存redisObject和SDS。Redis这样做会有很多好处： embstr编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次； 释放 embstr编码的字符串对象同样只需要调用一次内存释放函数； 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。 但是 embstr 也有缺点的： 如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以embstr编码的字符串对象实际上是只读的，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令 ListList 类型的底层数据结构是由双向链表或压缩列表实现的： 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构； 如果列表的元素不满足上面的条件，Redis 会使用双向链表作为 List 类型的底层数据结构； 但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。 HashHash 类型的底层数据结构是由压缩列表或哈希表实现的： 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 SetSet 类型的底层数据结构是由哈希表或整数集合实现的： 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构； 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。 ZsetZset 类型的底层数据结构是由压缩列表或跳表实现的： 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构； 如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构； 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 BitMapBitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。 由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。 内部实现： Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。 String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。 HyperLogLogRedis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。 所以，简单来说 HyperLogLog 提供不精确的去重计数。 HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。 GEORedis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。 内部实现： GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。 StreamRedis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。 在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如： 发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷； List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。 基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。 Redis 数据类型的应用场景 String 类型的应用场景：缓存对象、常规计数、分布式锁、共享session信息等。 List 类型的应用场景：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。 Hash 类型：缓存对象、购物车等。 Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。 Zset 类型：排序场景，比如排行榜、电话和姓名排序等。 Redis 后续版本又支持四种数据类型，它们的应用场景如下： BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等； HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等； GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车； Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。 补充把 Redis 当作队列来使用时，会面临的 2 个问题 Redis 本身可能会丢数据； 面对消息挤压，内存资源会紧张； Redis 发布/订阅机制为什么不可以作为消息队列？ 发布/订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布/订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布/订阅机制的数据也会全部丢失。 发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。 当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 client-output-buffer-limit pubsub 32mb 8mb 60。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"丑数","slug":"算法/丑数","date":"2023-04-02T02:00:40.124Z","updated":"2023-04-02T02:02:11.694Z","comments":true,"path":"2023/04/02/算法/丑数/","link":"","permalink":"http://example.com/2023/04/02/%E7%AE%97%E6%B3%95/%E4%B8%91%E6%95%B0/","excerpt":"","text":"丑数263.丑数 264.丑数 II 263.丑数123456789101112class Solution { public boolean isUgly(int n) { if (n &lt; 1) return false; int[] cs = {2,3,5}; for (int i = 0; i &lt; cs.length; ++i) { while (n % cs[i] == 0) { n /= cs[i]; } } return n == 1; }} 264.丑数 II123456789101112131415class Solution { public int nthUglyNumber(int n) { int[] dp = new int[n]; dp[0] = 1; int a = 0,b = 0,c = 0; for (int i = 1; i &lt; n; ++i) { int n1 = 2 * dp[a],n2 = 3 * dp[b],n3 = 5 * dp[c]; dp[i] = Math.min(Math.min(n1,n2),n3); if (n1 == dp[i]) a++; if (n2 == dp[i]) b++; if (n3 == dp[i]) c++; } return dp[n-1]; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"字符串的反转和字符串中单词的反转","slug":"算法/字符串的反转和字符串中单词的反转","date":"2023-04-01T09:05:27.105Z","updated":"2023-04-01T09:10:04.296Z","comments":true,"path":"2023/04/01/算法/字符串的反转和字符串中单词的反转/","link":"","permalink":"http://example.com/2023/04/01/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%8F%8D%E8%BD%AC%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E5%8D%95%E8%AF%8D%E7%9A%84%E5%8F%8D%E8%BD%AC/","excerpt":"","text":"字符串的反转和字符串中单词的反转151.反转字符串中的单词 557.反转字符串中的单词 III 剑指 Offer 58 - II. 左旋转字符串 （左旋） 189.轮转数组（右旋） 541.反转字符串 II 剑指 Offer 05. 替换空格 345.反转字符串中的元音字母 796.旋转字符串 151.反转字符串中的单词不用API库123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Solution { public String reverseWords(String s) { StringBuilder sb = trimSpaces(s); // 翻转字符串 reverse(sb, 0, sb.length() - 1); // 翻转每个单词 reverseEachWord(sb); return sb.toString(); } public StringBuilder trimSpaces(String s) { int left = 0, right = s.length() - 1; // 去掉字符串开头的空白字符 while (left &lt;= right &amp;&amp; s.charAt(left) == ' ') { ++left; } // 去掉字符串末尾的空白字符 while (left &lt;= right &amp;&amp; s.charAt(right) == ' ') { --right; } // 将字符串间多余的空白字符去除 StringBuilder sb = new StringBuilder(); while (left &lt;= right) { char c = s.charAt(left); if (c != ' ') { sb.append(c); } else if (sb.charAt(sb.length() - 1) != ' ') { sb.append(c); } ++left; } return sb; } public void reverse(StringBuilder sb, int left, int right) { while (left &lt; right) { char tmp = sb.charAt(left); sb.setCharAt(left++, sb.charAt(right)); sb.setCharAt(right--, tmp); } } public void reverseEachWord(StringBuilder sb) { int n = sb.length(); int start = 0, end = 0; while (start &lt; n) { // 循环至单词的末尾 while (end &lt; n &amp;&amp; sb.charAt(end) != ' ') { ++end; } // 翻转单词 reverse(sb, start, end - 1); // 更新start，去找下一个单词 start = end + 1; ++end; } }} 用API库1234567class Solution { public String reverseWords(String s) { String[] words = s.trim().split(\" +\"); Collections.reverse(Arrays.asList(words)); return String.join(\" \", words); }} 557.反转字符串中的单词 III12345678910111213141516171819202122class Solution { public String reverseWords(String s) { char[] chars = s.toCharArray(); int i = 0; for (int j = 0; j &lt; chars.length; j++) { if (chars[j] == ' ') { reverse(chars, i, j - 1); i = j + 1; } } reverse(chars, i, chars.length - 1); return String.valueOf(chars); } private void reverse(char[] chars, int i, int j) { while (i &lt; j) { char temp = chars[i]; chars[i++] = chars[j]; chars[j--] = temp; } }} 剑指 Offer 58 - II. 左旋转字符串 （左旋）遍历拼接12345678910class Solution { public String reverseLeftWords(String s, int n) { StringBuilder res = new StringBuilder(); for(int i = n; i &lt; s.length(); i++) res.append(s.charAt(i)); for(int i = 0; i &lt; n; i++) res.append(s.charAt(i)); return res.toString(); }} 字符串切片12345class Solution { public String reverseLeftWords(String s, int n) { return s.substring(n,s.length()) + s.substring(0,n); }} 189.轮转数组（右旋）1234567891011121314151617class Solution { public void rotate(int[] nums, int k) { int length = nums.length; k %= length; reverse(nums, 0, length - 1);//先反转全部的元素 reverse(nums, 0, k - 1);//在反转前k个元素 reverse(nums, k, length - 1);//接着反转剩余的 } public void reverse(int[] nums, int start, int end) { while (start &lt; end) { int temp = nums[start]; nums[start++] = nums[end]; nums[end--] = temp; } }} 541.反转字符串 II12345678910111213141516171819class Solution { public String reverseStr(String s, int k) { char[] arr = s.toCharArray(); for(int i = 0;i &lt; s.length();i = k * 2 + i){ reverse(arr,i,Math.min(i + k,s.length()) - 1); } return new String(arr); } public void reverse(char[] arr,int left,int right){ while(left &lt; right){ char a = arr[left]; arr[left] = arr[right]; arr[right] = a; left ++; right --; } }} 剑指 Offer 05. 替换空格StringBuilder模仿数组1234567891011121314class Solution { public String replaceSpace(String s) { StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; s.length(); ++i) { char c = s.charAt(i); if (c != ' ') { sb.append(c); } else { sb.append(\"%20\"); } } return sb.toString(); }} 345.反转字符串中的元音字母双指针12345678910111213141516171819202122232425262728293031class Solution { public String reverseVowels(String s) { int n = s.length(); char[] arr = s.toCharArray(); int i = 0, j = n - 1; while (i &lt; j) { while (i &lt; n &amp;&amp; !isVowel(arr[i])) { ++i; } while (j &gt; 0 &amp;&amp; !isVowel(arr[j])) { --j; } if (i &lt; j) { swap(arr, i, j); ++i; --j; } } return new String(arr); } public boolean isVowel(char ch) { return \"aeiouAEIOU\".indexOf(ch) &gt;= 0; } public void swap(char[] arr, int i, int j) { char temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }} 796.旋转字符串12345class Solution { public boolean rotateString(String s, String goal) { return A.length() == B.length() &amp;&amp; (A + A).contains(B); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"StringTable","slug":"基础/StringTable","date":"2023-03-31T10:51:24.971Z","updated":"2023-03-31T10:52:56.523Z","comments":true,"path":"2023/03/31/基础/StringTable/","link":"","permalink":"http://example.com/2023/03/31/%E5%9F%BA%E7%A1%80/StringTable/","excerpt":"","text":"StringTableString的不可变性1String s = \"hello\"; 把s的值改一下，改成”world“ 值没改变，而是引用指向了一个新的字符串。 12String s = \"hello\";s = \"world\"; 字符串的拼接123String s1 = \"a\";String s2 = \"b\";String s3 = s1 + s2; new String() intern方法1234567intern方法的作用就是尝试将一个字符串放入StringTable中，如果不存在就放入StringTable并返回StringTable中的地址，如果存在的话就直接返回StringTable中的地址。这是jdk1.8版本中intern方法的作用，jdk1.6版本中有些不同，1.6中intern尝试将字符串对象放入StringTable，如果有则并不会放入，如果没有会把此对象复制一份，放入StringTable， 再把StringTable中的对象返回。不过我们在这里不讨论1.6版本。 在intern方法之前存在 1234567891011121314public class StringTable { public static void main(String[] args) { String s1 = \"a\"; String s2 = \"b\"; String s3 = s1 + s2; String s5 = \"ab\"; String s6 = s3.intern(); System.out.println(s5 == s3); // false System.out.println(s6 == s5); // true System.out.println(s6 == s3); // false }} 在intern方法之后存在 1234567891011121314public class StringTable { public static void main(String[] args) { String s1 = \"a\"; String s2 = \"b\"; String s3 = s1 + s2; String s6 = s3.intern(); String s5 = \"ab\"; System.out.println(s5 == s3); // true System.out.println(s6 == s5); // true System.out.println(s6 == s3); // true }}","categories":[{"name":"基础","slug":"基础","permalink":"http://example.com/categories/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"StringTable","slug":"StringTable","permalink":"http://example.com/tags/StringTable/"}]},{"title":"堆排序和快速排序","slug":"算法/堆排序和快速排序","date":"2023-03-30T13:43:32.666Z","updated":"2023-03-31T11:06:19.601Z","comments":true,"path":"2023/03/30/算法/堆排序和快速排序/","link":"","permalink":"http://example.com/2023/03/30/%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","excerpt":"","text":"堆排序和快速排序堆排序12345678910111213141516171819202122232425262728293031public static void sort(int[] arr) { for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { adjustHeap(arr, i, arr.length); } for (int j = arr.length - 1; j &gt; 0; j--) { swap(arr, 0, j); adjustHeap(arr, 0, j); } } public static void adjustHeap(int[] arr, int i, int length) { int temp = arr[i]; for (int k = i * 2 + 1; k &lt; length; k = k * 2 + 1) { if (k + 1 &lt; length &amp;&amp; arr[k] &lt; arr[k + 1]) { k++; } if (arr[k] &gt; temp) { arr[i] = arr[k]; i = k; } else { break; } } arr[i] = temp; } public static void swap(int[] arr, int a, int b) { int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; } 快速排序1234567891011121314151617181920212223public static void quickSort(int[] arr, int low, int high) { int i = low, j = high; int t = 0; if (i &gt; j) return; int temp = arr[low]; while (i &lt; j) { while (temp &lt;= arr[j] &amp;&amp; i &lt; j) { j--; } while (temp &gt;= arr[i] &amp;&amp; i &lt; j) { i++; } if (i &lt; j) { t = arr[j]; arr[j] = arr[i]; arr[i] = t; } arr[low] = arr[i]; arr[i] = temp; quickSort(arr, low, j - 1); quickSort(arr, j + 1, high); } }","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"百度校招Java研发工程师笔试卷","slug":"笔试/百度校招Java研发工程师笔试卷","date":"2023-03-30T07:48:54.986Z","updated":"2023-03-30T13:08:19.429Z","comments":true,"path":"2023/03/30/笔试/百度校招Java研发工程师笔试卷/","link":"","permalink":"http://example.com/2023/03/30/%E7%AC%94%E8%AF%95/%E7%99%BE%E5%BA%A6%E6%A0%A1%E6%8B%9BJava%E7%A0%94%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E5%8D%B7/","excerpt":"","text":"百度校招Java研发工程师笔试卷1.当请求过多，超出线程池负荷的时候，会触发拒绝策略。下列选项中，对于拒绝策略的描述错误的是：A. CallerRunsPolicy，线程调用运行该任务的 execute 本身，此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 B. AbortPolicy，处理程序遭到拒绝将直接抛出异常，丢弃任务。 C. DiscardPolicy，不能执行的任务将被删除。这种策略将丢弃任务，同时也会抛出异常。 D. DiscardOldestPolicy，如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序。 正确答案：C 12345线程池拒绝策略： （1） AbortPolicy 。丢弃任务，并抛出RejectedExecutionException异常，线程池默认拒绝策略； （2） DiscardPolicy。丢弃任务，不抛出异常； （3） DiscardOldesPolicy.丢弃队列最前面的任务，然后重新提交被拒绝的任务； （4） CallerRunPolicy。由调用的线程处理该任务，谁调用谁的线程处理。 2.下列关于AOP术语的描述中，错误的是：A. Joinpoint，是指目标对象上所定义的各个方法。 B. Pointcut，是用来定义当前的横切逻辑准备织入到哪些连接点上。 C. Advice，用来定义横切逻辑，即在连接点上准备织入什么样的逻辑。 D. Aspect，是一个用来封装切点和通知的组件。 正确答案：A 12345678910111213141. 连接点（Joinpoint）连接点描述的是程序执行的某个特定位置2. 切入点（Pointcut）切入点是一个连接点的过滤条件，AOP 通过切点定位到特定的连接点。3. 通知（Advice）切面在某个具体的连接点采取的行为或行动，称为通知。4. 通知器（Advisor）通知器由一个切入点（pointcut）和一个通知（Advice）组成。5. 切面（Aspect）与通知器（advisor）类似都是通知+切入点。6. 目标(Target)被通知的对象（方法）7. 代理(Proxy)向目标对象应用通知之后创建的对象 3.JVM中有很多垃圾回收策略，其中会用到很多垃圾收集器，如果我们将垃圾收集器的作用范围划分为新生代和老年代的话，那么以下哪个选项中的所有收集器的作用域是属于老年代A. Serial收集器、ParNew收集器、Paraller Scavenge收集器 B. Serial Old收集器、Paraller Old收集器、CMS收集器 C. Serial Old收集器、Paraller Old收集器、Paraller Scavenge收集器 D. CMS收集器、ParNew收集器、Paraller Scavenge收集器 正确答案：B 12年轻代：serial GC、parNew GC、paraller Scavenge GC老年代：serial old GC 、paraller old GC、CMS 4.下面几项关于Java程序初始化的几个原则：①静态对象（变量）优先于非静态对象（变量）初始化； ②父类优先于子类进行初始化； ③按照成员变量的定义顺序进行初始化； 其中正确的有： A. ①② B. ①③ C. ②③ D. ①②③ 正确答案：D 5.以下哪个不是分布式锁的实现方式A. 使用数据库乐观锁实现 B. 使用数据库悲观锁实现 C. 使用redis的setnx()、expire()方法，用于分布式锁 D. 基于Zookeeper实现分布式锁 正确答案：B 12345目前分布式锁的实现方案主要包括三种：1.基于数据库（唯一索引）2.基于缓存（Redis，memcached，tair）3.基于Zookeeper 6.对于数列4、5、6、7、9、12、18、23，如果采用折半查找元素9，请问需要查找几次？A. 2 B. 3 C. 4 D. 5 正确答案：B 12345n 代表数组长度4、5、6、7、9、12、18、231) Array[(0 + n - 1) / 2] 小于 9, (0 + n - 1) / 2 = 32) Array[(3 + 1 + n - 1) / 2] 大于 9, (3 + 1 + n - 1) / 2 = 53) Array[(3 + 1 + 5 - 1) / 2] 等于 9 7.现有一字符串”hello world”，使用哈夫曼编码最少使用多少bit内存：A. 4 B. 32 C. 64 D. 88 正确答案：B 8.已知现有一个大小为4初始状态为空的栈，现在有一组数据经过这个栈后，最终的数据顺序是:2 5 4 1 3,问原始的进栈数据不可能是以下的哪组A. 1 4 5 2 3 B. 5 2 3 1 4 C. 3 4 5 2 1 D. 4 1 3 5 2 正确答案：D 9.假设有一张表test,表中存放着全国的城市信息以及其所在的省份,现在要以每个省份包含名称以’州’为结尾的城市数量降序排序,包含相同数量的省份以省份名称降序拍戏,最终输出第二多以及第三多的省份以及数量,那么下面正确的sql语句是： create table test( id int(11) not null auto_increment, province char(50) not null comment ‘省份名称’, city char(50) not null comment ‘城市名称’, primary key(id), unique key idx(province, city) )engine = innodb; A. select province, count(*) c from test where city like ‘%州’ group by province order by c desc, province desc limit 2,1 B. select province, count(*) c from test where city like ‘%州’ group by province order by c desc, province desc limit 1,2 C. select province, count(*) c from test where city like ‘州%’ group by province order by c desc, province desc limit 2,1 D. select province, count(*) c from test where city like ‘州%’ group by province order by c desc, province desc limit 1,2 正确答案：B 10.假设有必修课成绩表course,每位学生的期末考试成绩以及补考成绩都录入到course表中,学号为20190001的同学想查询一下自己未通过的课程的课程编号与课程名称,那么下面正确的sql语句是： create table course( id int(11) not null auto_increment, sid int(11) not null comment ‘学号’, cid int(11) not null comment ‘课程编号’, cname char(50) not null comment ‘课程名称’, score int(11) not null comment ‘分数’, primary key(id) )engine = innodb; A. select distinct cid,cname from course where cid not in (select cid from course where score &gt; 60 and sid=20190001) B. select distinct cid,cname from course where cid in (select cid from course where score &lt; 60) and sid=20190001 C. select distinct cid,cname from course where cid not in (select cid from course where score &gt; 60) and sid=20190001 D. select distinct cid,cname from course where cid in (select cid from course where score &lt; 60 and sid=20190001) 11.序列{20, 23, 28, 41, 61, 31, 71, 76, 15, 30}构造为完全二叉树，完全二叉树再变为最小堆后，堆所对应的的中序遍历序列可能为A. 76, 23, 41, 61, 20, 30, 31, 15, 28, 71 B. 76, 23, 41, 20, 61, 30, 15, 31, 28, 71 C. 76, 20, 41, 23, 30, 61, 15, 31, 28, 71 D. 76, 23, 20, 41, 61, 15, 31, 20, 28, 71 正确答案：B 12.有如下递归函数 test(n)，其时间复杂度为多少？1234int test(int n) { if (n &lt;= 1) return 1; return (2 * test(n - 1) + 3 * test(n - 2));} A. O(logn) B. O(nlogn) C. O(n^2) D. O(n^3) E. O(2^n) 正确答案：E 1每一层递归调用两次递归，所以是2^n 13.假设磁头当前位于116道，正在向磁道序号增加的方向移动。现有一个磁道访问请求序列为48, 59, 37, 81, 125, 195, 185, 205采用电梯调度SCAN算法得到的磁道访问序列是：A. 125, 185, 195, 205, 81, 59, 48, 37 B. 125, 185, 195, 205, 37, 48, 59, 81 C. 37, 48, 59, 81, 125, 185, 195, 205 D. 125, 195, 185, 205, 48, 59, 37, 81 正确答案：A 属于同一进程的两个线程 T1和 T2并发执行，共享初值为 0 的全局变量 X。T1和 T2实现对全局变量 x 加 1 的伪代码分别如下: 123456789101112131415T1：temp1=X;temp1=temp1+1;X=temp1;T2：temp2=X;temp2=temp2+1;X=temp2; 2个线程进行到任意一步都能被对方打断，执行另外一个线程的代码，请问在所有可能的执行序列中，使 x 的值为 2 的序列个数有几种？ A. 1 B. 2 C. 3 D. 4 正确答案：B 1T1优先，T2优先 15.shell脚本中，需求如下：如果 ls /tmp 执行成功输出True，否则输出Fail，下列哪项正确A. ls /tmp; [[ $# -eq 0 ]] &amp;&amp; echo True || echo Fail B. ls /tmp; [[ $* -eq 0 ]] &amp;&amp; echo True || echo Fail C. ls /tmp; [[ $0 -eq 0 ]] &amp;&amp; echo True || echo Fail D. ls /tmp; [[ $? -eq 0 ]] &amp;&amp; echo True || echo Fail 正确答案：D 1234选项 A 中的$#表示命令行参数个数，而不是上一条命令执行结果的状态码。选项 B 中的$*表示所有命令行参数的字符串，而不是上一条命令执行结果的状态码。选项 C 中的$0表示脚本名字，而不是上一条命令执行结果的状态码。选项 D 中的$?表示上一条命令执行的状态码，如果状态码为 0，表示命令执行成功，否则表示执行失败。 16.nginx.log是一个日志文件，现在想将日志的最新输出实时打印在屏幕上，用哪个命令可以实现：A. cat -f nginx.log B. tee -f nginx.log C. head -f nginx.log D. tail -f nginx.log 正确答案：D 1234567linux命令中cat、more、less、tail、head均可用来查看文件内容，主要区别有：cat是一次性显示整个文件的内容，适用于文件内容少的情况；more和less一般用于显示文件内容超过一屏的内容，并且提供翻页的功能。tail 和 head分别显示文件的后几行和前几行内容。常用于大文件的截取。tail 用来显示文件的最后几行内容，当文件内容有更新时，tail会自己主动刷新，确保一直显示最新的文件内容。 17.由于前端直接可被用户访问，攻击者可以轻易得到页面和通讯过程中的相关信息，进而进行恶意的攻击，关于其攻击的方式描述正确的有哪些？A. 假定站点 foo.com 的服务器架设在公司内网，提供了任意站点截图服务 foo.com/screenshot?url=xxx，恶意修改 url 中的值为内网地址，构成 SSRF 攻击，进而造成数据泄露的风险 B. 网站 foo.com 提供 POST 方法的 /tansfer/to/xxx 的转账服务，由于未做 CSRF 的防范，被攻击者重复伪造该请求，形成重放攻击，造成经济损失 C. 网站 foo.com 使用了非安全的 HTTP 协议，其中转账服务 POST /transfer/to/xxx，转账金额 money 在 payload 上，假定接口层面采用了随机 token 来防范 csrf 攻击，接口参数未做签名校验，此时攻击者通过篡改 money 的数值，构成中间人攻击 D. 借助社会工程学的理论基础，基于用户的贪婪等心理，制作一个 qq.com 的”冒牌”中奖页面，诱导用户输入账号密码进行登录，造成隐私的泄露，属于”钓鱼”的网络欺诈行为 正确答案：ABCD 18.假设一个数组采用快速排序，则下面的选项中，不可能是第3趟排序结果的是A. 4, 8, 6, 10, 12, 16, 14 B. 10, 4, 6, 8, 12, 14, 16 C. 8, 4, 6, 12, 10, 14, 16 D. 4, 8, 6, 12, 10, 16, 14 正确答案：ACD 1234快速排序一趟确定1个或者2个点的最终位置，如果是第一次，确定1个。第二次以后，如果基点在最左边或者最右边确定1个点最终位置。如果在中间，那么确定2个点的最终位置，所以ACD全错只有B 选项，3个点依次都是在最左边，快速排序可能退化成冒泡排序，是正确的 19.某进程创建的若干个线程，这些线程不能共享的是A. 程序计数器 B. 某线程的栈指针 C. 进程打开的文件 D. 全局变量 E. 进程的堆空间 正确答案：AB 20.tcp发送报文数据时，可能将多个数据包合并成一个大的数据包发送，就有可能发生粘包问题。以下可以用来解决这个问题的是？A. 发送固定长度的消息 B. 包结尾增加分隔符 C. 慢开始算法 D. 把消息分成消息头和消息体，其中消息头上包含长度 E. 利用滑动窗口实现控制 正确答案：ABD 21.最小公倍数与最大公约数度度熊请你找出两个数a,b，满足1≤a,b≤n且lcm(a,b)−gcd(a,b)尽量大。输出最大的lcm*(a,b)−gcd(a,b).其中lcm*(a,b)表示a和b的最小公倍数，gcd*(a,b)表示a和b*的最大公约数。 示例1 输入 15 输出 119 示例2 输入 13 输出 15 正确答案： 123456789import java.util.*;public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); Long a = sc.nextLong(); System.out.println(a*(a-1)-1); }} 22.还原数列老板给度度熊n个数， 每一次从a[i]中取出一个最大的减去n， 其他的n−1个数加上1， 一直重复直到最大的a[i]&lt;n， 执行次数记为k。老板想知道最少执行多少次操作使得n个数都小于n呢？ 示例1 输入 1231 0 3 输出 11 正确答案： 12345678910111213141516171819202122232425262728293031323334353637import java.util.*; public class Main{ public static void main(String[] args){ Scanner sc =new Scanner(System.in); int n =sc.nextInt(); long [] arr =new long [n]; for(int i =0;i&lt;n;i++){ arr[i]=sc.nextLong(); } long count=0; int len=arr.length; while(!isVaild(arr)){ long max=0; int index=0; for(int i =0;i&lt;arr.length;i++){ if(arr[i]&gt;max){ max=arr[i]; index=i; } } count+=max/n; for(int i=0;i&lt;n;i++){ arr[i]+=max/n; } arr[index]=max%n; } System.out.println(count); } public static boolean isVaild(long [] arr){ boolean falg =true; for(long i:arr){ if(i&gt;=arr.length) return false; } return falg; }} 23.树上上升序列度度熊给定一棵树，树上的第u个节点有点权a**u。请你找出一条最长的路径(u,v)，使得从u沿着唯一路径走到v的途中，点权不断严格递增。换句话说，设路径为(u,p1​,p2​,…,p**m​,v)，则需要满足au*​&lt;a**p1​​&lt;*ap*2​​⋯&lt;apm​​&lt;a**v​。输出最长满足条件的路径的长度。 示例1 输入 12345653 5 5 4 11 21 32 42 5 输出 12 示例2 输入 1234543 4 1 21 22 32 4 输出 12 正确答案： 1234567891011121314151617181920212223242526272829303132333435363738394041//邻接表import java.util.*; public class Main { static List&lt;List&lt;Integer&gt;&gt; graph = new ArrayList&lt;&gt;(); static int max = 0; public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] num = new int[n]; for (int i = 0; i &lt; n; i++) { num[i] = sc.nextInt(); } for (int i = 0; i &lt; num.length; i++) { graph.add(new ArrayList&lt;&gt;()); } // 构建图,邻接矩阵 for (int i = 0; i &lt; n - 1; i++) { int a = sc.nextInt() - 1; int b = sc.nextInt() - 1; graph.get(a).add(b); graph.get(b).add(a); } for (int i = 0; i &lt; num.length - 1; i++) { dfs(num, i, 1); } System.out.println(max); } public static void dfs(int[] num, int start, int wayNum) { max = Math.max(max, wayNum); for (int i : graph.get(start)) { if (num[i] &gt; num[start]) { dfs(num, i, wayNum + 1); } } }}","categories":[{"name":"笔试","slug":"笔试","permalink":"http://example.com/categories/%E7%AC%94%E8%AF%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"二分查找","slug":"二分查找","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"哈夫曼编码","slug":"哈夫曼编码","permalink":"http://example.com/tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"哈夫曼编码","slug":"算法/哈夫曼编码","date":"2023-03-29T07:01:40.875Z","updated":"2023-03-29T07:19:43.958Z","comments":true,"path":"2023/03/29/算法/哈夫曼编码/","link":"","permalink":"http://example.com/2023/03/29/%E7%AE%97%E6%B3%95/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81/","excerpt":"","text":"哈夫曼编码步骤1.统计频率（空格也要统计） 2.排序 哈夫曼树是一个带权的二叉树，而在哈夫曼编码中，字符的出现频率就是字符的权重。因此要根据字符的频率放入优先队列中进行排序。然后根据这些字符构建一棵哈夫曼树 3.合并 进行迭代，每次都去除队列中的前面两个元素，也就是权值最小的两棵子树进行合并成一棵子树。直到最终所有的元素合并成一棵树。这棵树就是哈夫曼树。 4.进行编码 已知字符集{ a, b, c, d, e, f }，若各字符出现的次数分别为{ 6, 3, 8, 2, 10, 4 }，则对应字符集中各字符的哈夫曼编码可能是： A. 00, 1011, 01, 1010, 11, 100 B. 00, 100, 110, 000, 0010, 01 C. 10, 1011, 11, 0011, 00, 010 D. 0011, 10, 11, 0010, 01, 000 先排序 两个权小的合并 进行编码 最后结果： 字符 哈夫曼编码 a 00 b 1011 c 01 d 1010 e 11 f 100","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"哈夫曼树","slug":"哈夫曼树","permalink":"http://example.com/tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91/"}]},{"title":"磁盘调度算法","slug":"操作系统/磁盘调度算法","date":"2023-03-29T03:45:56.635Z","updated":"2023-03-29T03:47:06.873Z","comments":true,"path":"2023/03/29/操作系统/磁盘调度算法/","link":"","permalink":"http://example.com/2023/03/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/","excerpt":"","text":"磁盘调度算法原文出处:小林coding 磁盘的结构，如下图： 常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 512 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。 磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。 寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。 假设有下面一个请求序列，每个数字代表磁道的位置： 98，183，37，122，14，124，65，67 初始磁头当前的位置是在第 53 磁道。 接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有： 先来先服务算法 最短寻道时间优先算法 扫描算法 循环扫描算法 LOOK 与 C-LOOK 算法 先来先服务先来先服务（First-Come，First-Served，FCFS），顾名思义，先到来的请求，先被服务。 那按照这个序列的话： 98，183，37，122，14，124，65，67 那么，磁盘的写入顺序是从左到右，如下图： 先来先服务算法总共移动了 640 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。 最短寻道时间优先最短寻道时间优先（Shortest Seek First，SSF）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求，还是以这个序列为例子： 98，183，37，122，14，124，65，67 那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序： 65，67，37，14，98，122，124，183 磁头移动的总距离是 236 磁道，相比先来先服务性能提高了不少。 但这个算法可能存在某些请求的饥饿，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里产生饥饿的原因是磁头在一小块区域来回移动。 扫描算法最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。 为了防止这个问题，可以规定：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（*Scan*）算法。 这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。 还是以这个序列为例子，磁头的初始位置是 53： 98，183，37，122，14，124，65，67 那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序： 37，14，0，65，67，98，122，124，183 磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。 扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。 循环扫描算法扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。 循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。 还是以这个序列为例子，磁头的初始位置是 53： 98，183，37，122，14，124，65，67 那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序： 65，67，98，122，124，183，199，0，14，37 磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。 循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。 LOOK 与 C-LOOK算法我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。 那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。 那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。 而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"磁盘","slug":"磁盘","permalink":"http://example.com/tags/%E7%A3%81%E7%9B%98/"}]},{"title":"凹凸科技2017秋招java工程师笔试","slug":"笔试/凹凸科技2017秋招java工程师笔试","date":"2023-03-23T12:03:10.614Z","updated":"2023-03-27T10:46:50.959Z","comments":true,"path":"2023/03/23/笔试/凹凸科技2017秋招java工程师笔试/","link":"","permalink":"http://example.com/2023/03/23/%E7%AC%94%E8%AF%95/%E5%87%B9%E5%87%B8%E7%A7%91%E6%8A%802017%E7%A7%8B%E6%8B%9Bjava%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95/","excerpt":"","text":"凹凸科技2017秋招java工程师笔试1.GC是什么？为什么要有GC？正确答案： 123456在java语言中，垃圾回收（Garbage Collection，GC）的主要作用是回收程序中不再使用的内存。 为了减轻开发人员的工作，同时增加系统的安全性和稳定性，java语言提供了垃圾回收器来自动检测对象的作用域，可自动地把不再被使用的存储空间释放掉。主要的任务是：分配内存，回收不再被引用的对象的内存空间。 垃圾回收器提高了开发人员的开发效率，保证程序的稳定性，但是也带来了问题，为了处理垃圾回收，垃圾回收器必须跟踪内存的使用情况，释放没用的对象，在完成内存的释放后还需要处理堆中的碎片，这些操作增加JVM的负担，从而降低了程序的执行效率。 2.简述final，finalize，finally的区别？正确答案： 1234567891. final是关键字，final可以修饰类、方法、属性。 如果一个类被final修饰，那么这个类就是最终类，不能派生出新的子类，不能作为父类被继承，该类中的所有方法都不能被重写，但是final类中的成员变量是可以改变的，要想final类中的成员变量的不可以改变，必须给成员变量添加final修饰。因此，一个类不能同时被final和abstract修饰，这两个关键字相互矛盾。 如果final修饰方法，那么这个方法是最终方法，不允许任何子类重写该方法，但子类仍可以使用该方法，注意：final参数用来表示这个参数在这个函数内部不允许被修改。 final修饰属性，被final修饰的变量不可变。这里的不可变有两重含义：引用不可变和对象不可变。final指的是引用不可变，即它只能指向初始化时指向的那个对象，而不关心指向对象内容的变化。因此，被final修饰的变量必须初始化，该变量其实就是常量。2. finally作为异常处理的一部分，只能用在try/catch语句快中，finally代码块中的语句一定会被执行，经常被用来释放资源，如IO流和数据库资源的释放。3. finalize是Object类的一个方法，该方法在Object类中声明： protected void finalize() throws Throwable { } 在垃圾回收器执行时会调用被回收对象的finalize()方法，可以覆盖此方法来实现对其资源的回收。注意：一旦垃圾回收器准备释放某个对象占用的空间，将首先调该对象的finalize()方法，并且在下一次垃圾回收动作发生时，才真正将该对象占用的内存回收。 3.Abstract class和interface有什么区别？正确答案： Abstract class Interface 实例化 不能 不能 类 一种继承关系，一个类只能使用一次继承关系。可以通过继承多个接口实现多重继承 一个类可以实现多个interface 数据成员 可有自己的 静态的不能被修改即必须是static final，一般不在此定义 方法 可以私有的，非abstract方法，必须实现 不可有私有的，默认是public，abstract 类型 变量 可有私有的，默认是friendly 型，其值可以在子类中重新定义，也可以重新赋值 不可有私有的，默认是public static final 型，且必须给其初值，实现类中不能重新定义，不能改变其值。 设计理念 表示的是“is-a”关系 表示的是“like-a”关系 实现 需要继承，要用extends 要用implements 扩展：java8的接口新特性（可以有方法体的接口） 1234567interface MyInterface{ String myNewName(String newName); default String myOldName(){ return \"chao\"; }} 4.Java内存管理（1）请描述java的内存管理原理 （2）请描述java的内存分区 （3）请描述java的对象生命周期，以及对象的访问？ 正确答案： （1）请描述java的内存管理原理 123Java的内存管理就是对象的分配和释放在Java中，内存的分配是由程序完成的，而内存的释放是由垃圾收集器(Garbage Collection，GC)完成的 （2）请描述java的内存分区 （3）请描述java的对象生命周期，以及对象的访问？ 12345678生命周期： 1.创建阶段(Created)2.应用阶段(In Use)：一旦对象被创建，并被分派给某些变量赋值，这个对象的状态就切换到了应用阶段3.不可见阶段(Invisible)：例如我在for里面定义了i for循环break了就不能访问i4.不可达阶段(Unreachable)：对象处于不可达阶段是指该对象不再被任何强引用所持有。5.收集阶段(Collected)：当垃圾回收器发现该对象已经处于“不可达阶段”并且垃圾回收器已经对该对象的内存空间重新分配做好准备时，则对象进入了“收集阶段”。6.终结阶段(Finalized)：当对象执行完finalize()方法后仍然处于不可达状态时，则该对象进入终结阶段。在该阶段是等待垃圾回收器对该对象空间进行回收。7.对象空间重分配阶段(De-allocated)：垃圾回收器对该对象的所占用的内存空间进行回收或者再分配了，则该对象彻底消失了，称之为“对象空间重新分配阶段” 1句柄访问方式：java堆中将划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。 指针访问方式：reference变量中直接存储的就是对象的地址，而java堆对象一部分存储了对象实例数据，另外一部分存储了对象类型数据 5.指出以下程序的输出或错误。1234567891011121314public class Test{ public static void main(String[] args){ } public void method(int a){ } public void method(int b){ } public void method(long b){ } public void method(int a,int b){ } public void method(int a,char b){ }} 正确答案： 123456 publicvoidmethod(inta){ } publicvoidmethod(intb){ } 方法重载不以返回值类型为判断，重载通过不同的方法参数来区分，如不同的参数个数，不同的参数类型，不同的参数顺序；这2个方法错误。 6.指出以下程序的输出或者错误12345678910111213141516171819202122232425class Person{ Person(){ System.out.println(\"create person\"); } public static String getName(){ return\"Person\"; }}class Teacher extends Person{ Teacher(){ System.out.println(\"create teacher\"); super(); } public static String getName(){ return\"Teacher\"; }}public class Test{ public static void main(String[] args){ Person person = new Person(); Person teacher = new Teacher(); System.out.println(person.getName()); System.out.println(teacher.getName()); }} 正确答案： 1super要在构造函数第一行使用 7.假设树的节点的data类型为int型，请实现两棵树是否相等的比较？ 注:A,B两棵树相等且当rootA-&gt;data==rootB-&gt;data，而且A和B的左右子树相等或者左右互换后相等。 （1）给出树节点的结构定义 （2）写出实现思路，以及复杂度估计 （3）用你习惯的语言或者伪代码实现该算法 正确答案： （1）给出树节点的结构定义 123456789101112131415161718public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode() { } TreeNode(int val) { this.val = val; } TreeNode(int val, TreeNode left, TreeNode right) { this.val = val; this.left = left; this.right = right; }} （3）用你习惯的语言或者伪代码实现该算法 与LeetCode101. 对称二叉树相识 12345678910public class Main { public boolean equation(TreeNode root1, TreeNode root2) { if (root1 == null &amp;&amp; root2 == null) return true; if (root1 == null || root2 == null) return false; return (root1.val == root2.val) &amp;&amp; equation(root1.left,root2.left) &amp;&amp; equation(root1.right,root2.right); }} 8.假设基本数据为整型，输入为一串无序的整数，请用堆排序的方式对该整数串排序（增序），有重复时保留重复的数。 测试数据:[3,6,23,4,3,2,9,10,18,11] （1）堆排序的思想，使用情况一般是什么？ （2）算法所需要的数据结构？ （3）用你习惯的语言或者伪代码实现你的算法？ 正确答案： （1）堆排序的思想，使用情况一般是什么？ 123根据初始数组去构造初始堆（构建一个完全二叉树，保证所有的父结点都比它的孩子结点数值大）。每次交换第一个和最后一个元素，输出最后一个元素（最大值），然后把剩下元素重新调整为大根堆。当输出完最后一个元素后，这个数组已经是按照从小到大的顺序排列了。 （2）算法所需要的数据结构？ 1使用线性数据结构比如数组就可以实现堆排序 （3）用你习惯的语言或者伪代码实现你的算法？ 123456789101112131415161718192021222324252627282930313233343536373839public class HeapSort { public static void main(String[] args) { int[] arr = {8, 9, 7, 5, 6, 5, 1, 3, 2, 4}; sort(arr); System.out.println(Arrays.toString(arr)); } public static void sort(int[] arr) { for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { adjustHeap(arr, i, arr.length); } for (int j = arr.length - 1; j &gt; 0; j--) { swap(arr, 0, j); adjustHeap(arr, 0, j); } } public static void adjustHeap(int[] arr, int i, int length) { int temp = arr[i]; for (int k = i * 2 + 1; k &lt; length; k = k * 2 + 1) { if (k + 1 &lt; length &amp;&amp; arr[k] &lt; arr[k + 1]) { k++; } if (arr[k] &gt; temp) arr[i] = arr[k]; i = k; } else { break; } } arr[i] = temp; } public static void swap(int[] arr, int a, int b) { int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; }} 9.输入一个已经按升序排序过的数组和一个数字，在数组中查找两个数，使得它们的和是输入的那个数字，要求时间复杂度为O(n)，如果有多对数字的和等于输入的数字，输出任意一对即可。正确答案： 同LeetCode1. 两数之和，因题目比LeetCode多一个条件，可用以下方法 1234567891011121314151617private static void findAns(int[] data, int sum) { int size = data.length; int begin = 0; int end = size-1; while (begin &lt; size &amp;&amp; end &gt;=0 &amp;&amp; begin &lt; end) { int cu = data[begin] + data[end]; if (cu &gt; sum) { end --; } else if (cu &lt; sum) { begin ++; } else { System.out.println(data[begin] + \" \" + data[end]); return; } } System.out.println(\"无匹配项\");} LeetCode1. 两数之和解法 123456789101112class Solution { public int[] twoSum(int[] nums, int target) { HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; ++i) { if (map.containsKey(target-nums[i])) { return new int[]{map.get(target-nums[i]),i}; } map.put(nums[i],i); } return new int[]{}; }} 10.输入一个英文句子，翻转句子中的顺序，但单词内字符的顺序不变，句子中单词以空格隔开，为简单起见。标点符号和普通字母一样处理，例如输入”i am a student”.则输出”student a am I”正确答案： 同LeetCode151. 反转字符串中的单词 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class Solution { public String reverseWords(String s) { StringBuilder sb = trimSpaces(s); // 翻转字符串 reverse(sb, 0, sb.length() - 1); // 翻转每个单词 reverseEachWord(sb); return sb.toString(); } public StringBuilder trimSpaces(String s) { int left = 0, right = s.length() - 1; while (left &lt;= right &amp;&amp; s.charAt(left) == ' ') { ++left; } while (left &lt;= right &amp;&amp; s.charAt(right) == ' ') { --right; } StringBuilder sb = new StringBuilder(); while (left &lt;= right) { char c = s.charAt(left); if (c != ' ') { sb.append(c); } else if (sb.charAt(sb.length() - 1) != ' ') { sb.append(c); } ++left; } return sb; } public void reverse(StringBuilder sb, int left, int right) { while (left &lt; right) { char tmp = sb.charAt(left); sb.setCharAt(left++, sb.charAt(right)); sb.setCharAt(right--, tmp); } } public void reverseEachWord(StringBuilder sb) { int n = sb.length(); int start = 0, end = 0; while (start &lt; n) { while (end &lt; n &amp;&amp; sb.charAt(end) != ' ') { ++end; } reverse(sb, start, end - 1); start = end + 1; ++end; } }} 11.请用java，实现Stack类或者Queue类，支持该数据结构的基本操作。正确答案： 12345678910111213141516171819202122import java.util.LinkedList; public class MyStack { private LinkedList ll = new LinkedList(); public void push(Object obj){ ll.addFirst(obj); } public Object pop(){ return ll.removeFirst(); } public Object peek(){ return ll.getFirst(); } public boolean empty(){ return ll.isEmpty(); } } 12.设计线程类WorkThead，其构造函数接收一个message字符串作为参数，把该字符串打印到console上，同时，在WorkThread的main函数中启动该线程正确答案： 12345678910111213public Class WorkThead extends Thread{ String message; public WorkThead(Stirng message){ this.message=message; System.Out.PrintIn(message); } public void run(){ } public static void main(String[] argv){ WorkThead（\"hello world!\"）.start(); }}","categories":[{"name":"笔试","slug":"笔试","permalink":"http://example.com/categories/%E7%AC%94%E8%AF%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"},{"name":"GC","slug":"GC","permalink":"http://example.com/tags/GC/"},{"name":"interface","slug":"interface","permalink":"http://example.com/tags/interface/"},{"name":"abstract","slug":"abstract","permalink":"http://example.com/tags/abstract/"},{"name":"线程类","slug":"线程类","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B%E7%B1%BB/"}]},{"title":"点我达2019届校招Java开发笔试","slug":"笔试/点我达2019届校招Java开发笔试","date":"2023-03-21T11:14:07.098Z","updated":"2023-03-21T11:25:00.566Z","comments":true,"path":"2023/03/21/笔试/点我达2019届校招Java开发笔试/","link":"","permalink":"http://example.com/2023/03/21/%E7%AC%94%E8%AF%95/%E7%82%B9%E6%88%91%E8%BE%BE2019%E5%B1%8A%E6%A0%A1%E6%8B%9BJava%E5%BC%80%E5%8F%91%E7%AC%94%E8%AF%95/","excerpt":"","text":"点我达2019届校招Java开发笔试1.统计各部门平均年龄，其中三部门人员平均年龄分别为38岁、24岁、42岁。A和B 两部门人员平均年龄为30岁，B和C两部门人员平均年龄为34岁。这三个部门全体人员的平均年龄为多少岁？A. 34 B. 35 C. 36 D. 37 正确答案：B 本题考查计算中的平均数。依题设A部门x人,B部门y人, C部门z人，根据“A和B两部门人员平均年龄为30岁”可得：38x+24y=30(x+y)，求得x：y=3：4，x=0.75y;又根据“B和C两部门人员平均年龄为34岁”可得：24y+42z=34(y+z)，求得y：z=4：5，那么，x：y：z=3：4：5，那么设三者人数分别是3a、4a、5a，部门总人数=12a，平均年龄=(38×3a + 24×4a + 42×5a)÷12a，利用尾数法可知，括号内各项相加后尾数为0，只有35乘以12尾数为0。 2.以下数据结构的说法，错误的是A. 红黑树插入操作的平均时间复杂度为O(logn)，最坏时间复杂度为O(logn) B. B+树插入操作的平均时间复杂度为O(logn)，最坏时间复杂度为O(logn) C. Hash表插入操作的平均时间复杂度为O(logn)，最坏时间复杂度为O(n) D. 排序链表插入操作的平均时间复杂度为O(n)，最坏时间复杂度为O(n) 正确答案：C 哈希表插入的时间复杂度与冲突次数有关，O(冲突次数/n)，最好的情况冲突次数为0,直接插入，时间复杂度为O(1)。最坏情况是所有值对应同一个键值，这是冲突次数最多，为0+1+2+3+4+…+(n-1)=n*(n-1)/2,平均比较次数为(n-1)/2,时间复杂度为O(n) 3.用直接插入排序方法对下面4个序列进行排序(由小到大),元素比较次数最少的是A. 88,95,12,88,21,54,23,79 B. 95,21,79,88,54,23,39,12 C. 39,54,21,79,88,23,95,12 D. 12,21,23,39,79,54,88,95 正确答案：D 逆序越少的序列，在 直接插入排序 中比较次数是越少的 4.三个进程A，B，C。单核CPU执行时，需要以下资源。其中优先级高的进程可以抢占CPU资源但不能抢占IO资源。所有任务执行完毕时候，需要多长时间？ A. 170ms B. 200ms C. 240ms D. 270ms 正确答案：B 优先级：A&gt;B&gt;C A先I/O后CPU，这时候CPU是空闲的。B先CPU后I/O，C先CPU后I/O，B的优先级比C高，B先进行CPU操作； B执行完CPU操作以后A还在进行I/O操作，这时候C进行CPU操作，B等A的I/O执行完以后再进行操作； C执行完CPU操作以后，A还没执行完I/O操作，C也等着； A执行完I/O操作以后，B比C的优先级高，B进行I/O操作，A进行CPU操作，C等候。 B执行完I/O操作以后，C再操作 5.针对二分查找算法，假设一个有序数组有 136 个元素，那么要查找到第 10 个元素， 需要比较的元素为A. 68,34,17,9,13,11,10 B. 68,34,17,8,12,10 C. 69,35,18,10 D. 68,34,18,9,13,11,10 正确答案：B 6.入栈序列是：a1,a3,a5,a2,a4,a6,出栈序列是：a5,a4,a2,a6,a3,a1，则栈的容量最小是A. 5 B. 3 C. 6 D. 4 正确答案：D 1234567891011121 13 1 35 1 3 5- 1 3 52 1 3 24 1 3 2 4- 1 3 2 4- 1 3 26 1 3 6 - 1 3 6- 1 3- 1 7.在现代计算机上，即使是单核单CPU系统，一个程序的死循环bug，也不会导致别的程序完全得不到时间运行，这跟哪些因素有关？A. 时钟中断 B. OS进程（线程）时间片划分 C. 虚拟内存机制 D. OS抢占式调度 正确答案：ABD 8.Linux 系统中列出当前占用8080端口进程的命令1正确答案： 1lsof -i:8080 9.21点是一种扑克游戏。如果玩家拿到扑克牌的点数总和超过21点则称为爆点，被判失败。其中A牌可以被记为11点或者1点，J, Q, K 都记为10点。如果用一副牌玩游戏（52张牌），玩家手上拿到一个K和6。那他再抽两张牌会爆点的可能性约有多大？正确答案： 93.7% 或 93.8% 10.已知二叉树的中序遍历结果为MFLEDABKCGHJI，后序遍历结果为FELMDKHGJICBA，则其先序遍历结果为正确答案： 1ADMLFEBCKIJGH 11.为了解决进程间的同步和互斥问题，通常采用一种称为信号量机制的方法。若系统中有7个进程共享若干个资源R，每个进程都需要6个资源R，那么使系统不发生死锁的资源R的最少数目是正确答案： 136 1234用银行家算法计算死锁时，假设有m个共享资源，n个进程，每个进程所需的最大资源数为w，那么仅是m&gt;n*(w-1)时，才会不死锁。如果每个进程所需的资源数不同，则先平均分配，只要有一个进程满足了资源要求，就不会死锁。不会发生死锁的资源数m &gt; n * (w-1) = 7 * (6 - 1) = 7 * 5 = 35最少： 36个 12.假设某一虚拟存储系统采用先进先出（FIFO）页面淘汰算法，有一个进程在内存中占3页（开始时内存为空），当访问如下页面序列号后1,2,3,1,2,4,2,3,5,3,4,5,6会产生几次缺页正确答案： 16 11 2 3 依次进入缺页产生次数为3 接下来1 2 存在，4没有 则1出 现在为2 3 4 ，次数加1则为4 ，2 3 存在 5没有则 2出，缺页次数加1后为5，现在为 3 4 5 ，5存在，6没有则3出现在为 4 5 6 ，缺页次数加1 为6 13.若磁头的当前位置在第100磁道，现在有一磁盘读写请求序列如下：32,286,125,192,28,41,297,413,29,64,80,4。若采用最短寻道时间优先算法，则平均寻道长度是多少？正确答案： 142.08 1234磁盘最短寻道时间优先算法：从100开始依次搜索顺序：80，64，41，32，29，28，4，125，192，286，297，413 寻道长：20+16+23+9+3+1+24+121+67+94+11+116 / 12 = 42.08 14.用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。同LeetCode 232. 用栈实现队列 12345678910111213141516171819202122232425262728293031323334class MyQueue { Stack&lt;Integer&gt; sta1,sta2; public MyQueue() { sta1 = new Stack&lt;&gt;(); sta2 = new Stack&lt;&gt;(); } public void push(int x) { sta1.push(x); } public int pop() { if (sta2.isEmpty()) { while (!sta1.isEmpty()) { sta2.push(sta1.pop()); } } return sta2.pop(); } public int peek() { if (sta2.isEmpty()) { while (!sta1.isEmpty()) { sta2.push(sta1.pop()); } } return sta2.peek(); } public boolean empty() { return sta1.isEmpty() &amp;&amp; sta2.isEmpty(); }} 15.把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。同LeetCode 剑指 Offer 49. 丑数 123456789101112131415class Solution { public int nthUglyNumber(int n) { int[] dp = new int[n]; dp[0] = 1; int a = 0,b = 0, c = 0; for (int i = 1; i &lt; n; ++i) { int n1 = dp[a] * 2,n2 = dp[b] * 3,n3 = dp[c] * 5; dp[i] = Math.min(Math.min(n1,n2),n3); if (dp[i] == n1) a ++; if (dp[i] == n2) b ++; if (dp[i] == n3) c ++; } return dp[n - 1]; }} 16.现在一副54张的扑克牌（2个大王,2个小王），任意抽五张牌，判断是不是顺子。其中A看作1,J为11,Q为12,K为13。另外这里还有个“癞子”规则，就是大王和小王可以代替任何牌。比如：“红心A,黑桃3,小王,大王,方片5”, 上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4)。现在我们要用程序来判断5张牌是不是顺子。为了方便起见,你可以认为大小王是0。同LeetCode 面试题61. 扑克牌中的顺子 1234567891011class Solution { public boolean isStraight(int[] nums) { int joker = 0; Arrays.sort(nums); for(int i = 0; i &lt; 4; i++) { if(nums[i] == 0) joker++; else if(nums[i] == nums[i + 1]) return false; } return nums[4] - nums[joker] &lt; 5; }} 17.代码能否保证所有Hello, DWD一定在Done All DWD之前输出？如果不能，请尽可能多的提供方法来保证 正确答案： 1不能。CountDownLatch/线程池await/共享变量等 18.代码的输出结果是： 正确答案： 13 123此题考察的是finally抢占return的知识点。当finally里面有return语句时，会执行finally里的return语句而忽略try，catch代码块里的return语句。所以这里不管抛不抛出异常都会执行finally里的return语句。 19.代码的输出结果是： 正确答案： 123456AS BS AC BC AC BC 1234静态语句块、构造语句块和构造函数的执行顺序 静态语句块：在类加载的时候执行（从父类到子类） 静态语句块执行完，执行main方法 new对象，从上到下先执行构造代码块在执行构造器","categories":[{"name":"笔试","slug":"笔试","permalink":"http://example.com/categories/%E7%AC%94%E8%AF%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"基础","slug":"基础","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"智力题","slug":"智力题","permalink":"http://example.com/tags/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"name":"红黑树","slug":"红黑树","permalink":"http://example.com/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"b+数","slug":"b-数","permalink":"http://example.com/tags/b-%E6%95%B0/"},{"name":"二分查找","slug":"二分查找","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"银行家算法","slug":"银行家算法","permalink":"http://example.com/tags/%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95/"}]},{"title":"二叉树的迭代遍历","slug":"算法/二叉树/二叉树的迭代遍历","date":"2023-03-20T07:26:28.537Z","updated":"2023-03-20T07:27:34.506Z","comments":true,"path":"2023/03/20/算法/二叉树/二叉树的迭代遍历/","link":"","permalink":"http://example.com/2023/03/20/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%BF%AD%E4%BB%A3%E9%81%8D%E5%8E%86/","excerpt":"","text":"二叉树的迭代遍历前序遍历（迭代法）想出栈为左右，入栈得为右左 前序遍历是中左右，每次先处理的是中间节点，那么先将根节点放入栈中，然后将右孩子加入栈，再加入左孩子。 12345678910111213141516171819202122// 前序遍历顺序：中-左-右，入栈顺序：中-右-左class Solution { public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null){ return result; } Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()){ TreeNode node = stack.pop(); result.add(node.val); if (node.right != null){ stack.push(node.right); } if (node.left != null){ stack.push(node.left); } } return result; }} 后序遍历（迭代法）后序遍历，先序遍历是中左右，后续遍历是左右中，那么我们只需要调整一下先序遍历的代码顺序，就变成中右左的遍历顺序，然后在反转result数组，输出的结果顺序就是左右中了 1234567891011121314151617181920212223// 后序遍历顺序 左-右-中 入栈顺序：中-左-右 出栈顺序：中-右-左， 最后翻转结果class Solution { public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null){ return result; } Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()){ TreeNode node = stack.pop(); result.add(node.val); if (node.left != null){ stack.push(node.left); } if (node.right != null){ stack.push(node.right); } } Collections.reverse(result); return result; }} 中序遍历（迭代法）12345678910111213141516171819202122// 中序遍历顺序: 左-中-右 入栈顺序： 左-右class Solution { public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null){ return result; } Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()){ if (cur != null){ stack.push(cur); cur = cur.left; }else{ cur = stack.pop(); result.add(cur.val); cur = cur.right; } } return result; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"}]},{"title":"并发类问题3","slug":"并发/并发类问题3","date":"2023-03-12T08:25:11.698Z","updated":"2023-03-12T08:27:48.701Z","comments":true,"path":"2023/03/12/并发/并发类问题3/","link":"","permalink":"http://example.com/2023/03/12/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E7%B1%BB%E9%97%AE%E9%A2%983/","excerpt":"","text":"并发类问题3线程与进程的比较 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；（单位） 线程共享本进程的地址空间，而进程之间是独立的地址空间；（地址空间） 每个进程具备各自的数据空间，进程之间的切换会有较大的开销。进程的上下文切换时间开销远远大于线程上下文切换时间,耗费资源较大,效率要差一些；（资源开销） 进程的并发性较低,线程的并发性较高；（并发性） 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；（拥有的资源） 一个进程崩溃后,在保护模式下不会对其他进程产生影响,但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮；（崩溃） 系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言,除了 CPU 外,系统不会为线程分配内存，线程组之间只能共享资源；（内存空间） 并行和并发的区别？ 并行：单位时间多个处理器同时处理多个任务。 并发：一个处理器处理多个任务，按时间片轮流处理多个任务。 线程的上下文切换即便是单核的处理器也会支持多线程，处理器会给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给每个线程的执行时间，一般来说时间片非常的短，所以处理器会不停地切换线程。 CPU会通过时间片分配算法来循环执行任务，当前任务执行完一个时间片后会切换到下一个任务，但切换前会保存上一个任务的状态，因为下次切换回这个任务时还要加载这个任务的状态继续执行，从任务保存到在加载的过程就是一次上下文切换。 Java中守护线程和用户线程的区别？任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on) 设置，true则是将该线程设置为守护线程，false则是将该线程设置为用户线程。同时，Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。 用户线程：平时使用到的线程均为用户线程。 守护线程：用来服务用户线程的线程，例如垃圾回收线程。 守护线程和用户线程的区别主要在于Java虚拟机何时离开。 用户线程：当任何一个用户线程未结束，Java虚拟机是不会结束的。 守护线程：如何只剩守护线程未结束，Java虚拟机结束。 Java中的死锁、活锁、饥饿有什么区别？活锁：任务或者执行者没有被阻塞，由于某些条件没有被满足，导致线程一直重复尝试、失败、尝试、失败。例如，线程1和线程2都需要获取一个资源，但他们同时让其他线程先获取该资源，两个线程一直谦让，最后都无法获取 活锁和死锁的区别： 活锁是在不断地尝试、死锁是在一直等待。 活锁有可能自行解开、死锁无法自行解开。 饥饿：一个或者多个线程因为种种原因无法获得所需要的资源， 导致一直无法执行的状态。以打印机打印文件为例，当有多个线程需要打印文件，系统按照短文件优先的策略进行打印，但当短文件的打印任务一直不间断地出现，那长文件的打印任务会被一直推迟，导致饥饿。活锁就是在忙式等待条件下发生的饥饿，忙式等待就是不进入等待状态的等待。 产生饥饿的原因： 高优先级的线程占用了低优先级线程的CPU时间 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的wait()方法)，因为其他线程总是被持续地获得唤醒。 死锁、饥饿的区别：饥饿可自行解开，死锁不行。 创建线程一共有哪几种方法？ 继承Thread类创建线程 实现Runnable接口创建线程 使用Callable和Future创建线程 使用线程池例如用Executor框架 如何停止一个正在运行的线程？ 中断：Interrupt方法中断线程 使用volatile boolean标志位停止线程：在线程中设置一个boolean标志位，同时用volatile修饰保证可见性，在线程里不断地读取这个值，其他地方可以修改这个boolean值。 使用stop()方法停止线程，但该方法已经被废弃。因为这样线程不能在停止前保存数据，会出现数据完整性问题。 同步方法和同步方法块哪个效果更好？同步块更好些，因为它锁定的范围更灵活些，只在需要锁住的代码块锁住相应的对象，而同步方法会锁住整个对象。","categories":[{"name":"并发","slug":"并发","permalink":"http://example.com/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"并发类问题2","slug":"并发/并发类问题2","date":"2023-03-10T09:39:32.248Z","updated":"2023-03-11T09:18:35.122Z","comments":true,"path":"2023/03/10/并发/并发类问题2/","link":"","permalink":"http://example.com/2023/03/10/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E7%B1%BB%E9%97%AE%E9%A2%982/","excerpt":"","text":"并发类问题runnable 和 callable 有什么区别？相同点： 两者都是接口 两者都需要调用Thread.start启动线程 不同点： callable的核心是call()方法，允许返回值，runnable的核心是run()方法，没有返回值 call()方法可以抛出异常，但是run()方法不行 callable和runnable都可以应用于executors，thread类只支持runnable 线程的run()和start()有什么区别？ 调用 start() 方法是用来启动线程的，轮到该线程执行时，会自动调用 run()；直接调用 run() 方法，无法达到启动多线程的目的，相当于主线程线性执行 Thread 对象的 run() 方法。 一个线程对线的 start() 方法只能调用一次，多次调用会抛出 java.lang.IllegalThreadStateException 异常；run() 方法没有限制。 线程同步以及线程调度相关的方法有哪些？ wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁； sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常； notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒 某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关； notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是 让它们竞争，只有获得锁的线程才能进入就绪状态； join()：与sleep()方法一样，是一个可中断的方法，在一个线程中调用另一个线程的join()方法，会使得当前的线程挂起，知直到执行join()方法的线程结束。例如在B线程中调用A线程的join()方法，B线程进入阻塞状态，直到A线程结束或者到达指定的时间。 yield()：暂停当前线程，以便其他线程有机会执行，不过不能指定暂停的时间，并且也不能保证当前线程马上停止。yield方法只是将Running状态转变为Runnable状态。 线程的sleep()方法和yield()方法有什么不同？ sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给优先级低的线程以运行的机会，而yield()方法只会给相同优先级或者更高优先级的线程以运行机会。 线程执行sleep()方法后会转入阻塞状态，所以，执行sleep()方法的线程在指定的时间内肯定不会被执行，而yield()方法只是使当前线程重新回到可执行状态，所以执行yield()方法的线程有可能在进入到可执行状态后马上又被执行。 sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常。 sleep()方法和wait()方法的区别？相同点： wait()方法和sleep()方法都可以使得线程进入到阻塞状态。 wait()和sleep()方法都是可中断方法，被中断后都会收到中断异常。 不同点： wait()是Object的方法，sleep()是Thread的方法。 wait()必须在同步方法中进行，sleep()方法不需要。 线程在同步方法中执行sleep()方法，不会释放monitor的锁，而wait()方法会释放monitor的锁。 sleep()方法在短暂的休眠之后会主动退出阻塞，而wait()方法在没有指定wait时间的情况下需要被其他线程中断才可以退出阻塞。 wait()方法一般在循环块中使用还是if块中使用？wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。 为什么wait()，notify()和notifyAll()必须在同步方法或者同步块中被调用？因为wait()暂停的是持有锁的对象，notify()或notifyAll()唤醒的是等待锁的对象。所以wait()、notify()、notifyAll()都需要线程持有锁的对象，进而需要在同步方法或者同步块中被调用。 为什么Thread类的sleep和yield方法是静态的？如果sleep和yield是静态方法，那么不管哪个线程，只要一调用就把自己给sleep、yield了。 如果sleep和yield是实例方法，一个线程可以获取其他线程对象的引用，然后通过引用调要其他线程的sleep和yield方法，让其他线程让出CPU使用权。","categories":[{"name":"并发","slug":"并发","permalink":"http://example.com/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"死锁定义及发生的条件","slug":"操作系统/死锁定义及发生的条件","date":"2023-03-08T07:20:27.984Z","updated":"2023-03-08T09:38:16.960Z","comments":true,"path":"2023/03/08/操作系统/死锁定义及发生的条件/","link":"","permalink":"http://example.com/2023/03/08/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%AD%BB%E9%94%81%E5%AE%9A%E4%B9%89%E5%8F%8A%E5%8F%91%E7%94%9F%E7%9A%84%E6%9D%A1%E4%BB%B6/","excerpt":"","text":"死锁定义及发生的条件死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。 死锁只有同时满足以下四个条件才会发生： 互斥条件； 持有并等待条件； 不可剥夺条件； 环路等待条件； 互斥条件互斥条件是指多个线程不能同时使用同一个资源。 持有并等待条件持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。 不可剥夺条件不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。 环路等待条件环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。 比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。 避免死锁问题的发生那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。 那什么是资源有序分配法呢？ 线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。 我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。 我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。 所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"}]},{"title":"JVM内存结构","slug":"JVM/JVM内存结构","date":"2023-03-07T12:51:50.993Z","updated":"2023-03-08T06:46:38.934Z","comments":true,"path":"2023/03/07/JVM/JVM内存结构/","link":"","permalink":"http://example.com/2023/03/07/JVM/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"JVM内存结构 程序计数器1）定义Program Counter Register 程序计数器（寄存器）作用：是记录下一条 jvm 指令的执行地址行号。特点： 是线程私有的 不会存在内存溢出 2）作用 解释器会解释指令为机器码交给 cpu 执行，程序计数器会记录下一条指令的地址行号，这样下一次解释器会从程序计数器拿到指令然后进行解释执行。 多线程的环境下，如果两个线程发生了上下文切换，那么程序计数器会记录线程下一行指令的地址行号，以便于接着往下执行。 虚拟机栈1）定义 每个线程运行需要的内存空间，称为虚拟机栈 每个栈由多个栈帧（Frame）组成，对应着每次调用方法时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的方法 垃圾回收是否涉及栈内存？不会。栈内存是方法调用产生的，方法调用结束后会弹出栈。 栈内存分配越大越好吗？不是。因为物理内存是一定的，栈内存越大，可以支持更多的递归调用，但是可执行的线程数就会越少。 方法呢的局部变量是否线程安全如果方法内部的变量没有逃离方法的作用访问，它是线程安全的如果是局部变量引用了对象，并逃离了方法的访问，那就要考虑线程安全问题。 2）栈内存溢出栈帧过大、过多、或者第三方类库操作，都有可能造成栈内存溢出 java.lang.stackOverflowError ，使用 -Xss256k 指定栈内存大小！ 3）线程运行诊断案例一：cpu 占用过多解决方法：Linux 环境下运行某些程序的时候，可能导致 CPU 的占用过高，这时需要定位占用 CPU 过高的线程 top 命令，查看是哪个进程占用 CPU 过高ps H -eo pid, tid（线程id）, %cpu | grep 刚才通过 top 查到的进程号 通过 ps 命令进一步查看是哪个线程占用 CPU 过高jstack 进程 id 通过查看进程中的线程的 nid ，刚才通过 ps 命令看到的 tid 来对比定位，注意 jstack 查找出的线程 id 是 16 进制的，需要转换。 本地方法栈一些带有 native 关键字的方法就是需要 JAVA 去调用本地的C或者C++方法，因为 JAVA 有时候没法直接和操作系统底层交互，所以需要用到本地方法栈，服务于带 native 关键字的方法。 堆1）定义Heap 堆 通过new关键字创建的对象都会被放在堆内存 特点 它是线程共享，堆内存中的对象都需要考虑线程安全问题 有垃圾回收机制 2）堆内存溢出java.lang.OutofMemoryError ：java heap space. 堆内存溢出可以使用 -Xmx8m 来指定堆内存大小。 2）堆内存诊断 jps 工具查看当前系统中有哪些 java 进程 jmap 工具查看堆内存占用情况 jmap - heap 进程id jconsole 工具图形界面的，多功能的监测工具，可以连续监测 jvisualvm 工具 方法区1）定义Java 虚拟机有一个在所有 Java 虚拟机线程之间共享的方法区域。方法区域类似于用于传统语言的编译代码的存储区域，或者类似于操作系统进程中的“文本”段。它存储每个类的结构，例如运行时常量池、字段和方法数据，以及方法和构造函数的代码，包括特殊方法，用于类和实例初始化以及接口初始化方法区域是在虚拟机启动时创建的。尽管方法区域在逻辑上是堆的一部分，但简单的实现可能不会选择垃圾收集或压缩它。此规范不强制指定方法区的位置或用于管理已编译代码的策略。方法区域可以具有固定的大小，或者可以根据计算的需要进行扩展，并且如果不需要更大的方法区域，则可以收缩。方法区域的内存不需要是连续的！ 2）组成Hotspot 虚拟机 jdk1.6 1.7 1.8 内存结构图 3）方法区内存溢出 1.8 之前会导致永久代内存溢出 使用 -XX:MaxPermSize=8m 指定永久代内存大小 1.8 之后会导致元空间内存溢出 使用 -XX:MaxMetaspaceSize=8m 指定元空间大小 4）运行时常量池二进制字节码包含（类的基本信息，常量池，类方法定义，包含了虚拟机的指令）首先看看常量池是什么，编译如下代码： 123456public class Test { public static void main(String[] args) { System.out.println(\"Hello World!\"); }} 然后使用 javap -v Test.class 命令反编译查看结果。 每条指令都会对应常量池表中一个地址，常量池表中的地址可能对应着一个类名、方法名、参数类型等信息。 常量池：就是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息运行时常量池：常量池是 *.class 文件中的，当该类被加载以后，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实地址 5）StringTable 常量池中的字符串仅是符号，只有在被用到时才会转化为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是StringBuilder 字符串常量拼接的原理是编译器优化 可以使用intern方法，主动将串池中还没有的字符串对象放入串池中 intern方法 1.8调用字符串对象的 intern 方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，则放入成功 如果有该字符串对象，则放入失败无论放入是否成功，都会返回串池中的字符串对象 注意：此时如果调用 intern 方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象 12345678910111213public class StringTable { public static void main(String[] args) { String s1 = \"a\"; String s2 = \"b\"; String s3 = s1 + s2; String s4 = new String(\"a\") + new String(\"b\"); String s5 = \"ab\"; String s6 = s3.intern(); System.out.println(s3 == s4); // false System.out.println(s5 == s3); // false System.out.println(s6 == s5); // true }} 12345678910111213public class Main { public static void main(String[] args) { // \"a\" \"b\" 被放入串池中，str 则存在于堆内存之中 String str = new String(\"a\") + new String(\"b\"); // 调用 str 的 intern 方法，这时串池中没有 \"ab\" ，则会将该字符串对象放入到串池中，此时堆内存与串池中的 \"ab\" 是同一个对象 String st2 = str.intern(); // 给 str3 赋值，因为此时串池中已有 \"ab\" ，则直接将串池中的内容返回 String str3 = \"ab\"; // 因为堆内存与串池中的 \"ab\" 是同一个对象，所以以下两条语句打印的都为 true System.out.println(str == st2); // true System.out.println(str == str3); // true }} 1234567891011121314public class Main { public static void main(String[] args) { // 此处创建字符串对象 \"ab\" ，因为串池中还没有 \"ab\" ，所以将其放入串池中 String str3 = \"ab\"; // \"a\" \"b\" 被放入串池中，str 则存在于堆内存之中 String str = new String(\"a\") + new String(\"b\"); // 此时因为在创建 str3 时，\"ab\" 已存在与串池中，所以放入失败，但是会返回串池中的 \"ab\" String str2 = str.intern(); System.out.println(str == str2); // false System.out.println(str == str3); // false System.out.println(str2 == str3); // true }} 6）StringTable 的位置jdk1.6 StringTable 位置是在永久代中，1.8 StringTable 位置是在堆中。 7）StringTable 垃圾回收-Xmx10m 指定堆内存大小-XX:+PrintStringTableStatistics 打印字符串常量池信息-XX:+PrintGCDetails-verbose:gc 打印 gc 的次数，耗费时间等信息 8）StringTable 性能调优 因为StringTable是由HashTable实现的，所以可以适当增加HashTable桶的个数，来减少字符串放入串池所需要的时间 1-XX:StringTableSize=桶个数（最少设置为 1009 以上） 考虑是否需要将字符串对象入池可以通过 intern 方法减少重复入池 直接内存1）定义Direct Memory 常见于 NIO 操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不受 JVM 内存回收管理 2）使用直接内存的好处文件读写流程： 因为 java 不能直接操作文件管理，需要切换到内核态，使用本地方法进行操作，然后读取磁盘文件，会在系统内存中创建一个缓冲区，将数据读到系统缓冲区， 然后在将系统缓冲区数据，复制到 java 堆内存中。缺点是数据存储了两份，在系统内存中有一份，java 堆中有一份，造成了不必要的复制。 使用了 DirectBuffer 文件读取流程 直接内存是操作系统和 Java 代码都可以访问的一块区域，无需将代码从系统内存复制到 Java 堆内存，从而提高了效率。 3）直接内存的回收机制总结 使用了 Unsafe 类来完成直接内存的分配回收，回收需要主动调用freeMemory 方法 ByteBuffer 的实现内部使用了 Cleaner（虚引用）来检测 ByteBuffer 。一旦ByteBuffer 被垃圾回收，那么会由 ReferenceHandler（守护线程） 来调用 Cleaner 的 clean 方法调用 freeMemory 来释放内存 注意： 一般用 jvm 调优时，会加上下面的参数： 1-XX:+DisableExplicitGC // 静止显示的 GC 意思就是禁止我们手动的 GC，比如手动 System.gc() 无效，它是一种 full gc，会回收新生代、老年代，会造成程序执行的时间比较长。所以我们就通过 unsafe 对象调用 freeMemory 的方式释放内存。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"进程间的通信方式","slug":"操作系统/进程间的通信方式","date":"2023-03-06T12:28:36.396Z","updated":"2023-03-08T09:37:55.532Z","comments":true,"path":"2023/03/06/操作系统/进程间的通信方式/","link":"","permalink":"http://example.com/2023/03/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/","excerpt":"","text":"进程间的通信方式管道分为匿名管道和命名管道 管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。 管道这种通信方式效率低，不适合进程间频繁地交换数据。它的好处，就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。 所谓的管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。 对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。 对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。 同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。 消息队列管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。对于这个问题，消息队列的通信模式就可以解决。 消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。 存在不足的地方有两点，一是通信不及时，二是附件也有大小限制。 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。 消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。 共享内存消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。 共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。 信号量为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 信号量表示资源的数量，控制信号量的方式有两种原子操作： 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程； 信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。 信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。 需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。 信号上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。 进程有三种方式响应信号 1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。 2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。 Socket前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。 Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"并发类问题","slug":"并发/并发类问题","date":"2023-02-26T13:03:50.024Z","updated":"2023-03-11T09:17:52.832Z","comments":true,"path":"2023/02/26/并发/并发类问题/","link":"","permalink":"http://example.com/2023/02/26/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E7%B1%BB%E9%97%AE%E9%A2%98/","excerpt":"","text":"并发类问题线程状态六种状态及转换 新建 当一个线程对象被创建，但还未调用 start 方法时处于新建状态 此时未与操作系统底层线程关联 可运行 调用了 start 方法，就会由新建进入可运行 此时与底层线程关联，由操作系统调度执行 终结 线程内代码已经执行完毕，由可运行进入终结 此时会取消与底层线程关联 阻塞 当获取锁失败后，由可运行进入 Monitor 的阻塞队列阻塞，此时不占用 cpu 时间 当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的阻塞线程，唤醒后的线程进入可运行状态 等待 当获取锁成功后，但由于条件不满足，调用了 wait() 方法，此时从可运行状态释放锁进入 Monitor 等待集合等待，同样不占用 cpu 时间 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的等待线程，恢复为可运行状态 有时限等待 当获取锁成功后，但由于条件不满足，调用了 wait(long) 方法，此时从可运行状态释放锁进入 Monitor 等待集合进行有时限等待，同样不占用 cpu 时间 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的有时限等待线程，恢复为可运行状态，并重新去竞争锁 如果等待超时，也会从有时限等待状态恢复为可运行状态，并重新去竞争锁 还有一种情况是调用 sleep(long) 方法也会从可运行状态进入有时限等待状态，但与 Monitor 无关，不需要主动唤醒，超时时间到自然恢复为可运行状态 其它情况（了解） 可以用 interrupt() 方法打断等待、有时限等待的线程，让它们恢复为可运行状态 park，unpark 等方法也可以让线程等待和唤醒 五种状态五种状态的说法来自于操作系统层面的划分 运行态：分到 cpu 时间，能真正执行线程内代码的 就绪态：有资格分到 cpu 时间，但还未轮到它的 阻塞态：没资格分到 cpu 时间的 涵盖了 java 状态中提到的阻塞、等待、有时限等待 多出了阻塞 I/O，指线程在调用阻塞 I/O 时，实际活由 I/O 设备完成，此时线程无事可做，只能干等 新建与终结态：与 java 中同名状态类似 线程池七大参数 corePoolSize 核心线程数目 - 池中会保留的最多线程数 maximumPoolSize 最大线程数目 - 核心线程+救急线程的最大数目 keepAliveTime 生存时间 - 救急线程的生存时间，生存时间内没有新任务，此线程资源会释放 unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等 workQueue 阻塞队列 - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务 threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等 handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略 抛异常 java.util.concurrent.ThreadPoolExecutor.AbortPolicy 由调用者执行任务 java.util.concurrent.ThreadPoolExecutor.CallerRunsPolicy 丢弃任务 java.util.concurrent.ThreadPoolExecutor.DiscardPolicy 丢弃最早排队任务 java.util.concurrent.ThreadPoolExecutor.DiscardOldestPolicy wait vs sleep共同点 wait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态 不同点 语法使用不同 wait 方法必须配合 synchronized 一起使用，不然在运行时就会抛出 IllegalMonitorStateException 的异常 方法归属不同 sleep(long) 是 Thread 的静态方法 而 wait()，wait(long) 都是 Object 的成员方法，每个对象都有 醒来时机不同 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来 sleep 方法具有主动唤醒功能，而不传递任何参数的 wait 方法只能被动的被唤醒。 它们都可以被打断唤醒 锁特性不同（重点） wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制(同第一条) wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用） 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了） lock vs synchronized三个层面 不同点 语法层面 synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现 Lock 是接口，源码由 jdk 提供，用 java 语言实现 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁 功能层面 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能 Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量 Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock 性能层面 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖 在竞争激烈时，Lock 的实现通常会提供更好的性能 公平锁 公平锁的公平体现 已经处在阻塞队列中的线程（不考虑超时）始终都是公平的，先进先出 公平锁是指未处于阻塞队列中的线程来争抢锁，如果队列不为空，则老实到队尾等待 非公平锁是指未处于阻塞队列中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的 公平锁会降低吞吐量，一般不用 条件变量 ReentrantLock 中的条件变量功能类似于普通 synchronized 的 wait，notify，用在当线程获得锁后，发现条件不满足时，临时等待的链表结构 与 synchronized 的等待集合不同之处在于，ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制 volatile 掌握线程安全要考虑的三个问题 掌握 volatile 能解决哪些问题 原子性 起因：多线程下，不同线程的指令发生了交错导致的共享变量的读写混乱 解决：用悲观锁或乐观锁解决，volatile 并不能解决原子性 可见性 起因：由于编译器优化、或缓存优化、或 CPU 指令重排序优化导致的对共享变量所做的修改另外的线程看不到 解决：用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见 有序性 起因：由于编译器优化、或缓存优化、或 CPU 指令重排序优化导致指令的实际执行顺序与编写顺序不一致 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果 注意： volatile 变量写加的屏障是阻止上方其它写操作越过屏障排到 volatile 变量写之下 volatile 变量读加的屏障是阻止下方其它读操作越过屏障排到 volatile 变量读之上 volatile 读写加入的屏障只能防止同一线程内的指令重排 Hashtable vs ConcurrentHashMap Hashtable 与 ConcurrentHashMap 的区别 ConcurrentHashMap 在不同版本的实现区别 Hashtable 对比 ConcurrentHashMap Hashtable 与 ConcurrentHashMap 都是线程安全的 Map 集合 Hashtable 并发度低，整个 Hashtable 对应一把锁，同一时刻，只能有一个线程操作它 ConcurrentHashMap 并发度高，整个 ConcurrentHashMap 对应多把锁，只要线程访问的是不同锁，那么不会冲突 ConcurrentHashMap 1.7 数据结构：Segment(大数组) + HashEntry(小数组) + 链表，每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问。Segment 数组不能扩容，意味着并发度在 ConcurrentHashMap 创建时就固定了 索引计算 假设大数组长度是 $2^m$，key 在大数组内的索引是 key 的二次 hash 值的高 m 位 假设小数组长度是 $2^n$，key 在小数组内的索引是 key 的二次 hash 值的低 n 位 扩容：每个小数组的扩容相对独立，小数组在超过扩容因子时会触发扩容，每次扩容翻倍 Segment[0] 原型：首次创建其它小数组时，会以此原型为依据，数组长度，扩容因子都会以原型为准 ConcurrentHashMap 1.8 数据结构：Node 数组 + 链表或红黑树，数组的每个头节点作为锁，如果多个线程访问的头节点不同，则不会冲突。首次生成头节点时如果发生竞争，利用 cas 而非 syncronized，进一步提升性能 并发度：Node 数组有多大，并发度就有多大，与 1.7 不同，Node 数组可以扩容 扩容条件：Node 数组满 3/4 时就会扩容 扩容单位：以链表为单位从后向前迁移链表，迁移完成的将旧数组头节点替换为 ForwardingNode 扩容时并发 get 根据是否为 ForwardingNode 来决定是在新数组查找还是在旧数组查找，不会阻塞 如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变 如果链表最后几个元素扩容后索引不变，则节点无需复制 扩容时并发 put 如果 put 的线程与扩容线程操作的链表是同一个，put 线程会阻塞 如果 put 的线程操作的链表还未迁移完成，即头节点不是 ForwardingNode，则可以并发执行 如果 put 的线程操作的链表已经迁移完成，即头结点是 ForwardingNode，则可以协助扩容 与 1.7 相比是懒惰初始化 capacity 代表预估的元素个数，capacity / factory 来计算出初始数组大小，需要贴近 $2^n$ loadFactor 只在计算初始数组大小时被使用，之后扩容固定为 3/4 超过树化阈值时的扩容问题，如果容量已经是 64，直接树化，否则在原来容量基础上做 3 轮扩容 ThreadLocal ThreadLocal 的作用与原理 ThreadLocal 的内存释放时机 作用 ThreadLocal 可以实现【资源对象】的线程隔离，让每个线程各用各的【资源对象】，避免争用引发的线程安全问题 ThreadLocal 同时实现了线程内的资源共享 原理 每个线程内有一个 ThreadLocalMap 类型的成员变量，用来存储资源对象 调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中 调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中查找关联的资源值 调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值 ThreadLocalMap 的一些特点 key 的 hash 值统一分配 初始容量 16，扩容因子 2/3，扩容容量翻倍 key 索引冲突后用开放寻址法解决冲突 弱引用 key ThreadLocalMap 中的 key 被设计为弱引用，原因如下 Thread 可能需要长时间运行（如线程池中的线程），如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存 内存释放时机 被动 GC 释放 key 仅是让 key 的内存释放，关联 value 的内存并不会释放 懒惰被动释放 value get key 时，发现是 null key，则释放其 value 内存 set key 时，会使用启发式扫描，清除临近的 null key 的 value 内存，启发次数与元素个数，是否发现 null key 有关 主动 remove 释放 key，value 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存 推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收","categories":[{"name":"并发","slug":"并发","permalink":"http://example.com/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"HashMap","slug":"基础/HashMap","date":"2023-02-23T05:36:17.271Z","updated":"2023-03-11T09:13:49.548Z","comments":true,"path":"2023/02/23/基础/HashMap/","link":"","permalink":"http://example.com/2023/02/23/%E5%9F%BA%E7%A1%80/HashMap/","excerpt":"","text":"HashMap底层数据结构，1.7与1.8有何不同？1.7数组+链表，1.8数组+（链表|红黑树） 为何要用红黑树，为何一上来不树化？红黑树用来避免DoS攻击，防止链表超长时性能下降，树化应当是偶然情况hash表的查找，更新的时间复杂度是0(1），而红黑树的查找，更新的时间复杂度是0(log2n)，TreeNode 占用空间也比普通Node的大，如非必要，尽量还是使用链表 树化阈值为何是8 hash值如果足够随机，则在hash表内按泊松分布，在负载因子0.75的情况下，长度超过8的链表出现概率是0.00000006，选择8就是为了让树化几率足够小 何时会树化树化两个条件：链表长度超过树化阈值；数组容量 &gt;=64 何时会退化为链表？退化情况1：在扩容时如果拆分树时，树元素个数&lt;=6则会退化链表，退化情况2：remove树节点时，若root、root.left、root.right、root.left.left有一个为 null，也会退化为链表 索引如何计算？计算对象的hashCode()，再进行调用HashMap的hash()方法进行二次哈希，最后&amp;(capacity-1)得到索引 hashCode都有了，为何还要提供hash(）方法？二次hash(）是为了综合高位数据，让哈希分布更为均匀 数组容量为何是2的n次幂？计算索引时，如果是2的n次幂可以使用位与运算代替取模，效率更高；扩容时 hash&amp;oldCap==0的元素留在原来位置，否则新位置=旧位置+oldCap 都是为了配合容量为2的n次幂时的优化手段，例如Hashtable的容量就不是2的n次幂，并不能说哪种设计更优，应该是设计者综合了各种因素，最终选择了使用2的n次幂作为容量 介绍一下put方法流程，1.7与1.8有何不同?1.HashMap是懒惰创建数组的，首次使用才创建数组 2.计算索引(桶下标) 3.如果桶下标还没人占用，创建Node占位返回 4.如果桶下标已经有人占用 ​ 已经是TreeNode走红黑树的添加或更新逻辑 ​ 是普通Node，走链表的添加或更新逻辑，如果链表长度超过树化阈值，走树化逻辑 5.返回前检查容量是否超过阈值，一旦超过进行扩容 6.不同 ​ 链表插入节点时，1.7是头插法，1.8是尾插法 ​ 1.7是大于等于阈值且没有空位时才扩容，而1.8是大于阈值就扩容 1.8在扩容计算Node索引时，会优化加载因子为何默认是0.75f在空间占用与查询时间之间取得较好的权衡 大于这个值，空间节省了，但链表就会比较长影响性能 小于这个值，冲突减少了，但扩容就会更频繁，空间占用多 多线程下会有啥问题?扩容死链（1.7) 数据错乱（1.7，1.8) key能否为null，作为key的对象有什么要求?1.HashMap 的 key可以为null，但 Map 的其他实现则不然 2.作为key的对象，必须实现 hashCode和equals，并且 key的内容不能修改（不可变) String对象的 hashCode()如何设计的，为啥每次乘的是31目标是达到较为均匀的散列效果，每个字符串的hashCode足够独特 1.字符串中的每个字符都可以表现为一个数字，称为Sj，其中i的范围是0~n - 1 2.散列公式为:So* 31n-1+ S1* 31n-2+ … Si * 31n-1-i + …Sn-1 * 310 3.31代入公式有较好的散列特性，并且31*h可以被优化为 ​ 即32 * h - h ​ 即25 * h - h ​ 即h &lt;&lt; 5 - h","categories":[{"name":"基础","slug":"基础","permalink":"http://example.com/categories/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"}]},{"title":"ArrayList的扩容规则,FailFast与FailSafe","slug":"基础/ArrayList的扩容规则,FailFast与FailSafe","date":"2023-02-21T12:43:04.840Z","updated":"2023-03-11T09:15:22.250Z","comments":true,"path":"2023/02/21/基础/ArrayList的扩容规则,FailFast与FailSafe/","link":"","permalink":"http://example.com/2023/02/21/%E5%9F%BA%E7%A1%80/ArrayList%E7%9A%84%E6%89%A9%E5%AE%B9%E8%A7%84%E5%88%99,FailFast%E4%B8%8EFailSafe/","excerpt":"","text":"ArrayList的扩容规则,FailFast与FailSafeArrayList的扩容规则 ArrayList无参构造源码 创建时是一个为空的数组，第一次添加元素的时候才分配容量为10的内存 12345private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;} ArrayList有参构造源码 12345678910public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); }} add()扩容不是直接乘以1.5，先用位运算&gt;&gt;1，然后加上本身 123456&gt; 15*1.5&lt; 22.5&gt; 15&gt;&gt;1&lt; 7&gt; 7+15&lt; 22 FailFast与FailSafe FailFast:ArrayList源码 123456789101112131415161718192021222324252627282930313233343536373839404142private class Itr implements Iterator&lt;E&gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() { return cursor != size; } @SuppressWarnings(\"unchecked\") public E next() { checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); }} checkForComodification这个方法，它是在modCount != expectedModCount的时候抛出的异常，而在next方法中第一句就是checkForComodification，所以遍历集合才会可能抛出并发修改异常。 而且，在创建一个迭代器后，expectedModCount的初始值就是modCount了，对集合修改只会改变modCount，expectedModCount只会在迭代器的remove方法中被修改为modCountt ArrayList的其他方法 remove： 1234567891011121314151617181920212223242526public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;}private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work} fastRemove中对modCount++了，所以后面modCount会和expectedModCount不相等，进而抛出并发修改异常。 add： 12345public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;} 在ensureCapacityInternal方法里对modCount++了。 set： 1234567public E set(int index, E element) { rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;} 可以看出set方法并没有对modCount++，所以对集合的某个元素进行修改并不会fail-fast FailSafe:ArrayList使用fail-fast机制自然是因为它增强了数据的安全性。但在某些场景，我们可能想避免fail-fast机制抛出的异常，这时我们就要将ArrayList替换为使用fail-safe机制的CopyOnWriteArrayList。 写时复制，简单理解就是，当我们往一个容器添加元素的时候，先将当前容器复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 123456789101112131415161718public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); }}final void setArray(Object[] a) { array = a;} 添加的时候是需要加锁的，否则多线程写的时候会复制出N个副本出来…… 读的时候不需要加锁，如果读的时候有多个线程正在向ArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList。 CopyOnWrite的应用场景：CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。 CopyOnWrite的缺点：CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下： 如何避免fail-fast抛异常？1.如果非要在遍历的时候修改集合，那么建议用迭代器的remove等方法，而不是用集合的remove等方法。 2.如果是并发的环境，那还要对Iterator对象加锁；也可以直接使用Collections.synchronizedList。 3.CopyOnWriteArrayList（采用fail-safe）","categories":[{"name":"基础","slug":"基础","permalink":"http://example.com/categories/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://example.com/tags/ArrayList/"},{"name":"迭代器","slug":"迭代器","permalink":"http://example.com/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"},{"name":"CopyOnWrite","slug":"CopyOnWrite","permalink":"http://example.com/tags/CopyOnWrite/"}]},{"title":"位运算技巧","slug":"算法/位运算/位运算技巧","date":"2023-02-05T05:18:38.235Z","updated":"2023-02-05T05:20:41.243Z","comments":true,"path":"2023/02/05/算法/位运算/位运算技巧/","link":"","permalink":"http://example.com/2023/02/05/%E7%AE%97%E6%B3%95/%E4%BD%8D%E8%BF%90%E7%AE%97/%E4%BD%8D%E8%BF%90%E7%AE%97%E6%8A%80%E5%B7%A7/","excerpt":"","text":"位运算技巧位操作符 &amp; 与运算 两个位都是 1 时，结果才为 1，否则为 0，如 1 0 0 1 1&amp; 1 1 0 0 1------------------------------ 1 0 0 0 1 | 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 1 0 0 1 1| 1 1 0 0 1------------------------------ 1 1 0 1 1 ^ 异或运算，两个位相同则为 0，不同则为 1，如 1 0 0 1 1^ 1 1 0 0 1----------------------------- 0 1 0 1 0 ~ 取反运算，0 则变为 1，1 则变为 0，如~ 1 0 0 1 1----------------------------- 0 1 1 0 0 &lt;&lt; 左移运算，向左进行移位操作，高位丢弃，低位补 0，如 1234int a = 8;a &lt;&lt; 3;移位前：0000 0000 0000 0000 0000 0000 0000 1000移位后：0000 0000 0000 0000 0000 0000 0100 0000 &gt;&gt; 右移运算，向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位， 无符号右移：&gt;&gt;&gt;，将二进制向右移动1位，最左边用0填补如 123456789unsigned int a = 8;a &gt;&gt; 3;移位前：0000 0000 0000 0000 0000 0000 0000 1000移位后：0000 0000 0000 0000 0000 0000 0000 0001int a = -8;a &gt;&gt; 3;移位前：1111 1111 1111 1111 1111 1111 1111 1000移位前：1111 1111 1111 1111 1111 1111 1111 1111 位操作1. 位操作实现乘除法 数 a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2 123int a = 2;a &gt;&gt; 1; ---&gt; 1a &lt;&lt; 1; ---&gt; 4 2. 位操作交货两数 位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高 12345678910111213//普通操作void swap(int &amp;a, int &amp;b) { a = a + b; b = a - b; a = a - b;}//位与操作void swap(int &amp;a, int &amp;b) { a ^= b; b ^= a; a ^= b;} 位与操作解释：第一步：a ^= b —&gt; a = (a^b); 第二步：b ^= a —&gt; b = b^(a^b) —&gt; b = (b^b)^a = a 第三步：a ^= b —&gt; a = (a^b)^a = (a^a)^b = b 3. 位操作判断奇偶数 只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数。 123if(0 == (a &amp; 1)) { //偶数} 4. 位操作交换符号 交换符号将正数变成负数，负数变成正数 123int reversal(int a) { return ~a + 1;} 整数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数 5. 位操作求绝对值 整数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作 1234int abs(int a) { int i = a &gt;&gt; 31; return i == 0 ? a : (~a + 1);} 上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1) 1234int abs2(int a) { int i = a &gt;&gt; 31; return ((a^i) - i);} 6.利用或操作 | 和空格将英文字符转换为小写12('a' | ' ') = 'a'('A' | ' ') = 'a' 7.利用与操作 &amp; 和下划线将英文字符转换为大写12('b' &amp; '_') = 'B'('B' &amp; '_') = 'B' 8.利用异或操作 ^ 和空格进行英文字符大小写互换12('d' ^ ' ') = 'D'('D' ^ ' ') = 'd' 9.判断两个数是否异号12345int x = -1, y = 2;boolean f = ((x ^ y) &lt; 0); // trueint x = 3, y = 2;boolean f = ((x ^ y) &lt; 0); // false 10.加一123int n = 1;n = -~n;// 现在 n = 2 11.减一123int n = 2;n = ~-n;// 现在 n = 1 12.n &amp; (n-1)这个操作是算法中常见的，作用是消除数字 n 的二进制表示中的最后一个 1","categories":[{"name":"日常","slug":"日常","permalink":"http://example.com/categories/%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"}]},{"title":"位运算","slug":"算法/位运算/位运算","date":"2023-02-05T04:13:36.269Z","updated":"2023-02-06T05:07:37.285Z","comments":true,"path":"2023/02/05/算法/位运算/位运算/","link":"","permalink":"http://example.com/2023/02/05/%E7%AE%97%E6%B3%95/%E4%BD%8D%E8%BF%90%E7%AE%97/%E4%BD%8D%E8%BF%90%E7%AE%97/","excerpt":"","text":"位运算191.位1的个数 剑指 Offer 56 - I. 数组中数字出现的次数 剑指 Offer 56 - II. 数组中数字出现的次数 II 剑指 Offer 65. 不用加减乘除做加法 231.2 的幂 268.丢失的数字 191.位1的个数12345678910public class Solution { public int hammingWeight(int n) { int sum = 0; for (int i = 0; i &lt; 32; ++i) { sum += (n &amp; 1); n &gt;&gt;= 1; } return sum; }} 剑指 Offer 56 - I. 数组中数字出现的次数 123456789101112131415161718class Solution { public int[] singleNumbers(int[] nums) { int a = 0; for (int i: nums) { a ^= i; } int m = 1; while ((a &amp; m) == 0) { m &lt;&lt;= 1; } int x = 0,y = 0; for (int i: nums) { if ((i &amp; m) == 0) x ^= i; else y ^= i; } return new int[] {x,y}; }} 剑指 Offer 56 - II. 数组中数字出现的次数 II 123456789101112131415class Solution { public int singleNumber(int[] nums) { int result = 0; for (int i = 0; i &lt; 32; ++i) { int count = 0; for (int j = 0; j &lt; nums.length; ++j) { count += (nums[j] &gt;&gt;&gt; i) &amp; 1; } if (count % 3 == 1) { result |= 1 &lt;&lt; i; } } return result; }} 剑指 Offer 65. 不用加减乘除做加法 12345678910class Solution { public int add(int a, int b) { while (b != 0) { int c = (a &amp; b) &lt;&lt; 1; a ^= b; b = c; } return a; }} 231.2 的幂12345class Solution { public boolean isPowerOfTwo(int n) { return n &gt; 0 &amp;&amp; (n &amp; (n - 1)) == 0; }} 268.丢失的数字123456789101112class Solution { public int missingNumber(int[] nums) { int ans = 0; for (int i = 0; i &lt; nums.length + 1; ++i) { ans ^= i; } for (int i = 0; i &lt; nums.length; ++i) { ans ^= nums[i]; } return ans; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"十大排序算法前五种","slug":"算法/十大排序算法前五种","date":"2023-01-05T07:22:39.211Z","updated":"2023-01-05T07:23:54.086Z","comments":true,"path":"2023/01/05/算法/十大排序算法前五种/","link":"","permalink":"http://example.com/2023/01/05/%E7%AE%97%E6%B3%95/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%89%8D%E4%BA%94%E7%A7%8D/","excerpt":"","text":"十大排序算法前五种 冒泡排序（Bubble Sort)123456789101112public static int[] bubbleSort(int[] arr) { for (int i = 0; i &lt; arr.length; i++) { for (int j = 0; j &lt; arr.length - 1 - i; j++) { if (arr[j + 1] &lt; arr[j]) { int temp = arr[j + 1]; arr[j + 1] = arr[j]; arr[j] = temp; } } } return arr; } 选择排序（Selection Sort）123456789101112131415public static int[] selectionSort(int[] arr) { for (int i = 0; i &lt; arr.length; i++) { int minIndex = i; for (int j = i; j &lt; arr.length; j++) { if (arr[j] &lt; arr[minIndex]) minIndex = j; } if (i != minIndex) { int temp = arr[minIndex]; arr[minIndex] = arr[i]; arr[i] = temp; } } return arr;} 插入排序（Insertion Sort）123456789101112public static int[] insertionSort(int[] arr) { for (int i = 0; i &lt; arr.length - 1; ++i) { int current = arr[i + 1]; int preIndex = i; while (preIndex &gt;= 0 &amp;&amp; current &lt; arr[preIndex]) { arr[preIndex + 1] = arr[preIndex]; preIndex --; } arr[preIndex + 1] = current; } return arr;} 希尔排序（Shell Sort）1234567891011121314151617public static int[] shellSort(int[] arr) { int len = arr.length; int temp, gap = len / 2; while (gap &gt; 0) { for (int i = gap; i &lt; len; i++) { temp = arr[i]; int preIndex = i - gap; while (preIndex &gt;= 0 &amp;&amp; arr[preIndex] &gt; temp) { arr[preIndex + gap] = arr[preIndex]; preIndex -= gap; } arr[preIndex + gap] = temp; } gap /= 2; } return arr;} 归并排序（Merge Sort）1234567891011121314151617181920212223public static int[] mergeSort(int[] arr) { if (arr.length &lt; 2) return arr; int mid = arr.length / 2; int[] left = Arrays.copyOfRange(arr, 0, mid); int[] right = Arrays.copyOfRange(arr, mid, arr.length); return merge(mergeSort(left), mergeSort(right));}public static int[] merge(int[] left, int[] right) { int[] result = new int[left.length + right.length]; for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) { if (i &gt;= left.length) result[index] = right[j++]; else if (j &gt;= right.length) result[index] = left[i++]; else if (left[i] &gt; right[j]) result[index] = right[j++]; else result[index] = left[i++]; } return result;}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"不同路径问题","slug":"算法/动态规划/不同路径问题","date":"2023-01-02T06:18:23.358Z","updated":"2023-01-02T06:19:18.244Z","comments":true,"path":"2023/01/02/算法/动态规划/不同路径问题/","link":"","permalink":"http://example.com/2023/01/02/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"不同路径问题62.不同路径 63.不同路径 II 62.不同路径123456789101112131415161718class Solution { public int uniquePaths(int m, int n) { int[][] dp = new int[m][n]; for(int i = 0; i &lt; dp.length; ++i) { dp[i][0] = 1; } for(int i = 0; i &lt; dp[0].length; ++i) { dp[0][i] = 1; } for(int i = 1; i &lt; dp.length; ++i) { for(int j = 1; j &lt; dp[i].length; ++j) { dp[i][j] = dp[i - 1][j] + dp[i][j - 1]; } } return dp[m-1][n-1]; }} 63.不同路径 II12345678910111213141516171819202122232425class Solution { public int uniquePathsWithObstacles(int[][] obstacleGrid) { if (obstacleGrid == null || obstacleGrid.length == 0) { return 0; } int m = obstacleGrid.length, n = obstacleGrid[0].length; int[][] dp = new int[m][n]; for (int i = 0; i &lt; m &amp;&amp; obstacleGrid[i][0] == 0; i++) { dp[i][0] = 1; } for (int j = 0; j &lt; n &amp;&amp; obstacleGrid[0][j] == 0; j++) { dp[0][j] = 1; } for (int i = 1; i &lt; m; i++) { for (int j = 1; j &lt; n; j++) { if (obstacleGrid[i][j] == 0) { dp[i][j] = dp[i - 1][j] + dp[i][j - 1]; } } } return dp[m - 1][n - 1]; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"矩阵","slug":"矩阵","permalink":"http://example.com/tags/%E7%9F%A9%E9%98%B5/"}]},{"title":"动态规划入门题","slug":"算法/动态规划/动态规划入门题","date":"2023-01-02T03:34:42.701Z","updated":"2023-01-02T03:36:45.462Z","comments":true,"path":"2023/01/02/算法/动态规划/动态规划入门题/","link":"","permalink":"http://example.com/2023/01/02/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%85%A5%E9%97%A8%E9%A2%98/","excerpt":"","text":"动态规划入门题509.斐波那契数 70.爬楼梯 746.使用最小花费爬楼梯 509.斐波那契数用常量123456789101112class Solution { public int fib(int n) { if (n &lt; 2) return n; int a = 0,b = 1,c = 0; for (int i = 1; i &lt; n; ++i) { c = a + b; a = b; b = c; } return c; }} 用数组123456789101112class Solution { public int fib(int n) { if(n &lt; 2) return n; int[] dp = new int[n + 1]; dp[0] = 0; dp[1] = 1; for(int i = 2; i &lt;= n; ++i) { dp[i] = dp[i - 1] + dp[i - 2]; } return dp[n]; }} 70.爬楼梯用常量123456789101112class Solution { public int climbStairs(int n) { if (n &lt; 3) return n; int a = 1,b = 2,c = 0; for (int i = 3; i &lt;= n; ++i) { c = a + b; a = b; b = c; } return c; }} 用数组123456789101112class Solution { public int climbStairs(int n) { if (n &lt; 3) return n; int[] dp = new int[n]; dp[0] = 1; dp[1] = 2; for (int i = 2; i &lt; n; ++i) { dp[i] = dp[i - 1] + dp[i - 2]; } return dp[n - 1]; }} 746.使用最小花费爬楼梯123456789101112class Solution { public int minCostClimbingStairs(int[] cost) { int[] dp = new int[cost.length]; dp[0] = cost[0]; dp[1] = cost[1]; for(int i = 2; i &lt; cost.length; ++i) { dp[i] = Math.min(dp[i - 1],dp[i - 2]) + cost[i]; } return Math.min(dp[cost.length - 1],dp[cost.length - 2]); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"记忆化搜索","slug":"记忆化搜索","permalink":"http://example.com/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"}]},{"title":"栈与队列经典题目","slug":"算法/栈/栈与队列经典题目","date":"2023-01-01T09:31:40.673Z","updated":"2023-02-22T11:38:12.075Z","comments":true,"path":"2023/01/01/算法/栈/栈与队列经典题目/","link":"","permalink":"http://example.com/2023/01/01/%E7%AE%97%E6%B3%95/%E6%A0%88/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/","excerpt":"","text":"栈与队列经典题目20.有效的括号 1047.删除字符串中的所有相邻重复项 150.逆波兰表达式求值 239.滑动窗口最大值 347.前 K 个高频元素 20.有效的括号123456789101112131415161718class Solution { public boolean isValid(String s) { Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); for(int i = 0;i &lt; s.length();i ++){ char ch = s.charAt(i); if(ch == '('){ stack.push(')'); } else if(ch == '{'){ stack.push('}'); } else if(ch == '['){ stack.push(']'); } else if(stack.isEmpty() || stack.pop() != ch){ return false; } } return stack.isEmpty(); }} 1047.删除字符串中的所有相邻重复项栈12345678910111213141516171819class Solution { public String removeDuplicates(String s) { Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); char[] arr = s.toCharArray(); for(int i = 0;i &lt; arr.length;i ++){ if(stack.isEmpty() || stack.peek() != arr[i]){ stack.push(arr[i]); } else { stack.pop(); } } String str = \"\"; while (!stack.isEmpty()) { str = stack.pop() + str; } return str; }} StringBuilder模拟栈1234567891011121314151617class Solution { public String removeDuplicates(String s) { StringBuilder str = new StringBuilder(); int top = -1; for (int i = 0; i &lt; s.length(); ++i) { char c = s.charAt(i); if (top &gt;= 0 &amp;&amp; str.charAt(top) == c) { str.deleteCharAt(top); top --; } else { str.append(c); top ++; } } return str.toString(); }} 数组模拟栈1234567891011121314class Solution { public String removeDuplicates(String S) { char[] s = S.toCharArray(); int top = -1; for (int i = 0; i &lt; S.length(); i++) { if (top == -1 || s[top] != s[i]) { s[++top] = s[i]; } else { top--; } } return String.valueOf(s, 0, top + 1); }} 150.逆波兰表达式求值1234567891011121314151617181920212223242526272829303132333435class Solution { public int evalRPN(String[] tokens) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for(int i = 0;i &lt; tokens.length;i ++){ String s = tokens[i]; if(isNumber(s)){ int j = Integer.parseInt(s); stack.push(j); } else { int num2 = stack.pop(); int num1 = stack.pop(); switch (s) { case \"+\": stack.push(num1 + num2); break; case \"-\": stack.push(num1 - num2); break; case \"*\": stack.push(num1 * num2); break; case \"/\": stack.push(num1 / num2); break; default: } } } return stack.pop(); } public boolean isNumber(String token) { return !(\"+\".equals(token) || \"-\".equals(token) || \"*\".equals(token) || \"/\".equals(token)); }} 239.滑动窗口最大值123456789101112131415161718192021222324252627class Solution { public int[] maxSlidingWindow(int[] nums, int k) { if(nums == null || nums.length &lt; 2) return nums; // 双向队列 保存当前窗口最大值的数组位置 保证队列中数组位置的数值按从大到小排序 LinkedList&lt;Integer&gt; queue = new LinkedList(); // 结果数组 int[] result = new int[nums.length-k+1]; // 遍历nums数组 for(int i = 0;i &lt; nums.length;i++){ // 保证从大到小 如果前面数小则需要依次弹出，直至满足要求 while(!queue.isEmpty() &amp;&amp; nums[queue.peekLast()] &lt;= nums[i]){ queue.pollLast(); } // 添加当前值对应的数组下标 queue.addLast(i); // 判断当前队列中队首的值是否有效 if(queue.peek() &lt;= i-k){ queue.poll(); } // 当窗口长度为k时 保存当前窗口中最大值 if(i+1 &gt;= k){ result[i+1-k] = nums[queue.peek()]; } } return result; }} 347.前 K 个高频元素基于大顶堆实现1234567891011121314151617181920212223class Solution { public int[] topKFrequent(int[] nums, int k) { Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int num:nums){ map.put(num,map.getOrDefault(num,0)+1); } //PriorityQueue&lt;int[]&gt; pq = new PriorityQueue&lt;&gt;((pair1, pair2)-&gt;pair2[1]-pair1[1]); PriorityQueue&lt;int[]&gt; pq = new PriorityQueue&lt;int[]&gt;(new Comparator&lt;int[]&gt;() { public int compare(int[] m, int[] n) { return n[1] - m[1]; } }); for(Map.Entry&lt;Integer,Integer&gt; entry:map.entrySet()){ pq.add(new int[]{entry.getKey(),entry.getValue()}); } int[] ans = new int[k]; for(int i=0;i&lt;k;i++){ ans[i] = pq.poll()[0]; } return ans; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"},{"name":"堆(优先队列)","slug":"堆-优先队列","permalink":"http://example.com/tags/%E5%A0%86-%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"},{"name":"单调队列","slug":"单调队列","permalink":"http://example.com/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/"}]},{"title":"栈与队列的互相实现","slug":"算法/栈/栈与队列的互相实现","date":"2022-12-28T03:45:19.998Z","updated":"2022-12-28T03:47:30.446Z","comments":true,"path":"2022/12/28/算法/栈/栈与队列的互相实现/","link":"","permalink":"http://example.com/2022/12/28/%E7%AE%97%E6%B3%95/%E6%A0%88/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%E7%9A%84%E4%BA%92%E7%9B%B8%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"栈与队列的互相实现232.用栈实现队列 225.用队列实现栈 232.用栈实现队列12345678910111213141516171819202122232425262728293031323334class MyQueue { Stack&lt;Integer&gt; stk1 , stk2; public MyQueue() { stk1 = new Stack&lt;&gt;(); stk2 = new Stack&lt;&gt;(); } public void push(int x) { stk1.push(x); } public int pop() { if(stk2.isEmpty()){ while(!stk1.isEmpty()){ stk2.push(stk1.pop()); } } return stk2.pop(); } public int peek() { if(stk2.isEmpty()){ while(!stk1.isEmpty()){ stk2.push(stk1.pop()); } } return stk2.peek(); } public boolean empty() { return stk1.isEmpty() &amp;&amp; stk2.isEmpty(); }} 225.用队列实现栈123456789101112131415161718192021222324252627282930313233class MyStack { Queue&lt;Integer&gt; queue1; Queue&lt;Integer&gt; queue2; public MyStack() { queue1 = new LinkedList&lt;&gt;(); queue2 = new LinkedList&lt;&gt;(); } public void push(int x) { queue2.offer(x); while (!queue1.isEmpty()){ queue2.offer(queue1.poll()); } Queue&lt;Integer&gt; queueTemp; queueTemp = queue1; queue1 = queue2; queue2 = queueTemp; } public int pop() { return queue1.poll(); } public int top() { return queue1.peek(); } public boolean empty() { return queue1.isEmpty(); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"},{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"棋盘问题","slug":"算法/回溯算法/棋盘问题","date":"2022-12-27T03:40:35.859Z","updated":"2023-02-24T04:59:42.907Z","comments":true,"path":"2022/12/27/算法/回溯算法/棋盘问题/","link":"","permalink":"http://example.com/2022/12/27/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/%E6%A3%8B%E7%9B%98%E9%97%AE%E9%A2%98/","excerpt":"","text":"棋盘问题51.N 皇后 37.解数独 51.N 皇后12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution { List&lt;List&lt;String&gt;&gt; list = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { char[][] arr = new char[n][n]; for (char[] c : arr) { Arrays.fill(c, '.'); } dfs(n, 0, arr); return list; } public void dfs(int n, int row, char[][] arr) { if (row == n) { list.add(Array2List(arr)); return; } for (int col = 0; col &lt; n; ++col) { if (isValid(row, col, n, arr)) { arr[row][col] = 'Q'; dfs(n, row+1, arr); arr[row][col] = '.'; } } } public List Array2List(char[][] chessboard) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (char[] c : chessboard) { list.add(String.copyValueOf(c)); } return list; } public boolean isValid(int row, int col, int n, char[][] arr) { for (int i=0; i&lt;row; ++i) { if (arr[i][col] == 'Q') { return false; } } for (int i=row-1, j=col-1; i&gt;=0 &amp;&amp; j&gt;=0; i--, j--) { if (arr[i][j] == 'Q') { return false; } } for (int i=row-1, j=col+1; i&gt;=0 &amp;&amp; j&lt;=n-1; i--, j++) { if (arr[i][j] == 'Q') { return false; } } return true; }} 37.解数独该方法时间复杂度较高 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution { public void solveSudoku(char[][] board) { solveSudokuHelper(board); } private boolean solveSudokuHelper(char[][] board){ for (int i = 0; i &lt; 9; i++){ for (int j = 0; j &lt; 9; j++){ if (board[i][j] != '.'){ continue; } for (char k = '1'; k &lt;= '9'; k++){ if (isValidSudoku(i, j, k, board)){ board[i][j] = k; if (solveSudokuHelper(board)){ return true; } board[i][j] = '.'; } } return false; } } return true; } private boolean isValidSudoku(int row, int col, char val, char[][] board){ for (int i = 0; i &lt; 9; i++){ if (board[row][i] == val){ return false; } } for (int j = 0; j &lt; 9; j++){ if (board[j][col] == val){ return false; } } int startRow = (row / 3) * 3; int startCol = (col / 3) * 3; for (int i = startRow; i &lt; startRow + 3; i++){ for (int j = startCol; j &lt; startCol + 3; j++){ if (board[i][j] == val){ return false; } } } return true; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"全排列问题","slug":"算法/回溯算法/全排列问题","date":"2022-12-26T03:07:21.564Z","updated":"2023-02-01T09:12:14.390Z","comments":true,"path":"2022/12/26/算法/回溯算法/全排列问题/","link":"","permalink":"http://example.com/2022/12/26/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/%E5%85%A8%E6%8E%92%E5%88%97%E9%97%AE%E9%A2%98/","excerpt":"","text":"全排列问题46.全排列 47.全排列 II 46.全排列1234567891011121314151617181920212223242526class Solution { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); boolean[] used; public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { used = new boolean[nums.length]; dfs(nums); return result; } public void dfs(int[] nums) { if (path.size() == nums.length) { result.add(new ArrayList&lt;&gt;(path)); } for (int i = 0; i &lt; nums.length; ++i) { if (used[i]) continue; used[i] = true; path.add(nums[i]); dfs(nums); path.removeLast(); used[i] = false; } }} 47.全排列 II去重必须先将数组排序 12345678910111213141516171819202122232425262728class Solution { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); boolean[] used; public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) { Arrays.sort(nums); used = new boolean[nums.length]; dfs(nums); return result; } public void dfs(int[] nums) { if (path.size() == nums.length) { result.add(new ArrayList&lt;&gt;(path)); } for (int i = 0; i &lt; nums.length; ++i) { if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i-1]) continue; if (used[i]) continue; used[i] = true; path.add(nums[i]); dfs(nums); path.removeLast(); used[i] = false; } }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"子集问题","slug":"算法/回溯算法/子集问题","date":"2022-12-26T02:29:31.773Z","updated":"2022-12-26T02:31:27.128Z","comments":true,"path":"2022/12/26/算法/回溯算法/子集问题/","link":"","permalink":"http://example.com/2022/12/26/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/%E5%AD%90%E9%9B%86%E9%97%AE%E9%A2%98/","excerpt":"","text":"子集问题78.子集 90.子集 II 78.子集12345678910111213141516171819class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { dfs(nums,0); return lists; } public void dfs(int[] nums,int startIndex) { lists.add(new ArrayList&lt;&gt;(list)); for(int i = startIndex; i &lt; nums.length; ++i) { list.add(nums[i]); dfs(nums,i + 1); list.removeLast(); } }} 90.子集 II1.用used[]排除重复项必须先对数组进行排序 2.是判断used[i-1]而不是used[i] 12345678910111213141516171819202122232425class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); int[] used; public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) { used = new int[nums.length]; Arrays.sort(nums); dfs(nums,0); return lists; } public void dfs(int[] nums, int startIndex) { lists.add(new ArrayList&lt;&gt;(path)); for (int i = startIndex; i &lt; nums.length; ++i) { if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; used[i - 1] == 0) continue; path.add(nums[i]); used[i] = 1; dfs(nums,i + 1); used[i] = 0; path.removeLast(); } }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"分割问题","slug":"算法/回溯算法/分割问题","date":"2022-12-24T03:31:00.664Z","updated":"2023-02-24T01:22:26.022Z","comments":true,"path":"2022/12/24/算法/回溯算法/分割问题/","link":"","permalink":"http://example.com/2022/12/24/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/%E5%88%86%E5%89%B2%E9%97%AE%E9%A2%98/","excerpt":"","text":"分割问题131.分割回文串 93.复原IP地址 131.分割回文串回溯算法12345678910111213141516171819202122232425262728293031323334class Solution { List&lt;List&lt;String&gt;&gt; lists = new ArrayList&lt;&gt;(); Deque&lt;String&gt; deque = new LinkedList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; partition(String s) { backTracking(s, 0); return lists; } private void backTracking(String s, int startIndex) { if (startIndex &gt;= s.length()) { lists.add(new ArrayList(deque)); return; } for (int i = startIndex; i &lt; s.length(); i++) { if (isPalindrome(s, startIndex, i)) { String str = s.substring(startIndex, i + 1); deque.addLast(str); } else { continue; } backTracking(s, i + 1); deque.removeLast(); } } private boolean isPalindrome(String s, int startIndex, int end) { for (int i = startIndex, j = end; i &lt; j; i++, j--) { if (s.charAt(i) != s.charAt(j)) { return false; } } return true; }} 验证回文串的时候，每一次都得使用「双指针」的方式验证子串是否是回文子串。利用「力扣」第 5 题：最长回文子串 的思路，可以先用动态规划把结果算出来，这样就可以以 O(1) 的时间复杂度直接得到一个子串是否是回文。 回溯的优化（使用动态规划得到所有子串是否是回文)12345678910111213141516171819202122232425262728293031323334353637383940414243public class Solution { public List&lt;List&lt;String&gt;&gt; partition(String s) { int len = s.length(); List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); if (len == 0) { return res; } char[] charArray = s.toCharArray(); // 预处理 // 状态：dp[i][j] 表示 s[i][j] 是否是回文 boolean[][] dp = new boolean[len][len]; // 状态转移方程：在 s[i] == s[j] 的时候，dp[i][j] 参考 dp[i + 1][j - 1] for (int right = 0; right &lt; len; right++) { // 注意：left &lt;= right 取等号表示 1 个字符的时候也需要判断 for (int left = 0; left &lt;= right; left++) { if (charArray[left] == charArray[right] &amp;&amp; (right - left &lt;= 2 || dp[left + 1][right - 1])) { dp[left][right] = true; } } } Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); dfs(s, 0, len, dp, stack, res); return res; } private void dfs(String s, int index, int len, boolean[][] dp, Deque&lt;String&gt; path, List&lt;List&lt;String&gt;&gt; res) { if (index == len) { res.add(new ArrayList&lt;&gt;(path)); return; } for (int i = index; i &lt; len; i++) { if (dp[index][i]) { path.addLast(s.substring(index, i + 1)); dfs(s, i + 1, len, dp, path, res); path.removeLast(); } } }} 93.复原IP地址1、一开始，字符串的长度小于 4 或者大于 12 ，一定不能拼凑出合法的 ip 地址（这一点可以一般化到中间结点的判断中，以产生剪枝行为）； 2、每一个结点可以选择截取的方法只有 3 种：截 1 位、截 2 位、截 3 位，因此每一个结点可以生长出的分支最多只有 3 条分支； 根据截取出来的字符串判断是否是合理的 ip 段，这里写法比较多，可以先截取，再转换成 int ，再判断。我采用的做法是先转成 int，是合法的 ip 段数值以后，再截取。 3、由于 ip 段最多就 4 个段，因此这棵三叉树最多 4 层，这个条件作为递归终止条件之一； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution { List&lt;String&gt; res = new ArrayList&lt;&gt;(); Deque&lt;String&gt; path = new ArrayDeque&lt;&gt;(4); public List&lt;String&gt; restoreIpAddresses(String s) { int len = s.length(); if (len &gt; 12 || len &lt; 4) { return res; } dfs(s, len, 0, 4); return res; } private void dfs(String s, int len, int begin, int residue) { if (begin == len) { if (residue == 0) { res.add(String.join(\".\", path)); } return; } for (int i = begin; i &lt; begin + 3; i++) { if (i &gt;= len) { break; } if (residue * 3 &lt; len - i) { continue; } if (judgeIpSegment(s, begin, i)) { String currentIpSegment = s.substring(begin, i + 1); path.addLast(currentIpSegment); dfs(s, len, i + 1, residue - 1); path.removeLast(); } } } private boolean judgeIpSegment(String s, int left, int right) { int len = right - left + 1; if (len &gt; 1 &amp;&amp; s.charAt(left) == '0') { return false; } int res = 0; while (left &lt;= right) { res = res * 10 + s.charAt(left) - '0'; left++; } return res &gt;= 0 &amp;&amp; res &lt;= 255; }} ## 参考 - [1] liweiwei1419","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"组合问题","slug":"算法/回溯算法/组合问题","date":"2022-12-23T03:27:56.784Z","updated":"2023-02-01T08:24:20.040Z","comments":true,"path":"2022/12/23/算法/回溯算法/组合问题/","link":"","permalink":"http://example.com/2022/12/23/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/%E7%BB%84%E5%90%88%E9%97%AE%E9%A2%98/","excerpt":"","text":"组合问题77.组合 216.组合总和 III 39.组合总和 40.组合总和 II 17.电话号码的字母组合 77.组合例如：n = 6 ，k = 4。 path.size() == 1 的时候，接下来要选择 3 个数，搜索起点最大是 4，最后一个被选的组合是 [4, 5, 6]；path.size() == 2 的时候，接下来要选择 2 个数，搜索起点最大是 5，最后一个被选的组合是 [5, 6]；path.size() == 3 的时候，接下来要选择 1 个数，搜索起点最大是 6，最后一个被选的组合是 [6]； 再如：n = 15 ，k = 4。path.size() == 1 的时候，接下来要选择 3 个数，搜索起点最大是 13，最后一个被选的是 [13, 14, 15]；path.size() == 2 的时候，接下来要选择 2 个数，搜索起点最大是 14，最后一个被选的是 [14, 15]；path.size() == 3 的时候，接下来要选择 1 个数，搜索起点最大是 15，最后一个被选的是 [15]； 搜索起点的上界 + 接下来要选择的元素个数 - 1 = n 其中，接下来要选择的元素个数 = k - path.size()，整理得到： 搜索起点的上界 = n - (k - path.size()) + 1 所以，我们的剪枝过程就是：把 i &lt;= n 改成 i &lt;= n - (k - path.size()) + 1 12345678910111213141516171819202122class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) { dfs(n,k,1); return lists; } public void dfs(int n, int k, int indexStart) { if (path.size() == k) { lists.add(new ArrayList&lt;&gt;(path)); return; } for (int i = indexStart; i &lt;= n - (k - path.size()) + 1; ++i) { path.add(i); dfs(n,k,i + 1); path.removeLast(); } }} 216.组合总和 III12345678910111213141516171819202122232425class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) { dfs(k,n,1,0); return lists; } public void dfs(int k, int n, int startIndex, int sum) { if (path.size() == k) { if (sum == n) { lists.add(new ArrayList&lt;&gt;(path)); } } for (int i = startIndex; i &lt;= 9; ++i) { path.add(i); sum += i; dfs(k,n,i + 1,sum); sum -= i; path.removeLast(); } }} 39.组合总和数组排序进行剪枝优化 如果没有if (sum + arr[i] &gt; target) break,会导致栈溢出 1234567891011121314151617181920212223242526class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;List&lt;Integer&gt;&gt;(); Deque&lt;Integer&gt; path = new ArrayDeque&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { Arrays.sort(candidates); dfs(candidates,target,0,0); return lists; } public void dfs(int[] arr,int target,int sum,int index) { if(sum == target) { lists.add(new ArrayList&lt;&gt;(path)); return; } for(int i = index; i &lt; arr.length; ++i) { if (sum + arr[i] &gt; target) break; path.add(arr[i]); sum += arr[i]; dfs(arr,target,sum,i); sum -= arr[i]; path.removeLast(); } }} 40.组合总和 II123456789101112131415161718192021222324252627282930class Solution { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; path = new LinkedList&lt;&gt;(); int[] used; public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) { used = new int[candidates.length]; Arrays.sort(candidates); dfs(candidates,target,0,0); return lists; } public void dfs(int[] arr, int target, int sum, int startIndex) { if (sum == target) { lists.add(new ArrayList&lt;&gt;(path)); } for (int i = startIndex; i &lt; arr.length; ++i) { if (i &gt; 0 &amp;&amp; arr[i] == arr[i - 1] &amp;&amp; used[i-1] == 0) continue; if (arr[i] + sum &gt; target) break; path.add(arr[i]); used[i] = 1; sum += arr[i]; dfs(arr,target,sum,i + 1); sum -= arr[i]; used[i] = 0; path.removeLast(); } }} 17.电话号码的字母组合StringBuilder temp = new StringBuilder() temp.deleteCharAt() 12345678910111213141516171819202122232425262728class Solution { List&lt;String&gt; lists = new ArrayList&lt;String&gt;(); public List&lt;String&gt; letterCombinations(String digits) { if (digits == null || digits.length() == 0) { return lists; } String[] sArr = {\"\",\"\",\"abc\",\"def\",\"ghi\",\"jkl\",\"mno\",\"pqrs\",\"tuv\",\"wxyz\"}; dfs(digits,sArr,0); return lists; } StringBuilder temp = new StringBuilder(); public void dfs(String digits,String[] sArr,int num) { if(digits.length() == num) { lists.add(temp.toString()); return; } String str = sArr[digits.charAt(num) - '0']; for(int i =0; i &lt; str.length(); ++i) { temp.append(str.charAt(i)); dfs(digits, sArr, num + 1); temp.deleteCharAt(temp.length() - 1); } }} 补充 ## 参考 - [1] liweiwei1419","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"二叉搜索树的修改与构造","slug":"算法/二叉树/二叉搜索树的修改与构造","date":"2022-12-22T02:32:25.978Z","updated":"2023-02-21T08:12:48.899Z","comments":true,"path":"2022/12/22/算法/二叉树/二叉搜索树的修改与构造/","link":"","permalink":"http://example.com/2022/12/22/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E4%BF%AE%E6%94%B9%E4%B8%8E%E6%9E%84%E9%80%A0/","excerpt":"","text":"二叉搜索树的修改与构造701.二叉搜索树中的插入操作 450.删除二叉搜索树中的节点 669.修剪二叉搜索树 108.将有序数组转换为二叉搜索树 701.二叉搜索树中的插入操作12345678910111213class Solution { public TreeNode insertIntoBST(TreeNode root, int val) { if(root == null) { return new TreeNode(val); } if(root.val &lt; val) { root.right = insertIntoBST(root.right,val); } else if(root.val &gt; val) { root.left = insertIntoBST(root.left,val); } return root; }} 450.删除二叉搜索树中的节点1234567891011121314151617181920class Solution { public TreeNode deleteNode(TreeNode root, int key) { if (root == null) return null; if (root.val &lt; key) { root.right = deleteNode(root.right,key); } else if (root.val &gt; key) { root.left = deleteNode(root.left,key); } else { if (root.left == null) return root.right; if (root.right == null) return root.left; TreeNode currNode = root.right; while (currNode.left != null) { currNode = currNode.left; } currNode.left = root.left; root = root.right; } return root; }} 669.修剪二叉搜索树1234567891011121314class Solution { public TreeNode trimBST(TreeNode root, int low, int high) { if(root == null) return null; if(root.val &lt; low) { return trimBST(root.right,low,high); } else if(root.val &gt; high) { return trimBST(root.left,low,high); } root.left = trimBST(root.left,low,high); root.right = trimBST(root.right,low,high); return root; }} 108.将有序数组转换为二叉搜索树数组构造二叉树，构成平衡树是自然而然的事情，因为大家默认都是从数组中间位置取值作为节点元素，一般不会随机取。 1234567891011121314class Solution { public TreeNode sortedArrayToBST(int[] nums) { return dfs(nums,0,nums.length - 1); } public TreeNode dfs(int[] nums, int left, int right) { if (left &gt; right) return null; int mid = left + (right - left) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = dfs(nums,left,mid - 1); root.right = dfs(nums,mid + 1,right); return root; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"分治","slug":"分治","permalink":"http://example.com/tags/%E5%88%86%E6%B2%BB/"}]},{"title":"二叉搜索树的属性","slug":"算法/二叉树/二叉搜索树的属性","date":"2022-12-20T03:10:37.791Z","updated":"2023-02-21T07:39:49.109Z","comments":true,"path":"2022/12/20/算法/二叉树/二叉搜索树的属性/","link":"","permalink":"http://example.com/2022/12/20/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E5%B1%9E%E6%80%A7/","excerpt":"","text":"二叉搜索树的属性700.二叉搜索树中的搜索 98.验证二叉搜索树 530.二叉搜索树的最小绝对差 501.二叉搜索树中的众数 538.把二叉搜索树转换为累加树 700.二叉搜索树中的搜索递归，普通二叉树123456789101112class Solution { public TreeNode searchBST(TreeNode root, int val) { if (root == null || root.val == val) { return root; } TreeNode left = searchBST(root.left, val); if (left != null) { return left; } return searchBST(root.right, val); }} 递归，利用二叉搜索树特点，优化123456789101112class Solution { public TreeNode searchBST(TreeNode root, int val) { if (root == null || root.val == val) { return root; } if (val &lt; root.val) { return searchBST(root.left, val); } else { return searchBST(root.right, val); } }} 98.验证二叉搜索树12345678910111213141516class Solution { long pre = Long.MIN_VALUE; public boolean isValidBST(TreeNode root) { return inorder(root); } private boolean inorder(TreeNode node) { if(node == null) return true; boolean l = inorder(node.left); if(node.val &lt;= pre) return false; pre = node.val; boolean r = inorder(node.right); return l &amp;&amp; r; }} 530.二叉搜索树的最小绝对差1234567891011121314151617181920212223class Solution { int pre; int ans; public int getMinimumDifference(TreeNode root) { pre = -1; ans = Integer.MAX_VALUE; dfs(root); return ans; } public void dfs(TreeNode root) { if(root == null) return; dfs(root.left); if(pre == -1) { pre = root.val; } else { ans = Math.min(ans,root.val - pre); pre = root.val; } dfs(root.right); }} 501.二叉搜索树中的众数123456789101112131415161718192021222324252627282930313233343536373839class Solution { List&lt;Integer&gt; answer = new ArrayList&lt;Integer&gt;(); int base, count, maxCount; public int[] findMode(TreeNode root) { dfs(root); int[] mode = new int[answer.size()]; for (int i = 0; i &lt; answer.size(); ++i) { mode[i] = answer.get(i); } return mode; } public void dfs(TreeNode o) { if (o == null) { return; } dfs(o.left); update(o.val); dfs(o.right); } public void update(int x) { if (x == base) { ++count; } else { count = 1; base = x; } if (count == maxCount) { answer.add(base); } if (count &gt; maxCount) { maxCount = count; answer.clear(); answer.add(base); } }} 538.把二叉搜索树转换为累加树1234567891011class Solution { int sum = 0; public TreeNode convertBST(TreeNode root) { if(root == null) return null; root.right = convertBST(root.right); sum += root.val; root.val = sum; root.left = convertBST(root.left); return root; }} 123456789101112131415class Solution { int sum; public TreeNode convertBST(TreeNode root) { dfs(root); return root; } public void dfs(TreeNode root) { if (root == null) return; dfs(root.right); sum += root.val; root.val = sum; dfs(root.left); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"二叉树的修改与构造","slug":"算法/二叉树/二叉树的修改与构造","date":"2022-12-19T03:36:48.272Z","updated":"2023-02-17T01:59:34.648Z","comments":true,"path":"2022/12/19/算法/二叉树/二叉树的修改与构造/","link":"","permalink":"http://example.com/2022/12/19/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%BF%AE%E6%94%B9%E4%B8%8E%E6%9E%84%E9%80%A0/","excerpt":"","text":"二叉树的修改与构造226.翻转二叉树 106.从中序与后序遍历序列构造二叉树 105.从前序与中序遍历序列构造二叉树 654.最大二叉树 617.合并二叉树 226.翻转二叉树123456789101112class Solution { public TreeNode invertTree(TreeNode root) { if (root == null) return null; invertTree(root.left); invertTree(root.right); TreeNode temp = root.left; root.left = root.right; root.right = temp; return root; }} 106.从中序与后序遍历序列构造二叉树12345678910111213141516171819202122232425262728293031class Solution { int post_idx; int[] postorder; Map&lt;Integer, Integer&gt; idx_map = new HashMap&lt;Integer, Integer&gt;(); public TreeNode helper(int in_left, int in_right) { if (in_left &gt; in_right) return null; int root_val = postorder[post_idx]; TreeNode root = new TreeNode(root_val); int index = idx_map.get(root_val); post_idx--; root.right = helper(index + 1, in_right); root.left = helper(in_left, index - 1); return root; } public TreeNode buildTree(int[] inorder, int[] postorder) { this.postorder = postorder; post_idx = postorder.length - 1; int idx = 0; for (Integer val : inorder) { idx_map.put(val, idx++); } return helper(0, inorder.length - 1); }} 105.从前序与中序遍历序列构造二叉树1234567891011121314151617181920212223242526272829class Solution { int pre_id = 0; int[] preorder; HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); public TreeNode buildTree(int[] preorder, int[] inorder) { this.preorder = preorder; int index = 0; for(Integer node : inorder) { map.put(node,index ++); } return build(0,inorder.length - 1); } public TreeNode build(int left_index,int right_index) { if(left_index &gt; right_index) { return null; } int root_val = preorder[pre_id]; TreeNode root = new TreeNode(root_val); pre_id ++; int index = map.get(root_val); root.left = build(left_index,index - 1); root.right = build(index + 1,right_index); return root; }} 654.最大二叉树12345678910111213141516171819202122232425class Solution { public TreeNode constructMaximumBinaryTree(int[] nums) { return dfs(nums,0,nums.length - 1); } public TreeNode dfs(int[] nums, int left, int right) { if (left &gt; right) return null; int index = getBig(nums,left,right); TreeNode root = new TreeNode(nums[index]); root.left = dfs(nums,left,index - 1); root.right = dfs(nums,index + 1,right); return root; } public int getBig(int[] nums, int left, int right) { int best = left; for (int i = left + 1; i &lt;= right; ++i) { if (nums[i] &gt; nums[best]) { best = i; } } return best; }} 617.合并二叉树 12345678910111213141516class Solution { public TreeNode mergeTrees(TreeNode root1, TreeNode root2) { if(root1 == null) { return root2; } if(root2 == null) { return root1; } TreeNode root = new TreeNode(root1.val + root2.val); root.left = mergeTrees(root1.left,root2.left); root.right = mergeTrees(root1.right,root2.right); return root; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"分治","slug":"分治","permalink":"http://example.com/tags/%E5%88%86%E6%B2%BB/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"二叉树的最近公共祖先问题","slug":"算法/二叉树/二叉树的最近公共祖先问题","date":"2022-12-18T03:20:39.323Z","updated":"2022-12-18T03:21:48.051Z","comments":true,"path":"2022/12/18/算法/二叉树/二叉树的最近公共祖先问题/","link":"","permalink":"http://example.com/2022/12/18/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88%E9%97%AE%E9%A2%98/","excerpt":"","text":"二叉树的最近公共祖先问题236.二叉树的最近公共祖先 235.二叉搜索树的最近公共祖先 236.二叉树的最近公共祖先1234567891011121314151617181920class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if(root == null || root == p || root == q) { return root; } TreeNode left = lowestCommonAncestor(root.left,p,q); TreeNode right = lowestCommonAncestor(root.right,p,q); if(left == null &amp;&amp; right == null) { return null; }else if(left == null &amp;&amp; right != null) { return right; }else if(left != null &amp;&amp; right == null) { return left; }else { return root; } }} 235.二叉搜索树的最近公共祖先123456789101112class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if(root.val &gt; p.val &amp;&amp; root.val &gt; q.val) { return lowestCommonAncestor(root.left,p,q); } if(root.val &lt; p.val &amp;&amp; root.val &lt; q.val) { return lowestCommonAncestor(root.right,p,q); } return root; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"二叉树的属性","slug":"算法/二叉树/二叉树的属性","date":"2022-12-15T03:21:42.874Z","updated":"2023-02-16T04:16:12.649Z","comments":true,"path":"2022/12/15/算法/二叉树/二叉树的属性/","link":"","permalink":"http://example.com/2022/12/15/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%9E%E6%80%A7/","excerpt":"","text":"二叉树的属性110.平衡二叉树 101.对称二叉树 222.完全二叉树的节点个数 404.左叶子之和 513.找树左下角的值 110.平衡二叉树从顶至底（暴力法）123456789101112131415class Solution { public boolean isBalanced(TreeNode root) { if (root == null) return true; return Math.abs(hight(root.left) - hight(root.right)) &lt;= 1 &amp;&amp; isBalanced(root.left) &amp;&amp; isBalanced(root.right); } public int hight(TreeNode node) { if (node == null) return 0; int left = hight(node.left); int right = hight(node.right); return Math.max(left,right) + 1; }} 从底至顶（提前阻断）1234567891011121314class Solution { public boolean isBalanced(TreeNode root) { return recur(root) != -1; } private int recur(TreeNode root) { if (root == null) return 0; int left = recur(root.left); if(left == -1) return -1; int right = recur(root.right); if(right == -1) return -1; return Math.abs(left - right) &lt; 2 ? Math.max(left, right) + 1 : -1; }} 101.对称二叉树DFS12345678910111213class Solution { public boolean isSymmetric(TreeNode root) { return dfs(root.left,root.right); } public boolean dfs(TreeNode le, TreeNode ri) { if (le == null &amp;&amp; ri == null) return true; if (le == null || ri == null) return false; return (le.val == ri.val) &amp;&amp; dfs(le.left,ri.right) &amp;&amp; dfs(le.right,ri.left); }} BFS长度为1的情况 循环中node为空的情况 1234567891011121314151617181920212223242526class Solution { public boolean isSymmetric(TreeNode root) { Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root.left); queue.add(root.right); while(!queue.isEmpty()) { TreeNode node1 = queue.poll(); TreeNode node2 = queue.poll(); if(node1 == null &amp;&amp; node2 == null) continue; if(node1 == null || node2 == null) return false; if(node1.val != node2.val) { return false; } queue.add(node1.left); queue.add(node2.right); queue.add(node1.right); queue.add(node2.left); } return true; }} 222.完全二叉树的节点个数利用完全二叉树的性质 123456789101112131415161718192021class Solution { public int countNodes(TreeNode root) { if(root == null) return 0; int leftDepth = getDepth(root.left); int rightDepth = getDepth(root.right); if (leftDepth == rightDepth) { return (1 &lt;&lt; leftDepth) + countNodes(root.right); } else { return (1 &lt;&lt; rightDepth) + countNodes(root.left); } } private int getDepth(TreeNode root) { int depth = 0; while (root != null) { root = root.left; depth++; } return depth; }} 404.左叶子之和123456789101112131415161718class Solution { public int sumOfLeftLeaves(TreeNode root) { if(root == null) { return 0; } int leftValue = sumOfLeftLeaves(root.left); int rightValue = sumOfLeftLeaves(root.right); int midValue = 0; if (root.left != null &amp;&amp; root.left.left == null &amp;&amp; root.left.right == null) { midValue = root.left.val; } int sum = midValue + leftValue + rightValue; return sum; }} 513.找树左下角的值使用 height 记录遍历到的节点的高度，curVal 记录高度在 curHeight 的最左节点的值。在深度优先搜索时，我们先搜索当前节点的左子节点，再搜索当前节点的右子节点，然后判断当前节点的高度 height 是否大于curHeight，如果是，那么将 curVal 设置为当前结点的值，curHeight 设置为 height。 因为我们先遍历左子树，然后再遍历右子树，所以对同一高度的所有节点，最左节点肯定是最先被遍历到的。 DFS1234567891011121314151617181920212223class Solution { int curVal = 0; int curHeight = 0; public int findBottomLeftValue(TreeNode root) { int curHeight = 0; dfs(root, 0); return curVal; } public void dfs(TreeNode root, int height) { if (root == null) { return; } height++; dfs(root.left, height); dfs(root.right, height); if (height &gt; curHeight) { curHeight = height; curVal = root.val; } }} BFS1234567891011121314151617class Solution { public int findBottomLeftValue(TreeNode root) { Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); int re = 0; queue.add(root); while (!queue.isEmpty()) { int size = queue.size(); for (int i = 0; i &lt; size; ++i) { TreeNode node = queue.poll(); if (i == 0) re = node.val; if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } } return re; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"二叉树的路径问题","slug":"算法/二叉树/二叉树的路径问题","date":"2022-12-14T07:40:33.338Z","updated":"2022-12-14T07:41:59.750Z","comments":true,"path":"2022/12/14/算法/二叉树/二叉树的路径问题/","link":"","permalink":"http://example.com/2022/12/14/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"二叉树的路径问题257.二叉树的所有路径 112.路径总和 257.二叉树的所有路径123456789101112131415161718192021class Solution { List&lt;String&gt; paths = new ArrayList&lt;String&gt;(); public List&lt;String&gt; binaryTreePaths(TreeNode root) { constructPaths(root, \"\"); return paths; } public void constructPaths(TreeNode root, String path) { if (root == null) return; StringBuffer pathSB = new StringBuffer(path); pathSB.append(Integer.toString(root.val)); if (root.left == null &amp;&amp; root.right == null) { paths.add(pathSB.toString()); } else { pathSB.append(\"-&gt;\"); constructPaths(root.left, pathSB.toString()); constructPaths(root.right, pathSB.toString()); } }} 112.路径总和同上题解法 1234567891011121314151617181920212223class Solution { private boolean flag = false; public boolean hasPathSum(TreeNode root, int targetSum) { path(root,targetSum,0); return flag; } public void path(TreeNode root,int targetSum,int sum) { if(root != null) { sum += root.val; if(root.left == null &amp;&amp; root.right == null) { if(sum == targetSum) { flag = true; return; } } else { path(root.left,targetSum,sum); path(root.right,targetSum,sum); } } }} 简洁解法 12345678910class Solution { public boolean hasPathSum(TreeNode root, int targetSum) { if (root == null) return false; if (root.left == null &amp;&amp; root.right == null) { return targetSum == root.val; } return hasPathSum(root.left,targetSum - root.val) || hasPathSum(root.right,targetSum - root.val); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"}]},{"title":"二叉树的最大/小深度","slug":"算法/二叉树/二叉树的最大小深度","date":"2022-12-14T03:41:12.090Z","updated":"2023-02-13T10:29:20.697Z","comments":true,"path":"2022/12/14/算法/二叉树/二叉树的最大小深度/","link":"","permalink":"http://example.com/2022/12/14/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E5%B0%8F%E6%B7%B1%E5%BA%A6/","excerpt":"","text":"二叉树的最大/小深度104.二叉树的最大深度 111.二叉树的最小深度 104.二叉树的最大深度DFS比BFS时间复杂度更低 DFS12345678910class Solution { public int maxDepth(TreeNode root) { if (root == null) { return 0; } int left = maxDepth(root.left); int right = maxDepth(root.right); return Math.max(left,right) + 1; }} BFS1234567891011121314151617181920212223class Solution { public int maxDepth(TreeNode root) { Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); if(root != null){ queue.add(root); } int depth = 0; while(!queue.isEmpty()) { int len = queue.size(); for(int i = 0; i &lt; len; ++i){ TreeNode node = queue.poll(); if(node.left != null) { queue.add(node.left); } if(node.right != null) { queue.add(node.right); } } depth ++; } return depth; }} 111.二叉树的最小深度只有当左右孩子都为空的时候，才说明遍历的最低点了。如果其中一个孩子为空则不是最低点 BFS比DFS时间复杂度更低 DFS12345678910111213141516171819class Solution { public int minDepth(TreeNode root) { if (root == null) { return 0; } int left = minDepth(root.left); int right = minDepth(root.right); if(root.left == null) { return right + 1; } if(root.right == null) { return left + 1; } return Math.min(left,right) + 1; }} BFS12345678910111213141516171819202122232425class Solution { public int minDepth(TreeNode root){ if (root == null) { return 0; } Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int depth = 0; while (!queue.isEmpty()){ int size = queue.size(); depth++; TreeNode cur = null; for (int i = 0; i &lt; size; i++) { cur = queue.poll(); //如果当前节点的左右孩子都为空，直接返回最小深度 if (cur.left == null &amp;&amp; cur.right == null){ return depth; } if (cur.left != null) queue.offer(cur.left); if (cur.right != null) queue.offer(cur.right); } } return depth; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"二叉树的层序遍历","slug":"算法/二叉树/二叉树的层序遍历","date":"2022-12-12T03:09:23.705Z","updated":"2023-02-13T09:09:08.740Z","comments":true,"path":"2022/12/12/算法/二叉树/二叉树的层序遍历/","link":"","permalink":"http://example.com/2022/12/12/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/","excerpt":"","text":"二叉树的层序遍历102.二叉树的层序遍历 107.二叉树的层序遍历 II 199.二叉树的右视图 637.二叉树的层平均值 429.N叉树的层序遍历 515.在每个树行中找最大值 116.填充每个节点的下一个右侧节点指针 117.填充每个节点的下一个右侧节点指针 II 102.二叉树的层序遍历123456789101112131415161718192021222324class Solution { public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); int currentLevelSize = queue.size(); for (int i = 1; i &lt;= currentLevelSize; ++i) { TreeNode node = queue.poll(); level.add(node.val); if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } } ret.add(level); } return ret; }} 107.二叉树的层序遍历 II123456789101112131415161718192021222324class Solution { public List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); int currentLevelSize = queue.size(); for (int i = 1; i &lt;= currentLevelSize; ++i) { TreeNode node = queue.poll(); level.add(node.val); if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } } ret.add(0,level); } return ret; }} 199.二叉树的右视图123456789101112131415161718192021222324class Solution { public List&lt;Integer&gt; rightSideView(TreeNode root) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { int currentLevelSize = queue.size(); for (int i = 1; i &lt;= currentLevelSize; ++i) { TreeNode node = queue.poll(); if (i == currentLevelSize) { ret.add(node.val); } if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } } } return ret; }} 637.二叉树的层平均值1234567891011121314151617181920212223242526class Solution { public List&lt;Double&gt; averageOfLevels(TreeNode root) { List&lt;Double&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { int currentLevelSize = queue.size(); double sum = 0; for (int i = 1; i &lt;= currentLevelSize; ++i) { TreeNode node = queue.poll(); sum += node.val; if (i == currentLevelSize) { ret.add(sum/currentLevelSize); } if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } } } return ret; }} 429.N叉树的层序遍历123456789101112131415161718192021class Solution { public List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) { List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); int currentLevelSize = queue.size(); for (int i = 1; i &lt;= currentLevelSize; ++i) { Node node = queue.poll(); level.add(node.val); for (Node no : node.children) { queue.offer(no); } } ret.add(level); } return ret; }} 515.在每个树行中找最大值注意节点的取值范围 1234567891011121314151617181920212223242526class Solution { public List&lt;Integer&gt; largestValues(TreeNode root) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) { int currentLevelSize = queue.size(); int ans = Integer.MIN_VALUE; for (int i = 1; i &lt;= currentLevelSize; ++i) { TreeNode node = queue.poll(); ans = Math.max(ans,node.val); if (i == currentLevelSize) { ret.add(ans); } if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } } } return ret; }} 116.填充每个节点的下一个右侧节点指针层序遍历如果用前面层次遍历的方法，116题和117题可以用一样的解法，但是时间复杂度都比较高 123456789101112131415161718192021222324class Solution { public Node connect(Node root) { Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); if(root != null) queue.add(root); while(!queue.isEmpty()){ int len = queue.size(); for(int i = 0; i &lt; len; ++i){ Node node = queue.poll(); if(i != len - 1){ node.next = queue.peek(); } else { node.next = null; } if(node.left != null){ queue.add(node.left); } if(node.right != null){ queue.add(node.right); } } } return root; }} 迭代第一种 是这两个串联的节点都有一个共同的父节点，通过父节点就可以将这两个子节点串联起来 第二种 是这两个串联的节点的父节点不同，对于这种情况，如果我们能将这一层的上一层串联好。那么可以通过父节点的next找到邻居，完成串联。 即 1root.right.next =&gt; root.next.left 这里我们需要保证 root.next 不为空就可以了。也就是说当我们要串联第 i 层节点时，需要先完成第 i-1 层的节点串联第一层最多只有一个节点，不需要串联第二层最多只有两个节点，借助根节点就可以完成串联了第三层串联时，上一层已经串联完了，所以第三层可以完成串联同理，可以完成第四层，第五层，第N层的串联 123456789101112131415161718class Solution { public Node connect(Node root) { if(root==null) return root; Node pre = root; while(pre.left!=null) { Node tmp = pre; while(tmp!=null) { tmp.left.next = tmp.right; if(tmp.next!=null) { tmp.right.next = tmp.next.left; } tmp = tmp.next; } pre = pre.left; } return root; }} 递归以从上往下的方向看，1，2，3，5，6这几个节点在位置上都是紧挨着的，同时这几个节点都是左右串联的。 我们以当前节root点为起始，左右节点不断的深入下面，left节点不断往右走，right节点不断往左走，当这两个节点走到底后，整个纵深这段就完成了串联。 123456789101112131415161718192021class Solution { public Node connect(Node root) { dfs(root); return root; } void dfs(Node root) { if(root==null) { return; } Node left = root.left; Node right = root.right; while(left!=null) { left.next = right; left = left.right; right = right.left; } dfs(root.left); dfs(root.right); }} 117.填充每个节点的下一个右侧节点指针 II层序遍历时间复杂度较高 123456789101112131415161718192021222324class Solution { public Node connect(Node root) { Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); if(root != null) queue.add(root); while(!queue.isEmpty()){ int len = queue.size(); for(int i = 0; i &lt; len; ++i){ Node node = queue.poll(); if(i != len - 1){ node.next = queue.peek(); } else { node.next = null; } if(node.left != null){ queue.add(node.left); } if(node.right != null){ queue.add(node.right); } } } return root; }} 常数空间只使用常数空间，时间复杂度低 把节点不同的入队然后再不停的出队，其实可以不需要队列，每一行都可以看成一个链表比如第一行就是只有一个节点的链表，第二行是只有两个节点的链表（假如根节点的左右两个子节点都不为空） 12345678910111213141516171819202122232425262728class Solution { public Node connect(Node root) { if (root == null) return root; Node head = new Node(0); Node headCur = head; Node cur = root; while (true) { while (cur != null) { if (cur.left != null) { headCur.next = cur.left; headCur = headCur.next; } if (cur.right != null) { headCur.next = cur.right; headCur = headCur.next; } cur = cur.next; } cur = head.next; head.next = null; headCur = head; if (cur == null) { break; } } return root; }} 参考资料 [1] [数据结构和算法](BFS解决（最好的击败了100%的用户） - 填充每个节点的下一个右侧节点指针 II - 力扣（LeetCode）) [2] [王尼玛](动画演示+三种实现 116. 填充每个节点的下一个右侧节点指针 - 填充每个节点的下一个右侧节点指针 - 力扣（LeetCode）) [3] 代码随想录","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"},{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"二叉树的递归遍历","slug":"算法/二叉树/二叉树的递归遍历","date":"2022-12-12T02:18:52.272Z","updated":"2022-12-12T02:21:07.087Z","comments":true,"path":"2022/12/12/算法/二叉树/二叉树的递归遍历/","link":"","permalink":"http://example.com/2022/12/12/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86/","excerpt":"","text":"二叉树的递归遍历114.二叉树的前序遍历 145.二叉树的后序遍历 94.二叉树的中序遍历 589.N叉树的前序遍历 590.N叉树的后序遍历 思路：1.确定递归函数的参数和返回值 2.确定终止条件 3.确定单层递归的逻辑 114.二叉树的前序遍历12345678910111213141516class Solution { public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); pre(root,list); return list; } public void pre(TreeNode root,List&lt;Integer&gt; list){ if(root == null){ return; } list.add(root.val); pre(root.left,list); pre(root.right,list); }} 145.二叉树的后序遍历12345678910111213141516class Solution { public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); post(root,list); return list; } public void post(TreeNode root,List&lt;Integer&gt; list){ if(root == null){ return; } post(root.left,list); post(root.right,list); list.add(root.val); }} 94.二叉树的中序遍历12345678910111213141516class Solution { public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); inorder(root,list); return list; } public void inorder(TreeNode root,List&lt;Integer&gt; list){ if(root == null){ return; } inorder(root.left,list); list.add(root.val); inorder(root.right,list); }} 589.N叉树的前序遍历1234567891011121314151617class Solution { public List&lt;Integer&gt; preorder(Node root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); pre(root,list); return list; } public void pre(Node root,List&lt;Integer&gt; list) { if(root == null) { return; } list.add(root.val); for(Node node : root.children) { pre(node,list); } }} 590.N叉树的后序遍历123456789101112131415161718class Solution { public List&lt;Integer&gt; postorder(Node root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); post(root,list); return list; } public void post(Node root,List&lt;Integer&gt; list) { if(root == null) { return; } for(Node node : root.children) { post(node,list); } list.add(root.val); }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"}]},{"title":"安装DelayExchange插件","slug":"笔记/技术2/安装DelayExchange插件","date":"2022-12-01T07:04:02.290Z","updated":"2022-12-01T07:10:22.044Z","comments":true,"path":"2022/12/01/笔记/技术2/安装DelayExchange插件/","link":"","permalink":"http://example.com/2022/12/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%AE%89%E8%A3%85DelayExchange%E6%8F%92%E4%BB%B6/","excerpt":"","text":"安装DelayExchange插件官方的安装指南地址为：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq 上述文档是基于linux原生安装RabbitMQ，然后安装插件。 因为我们之前是基于Docker安装RabbitMQ，所以下面我们会讲解基于Docker来安装RabbitMQ插件。 下载插件RabbitMQ有一个官方的插件社区，地址为：https://www.rabbitmq.com/community-plugins.html 其中包含各种各样的插件，包括我们要使用的DelayExchange插件： 大家可以去对应的GitHub页面下载3.8.9版本的插件，地址为https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/3.8.9这个对应RabbitMQ的3.8.5以上版本。 上传插件基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。 我们之前设定的RabbitMQ的数据卷名称为mq-plugins，所以我们使用下面命令查看数据卷： 1docker volume inspect mq-plugins 可以得到下面结果： 接下来，将插件上传到这个目录即可： 安装插件最后就是安装了，需要进入MQ容器内部来执行安装。我的容器名为mq，所以执行下面命令： 1docker exec -it mq bash 执行时，请将其中的 -it 后面的mq替换为你自己的容器名. 进入容器内部后，执行下面命令开启插件： 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 结果如下：","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"服务异步通信","slug":"笔记/技术2/RabbitMQ-高级篇","date":"2022-12-01T02:13:31.713Z","updated":"2022-12-01T07:01:56.022Z","comments":true,"path":"2022/12/01/笔记/技术2/RabbitMQ-高级篇/","link":"","permalink":"http://example.com/2022/12/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/RabbitMQ-%E9%AB%98%E7%BA%A7%E7%AF%87/","excerpt":"","text":"服务异步通信-高级篇消息队列在使用过程中，面临着很多实际问题需要思考： 1.消息可靠性消息从发送，到消费者接收，会经理多个过程： 其中的每一步都可能导致消息丢失，常见的丢失原因包括： 发送时丢失： 生产者发送的消息未送达exchange 消息到达exchange后未到达queue MQ宕机，queue将消息丢失 consumer接收到消息后未消费就宕机 针对这些问题，RabbitMQ分别给出了解决方案： 生产者确认机制 mq持久化 消费者确认机制 失败重试机制 1.1.生产者消息确认RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。 返回结果有两种方式： publisher-confirm，发送者确认 消息成功投递到交换机，返回ack 消息未投递到交换机，返回nack publisher-return，发送者回执 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。 注意： 1.1.1.修改配置首先，修改publisher服务中的application.yml文件，添加下面的内容： 1234567spring: rabbitmq: publisher-confirm-type: correlated publisher-returns: true template: mandatory: true 说明： publish-confirm-type：开启publisher-confirm，这里支持两种类型： simple：同步等待confirm结果，直到超时 correlated：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback publish-returns：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback template.mandatory：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息 1.1.2.定义Return回调每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置： 修改publisher服务，添加一个： 12345678910111213141516171819202122232425package cn.itcast.mq.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.annotation.Configuration;@Slf4j@Configurationpublic class CommonConfig implements ApplicationContextAware { @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { // 获取RabbitTemplate RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); // 设置ReturnCallback rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; { // 投递失败，记录日志 log.info(\"消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}\", replyCode, replyText, exchange, routingKey, message.toString()); // 如果有业务需要，可以重发消息 }); }} 1.1.3.定义ConfirmCallbackConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。 在publisher服务的cn.itcast.mq.spring.SpringAmqpTest类中，定义一个单元测试方法： 123456789101112131415161718192021222324public void testSendMessage2SimpleQueue() throws InterruptedException { // 1.消息体 String message = \"hello, spring amqp!\"; // 2.全局唯一的消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 3.添加callback correlationData.getFuture().addCallback( result -&gt; { if(result.isAck()){ // 3.1.ack，消息成功 log.debug(\"消息发送成功, ID:{}\", correlationData.getId()); }else{ // 3.2.nack，消息失败 log.error(\"消息发送失败, ID:{}, 原因{}\",correlationData.getId(), result.getReason()); } }, ex -&gt; log.error(\"消息发送异常, ID:{}, 原因{}\",correlationData.getId(),ex.getMessage()) ); // 4.发送消息 rabbitTemplate.convertAndSend(\"task.direct\", \"task\", message, correlationData); // 休眠一会儿，等待ack回执 Thread.sleep(2000);} 1.2.消息持久化生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。 要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。 交换机持久化 队列持久化 消息持久化 1.2.1.交换机持久化RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： 12345@Beanpublic DirectExchange simpleExchange(){ // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new DirectExchange(\"simple.direct\", true, false);} 事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。 可以在RabbitMQ控制台看到持久化的交换机都会带上D的标示： 1.2.2.队列持久化RabbitMQ中队列默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： 12345@Beanpublic Queue simpleQueue(){ // 使用QueueBuilder构建队列，durable就是持久化的 return QueueBuilder.durable(\"simple.queue\").build();} 事实上，默认情况下，由SpringAMQP声明的队列都是持久化的。 可以在RabbitMQ控制台看到持久化的队列都会带上D的标示： 1.2.3.消息持久化利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode： 1：非持久化 2：持久化 用java代码指定： 默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。 1.3.消费者消息确认RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。 而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。 设想这样的场景： 1）RabbitMQ投递消息给消费者 2）消费者获取消息后，返回ACK给RabbitMQ 3）RabbitMQ删除消息 4）消费者宕机，消息尚未处理 这样，消息就丢失了。因此消费者返回ACK的时机非常重要。 而SpringAMQP则允许配置三种确认模式： •manual：手动ack，需要在业务代码结束后，调用api发送ack。 •auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack •none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除 由此可知： none模式下，消息投递是不可靠的，可能丢失 auto模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack manual：自己根据业务情况，判断什么时候该ack 一般，我们都是使用默认的auto即可。 1.3.1.演示none模式修改consumer服务的application.yml文件，添加下面内容： 12345spring: rabbitmq: listener: simple: acknowledge-mode: none # 关闭ack 修改consumer服务的SpringRabbitListener类中的方法，模拟一个消息处理异常： 1234567@RabbitListener(queues = \"simple.queue\")public void listenSimpleQueue(String msg) { log.info(\"消费者接收到simple.queue的消息：【{}】\", msg); // 模拟异常 System.out.println(1 / 0); log.debug(\"消息处理完成！\");} 测试可以发现，当消息处理抛异常时，消息依然被RabbitMQ删除了。 1.3.2.演示auto模式再次把确认机制修改为auto: 12345spring: rabbitmq: listener: simple: acknowledge-mode: auto # 关闭ack 在异常位置打断点，再次发送消息，程序卡在断点时，可以发现此时消息状态为unack（未确定状态）： 抛出异常后，因为Spring会自动返回nack，所以消息恢复至Ready状态，并且没有被RabbitMQ删除： 1.4.消费失败重试机制当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力： 怎么办呢？ 1.4.1.本地重试我们可以利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。 修改consumer服务的application.yml文件，添加内容： 12345678910spring: rabbitmq: listener: simple: retry: enabled: true # 开启消费者失败重试 initial-interval: 1000 # 初识的失败等待时长为1秒 multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval max-attempts: 3 # 最大重试次数 stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false 重启consumer服务，重复之前的测试。可以发现： 在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了 查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了 结论： 开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试 重试达到最大次数后，Spring会返回ack，消息会被丢弃 1.4.2.失败策略在之前的测试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。 在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现： RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式 ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队 RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机 比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。 1）在consumer服务中定义处理失败消息的交换机和队列 123456789101112@Beanpublic DirectExchange errorMessageExchange(){ return new DirectExchange(\"error.direct\");}@Beanpublic Queue errorQueue(){ return new Queue(\"error.queue\", true);}@Beanpublic Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\"error\");} 2）定义一个RepublishMessageRecoverer，关联队列和交换机 1234@Beanpublic MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, \"error.direct\", \"error\");} 完整代码： 12345678910111213141516171819202122232425262728293031package cn.itcast.mq.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.retry.MessageRecoverer;import org.springframework.amqp.rabbit.retry.RepublishMessageRecoverer;import org.springframework.context.annotation.Bean;@Configurationpublic class ErrorMessageConfig { @Bean public DirectExchange errorMessageExchange(){ return new DirectExchange(\"error.direct\"); } @Bean public Queue errorQueue(){ return new Queue(\"error.queue\", true); } @Bean public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\"error\"); } @Bean public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, \"error.direct\", \"error\"); }} 1.5.总结如何确保RabbitMQ消息的可靠性？ 开启生产者确认机制，确保生产者的消息能到达队列 开启持久化功能，确保消息未消费前在队列中不会丢失 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack 开启消费者失败重试机制，并设置MessageRecoverer，多次重试失败后将消息投递到异常交换机，交由人工处理 2.死信交换机2.1.初识死信交换机2.1.1.什么是死信交换机什么是死信？ 当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）： 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false 消息是一个过期消息，超时无人消费 要投递的队列消息满了，无法投递 如果这个包含死信的队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX）。 如图，一个消息被消费者拒绝了，变成了死信： 因为simple.queue绑定了死信交换机 dl.direct，因此死信会投递给这个交换机： 如果这个死信交换机也绑定了一个队列，则消息最终会进入这个存放死信的队列： 另外，队列将死信投递给死信交换机时，必须知道两个信息： 死信交换机名称 死信交换机与死信队列绑定的RoutingKey 这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。 2.1.2.利用死信交换机接收死信（拓展）在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。 我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。 我们在consumer服务中，定义一组死信交换机、死信队列： 12345678910111213141516171819202122// 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct@Beanpublic Queue simpleQueue2(){ return QueueBuilder.durable(\"simple.queue\") // 指定队列名称，并持久化 .deadLetterExchange(\"dl.direct\") // 指定死信交换机 .build();}// 声明死信交换机 dl.direct@Beanpublic DirectExchange dlExchange(){ return new DirectExchange(\"dl.direct\", true, false);}// 声明存储死信的队列 dl.queue@Beanpublic Queue dlQueue(){ return new Queue(\"dl.queue\", true);}// 将死信队列 与 死信交换机绑定@Beanpublic Binding dlBinding(){ return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(\"simple\");} 2.1.3.总结什么样的消息会成为死信？ 消息被消费者reject或者返回nack 消息超时未消费 队列满了 死信交换机的使用场景是什么？ 如果队列绑定了死信交换机，死信会投递到死信交换机； 可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。 2.2.TTL一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况： 消息所在的队列设置了超时时间 消息本身设置了超时时间 2.2.1.接收超时死信的死信交换机在consumer服务的SpringRabbitListener中，定义一个新的消费者，并且声明 死信交换机、死信队列： 12345678@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"dl.ttl.queue\", durable = \"true\"), exchange = @Exchange(name = \"dl.ttl.direct\"), key = \"ttl\"))public void listenDlQueue(String msg){ log.info(\"接收到 dl.ttl.queue的延迟消息：{}\", msg);} 2.2.2.声明一个队列，并且指定TTL要给队列设置超时时间，需要在声明队列时配置x-message-ttl属性： 1234567@Beanpublic Queue ttlQueue(){ return QueueBuilder.durable(\"ttl.queue\") // 指定队列名称，并持久化 .ttl(10000) // 设置队列的超时时间，10秒 .deadLetterExchange(\"dl.ttl.direct\") // 指定死信交换机 .build();} 注意，这个队列设定了死信交换机为dl.ttl.direct 声明交换机，将ttl与交换机绑定： 12345678@Beanpublic DirectExchange ttlExchange(){ return new DirectExchange(\"ttl.direct\");}@Beanpublic Binding ttlBinding(){ return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(\"ttl\");} 发送消息，但是不要指定TTL： 1234567891011@Testpublic void testTTLQueue() { // 创建消息 String message = \"hello, ttl queue\"; // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(\"ttl.direct\", \"ttl\", message, correlationData); // 记录日志 log.debug(\"发送消息成功\");} 发送消息的日志： 查看下接收消息的日志： 因为队列的TTL值是10000ms，也就是10秒。可以看到消息发送与接收之间的时差刚好是10秒。 2.2.3.发送消息时，设定TTL在发送消息时，也可以指定TTL： 12345678910111213@Testpublic void testTTLMsg() { // 创建消息 Message message = MessageBuilder .withBody(\"hello, ttl message\".getBytes(StandardCharsets.UTF_8)) .setExpiration(\"5000\") .build(); // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(\"ttl.direct\", \"ttl\", message, correlationData); log.debug(\"发送消息成功\");} 查看发送消息日志： 接收消息日志： 这次，发送与接收的延迟只有5秒。说明当队列、消息都设置了TTL时，任意一个到期就会成为死信。 2.2.4.总结消息超时的两种方式是？ 给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信 给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信 如何实现发送一个消息20秒后消费者才收到消息？ 给消息的目标队列指定死信交换机 将消费者监听的队列绑定到死信交换机 发送消息时给消息设置超时时间为20秒 2.3.延迟队列利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。 延迟队列的使用场景包括： 延迟发送短信 用户下单，如果用户在15 分钟内未支付，则自动取消 预约工作会议，20分钟后自动通知所有参会人员 因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。 这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html 使用方式可以参考官网地址：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq 2.3.1.安装DelayExchange插件2.3.2.DelayExchange原理DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下： 接收消息 判断消息是否具备x-delay属性 如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间 返回routing not found结果给消息发送者 x-delay时间到期后，重新投递消息到指定队列 2.3.3.使用DelayExchange插件的使用也非常简单：声明一个交换机，交换机的类型可以是任意类型，只需要设定delayed属性为true即可，然后声明队列与其绑定即可。 1）声明DelayExchange交换机基于注解方式（推荐）： 也可以基于@Bean的方式： 2）发送消息发送消息时，一定要携带x-delay属性，指定延迟的时间： 2.3.4.总结延迟队列插件的使用步骤包括哪些？ •声明一个交换机，添加delayed属性为true •发送消息时，添加x-delay头，值为超时时间 3.惰性队列3.1.消息堆积问题当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。 解决消息堆积有两种思路： 增加更多消费者，提高消费速度。也就是我们之前说的work queue模式 扩大队列容积，提高堆积上限 要提升队列容积，把消息保存在内存中显然是不行的。 3.2.惰性队列从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下： 接收到消息后直接存入磁盘而非内存 消费者要消费消息时才会从磁盘中读取并加载到内存 支持数百万条的消息存储 3.2.1.基于命令行设置lazy-queue而要设置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列： 1rabbitmqctl set_policy Lazy \"^lazy-queue$\" '{\"queue-mode\":\"lazy\"}' --apply-to queues 命令解读： rabbitmqctl ：RabbitMQ的命令行工具 set_policy ：添加一个策略 Lazy ：策略名称，可以自定义 \"^lazy-queue$\" ：用正则表达式匹配队列的名字 '{\"queue-mode\":\"lazy\"}' ：设置队列模式为lazy模式 --apply-to queues ：策略的作用对象，是所有的队列 3.2.2.基于@Bean声明lazy-queue 3.2.3.基于@RabbitListener声明LazyQueue 3.3.总结消息堆积问题的解决方案？ 队列上绑定多个消费者，提高消费速度 使用惰性队列，可以再mq中保存更多消息 惰性队列的优点有哪些？ 基于磁盘存储，消息上限高 没有间歇性的page-out，性能比较稳定 惰性队列的缺点有哪些？ 基于磁盘存储，消息时效性会降低 性能受限于磁盘的IO 4.MQ集群4.1.集群分类RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式： •普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。 •镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。 镜像集群虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后，推出了新的功能：仲裁队列来代替镜像集群，底层采用Raft协议确保主从的数据一致性。 4.2.普通集群4.2.1.集群结构和特征普通集群，或者叫标准集群（classic cluster），具备下列特征： 会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回 队列所在节点宕机，队列中的消息就会丢失 结构如图： 4.3.镜像集群4.3.1.集群结构和特征镜像集群：本质是主从模式，具备下面的特征： 交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。 创建队列的节点被称为该队列的主节点，备份到的其它节点叫做该队列的镜像节点。 一个队列的主节点可能是另一个队列的镜像节点 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主 结构如图： 4.4.仲裁队列4.4.1.集群特征仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征： 与镜像队列一样，都是主从模式，支持主从数据同步 使用非常简单，没有复杂的配置 主从同步基于Raft协议，强一致 4.4.3.Java代码创建仲裁队列1234567@Beanpublic Queue quorumQueue() { return QueueBuilder .durable(\"quorum.queue\") // 持久化 .quorum() // 仲裁队列 .build();} 4.4.4.SpringAMQP连接MQ集群注意，这里用address来代替host、port方式 123456spring: rabbitmq: addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073 username: itcast password: 123321 virtual-host: /","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"分布式缓存\t哨兵&分片集群","slug":"笔记/技术2/分布式缓存2","date":"2022-11-14T07:57:37.850Z","updated":"2022-11-28T06:32:10.903Z","comments":true,"path":"2022/11/14/笔记/技术2/分布式缓存2/","link":"","permalink":"http://example.com/2022/11/14/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%982/","excerpt":"","text":"分布式缓存 哨兵&amp;分片集群– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题： Redis哨兵Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。 哨兵原理集群结构和作用哨兵的结构如图： 哨兵的作用如下： 监控：Sentinel 会不断检查您的master和slave是否按预期工作 自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主 通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端 集群监控原理Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令： •主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。 •客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。 集群故障恢复原理一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的： 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高 最后是判断slave节点的运行id大小，越小优先级越高。 当选出一个新的master后，该如何实现切换呢？ 流程如下： sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点 小结Sentinel的三个作用是什么？ 监控 故障转移 通知 Sentinel如何判断一个redis实例是否健康？ 每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线 如果大多数sentinel都认为实例主观下线，则判定服务下线 故障转移步骤有哪些？ 首先选定一个slave作为新的master，执行slaveof no one 然后让所有节点都执行slaveof 新master 修改故障节点配置，添加slaveof 新master RedisTemplate在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。 下面，我们通过一个测试来实现RedisTemplate集成哨兵机制。 导入Demo工程引入依赖在项目的pom文件中引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置Redis地址然后在配置文件application.yml中指定redis的sentinel相关信息： 12345678spring: redis: sentinel: master: mymaster nodes: - 192.168.150.101:27001 - 192.168.150.101:27002 - 192.168.150.101:27003 配置读写分离在项目的启动类中，添加一个新的bean： 1234@Beanpublic LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){ return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);} 这个bean中配置的就是读写策略，包括四种： MASTER：从主节点读取 MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica REPLICA：从slave（replica）节点读取 REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master Redis分片集群搭建分片集群主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决： 海量数据存储问题 高并发写的问题 使用分片集群可以解决上述问题，如图: 分片集群特征： 集群中有多个master，每个master保存不同数据 每个master都可以有多个slave节点 master之间通过ping监测彼此健康状态 客户端请求可以访问集群任意节点，最终都会被转发到正确节点 散列插槽插槽原理Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到： 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况： key中包含”{}”，且“{}”中至少包含1个字符，“{}”中的部分是有效部分 key中不包含“{}”，整个key都是有效部分 例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。 如图，在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到103节点。 到了7003后，执行get num时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点 小结Redis如何判断某个key应该在哪个实例？ 将16384个插槽分配到不同的实例 根据key的有效部分计算哈希值，对16384取余 余数作为插槽，寻找插槽所在实例即可 如何将同一类数据固定的保存在同一个Redis实例？ 这一类数据使用相同的有效部分，例如key都以{typeId}为前缀 集群伸缩redis-cli –cluster提供了很多操作集群的命令，可以通过下面方式查看： 比如，添加节点的命令： 需求分析需求：向集群中添加一个新的master节点，并向其中存储 num = 10 启动一个新的redis实例，端口为7004 添加7004到之前的集群，并作为一个master节点 给7004节点分配插槽，使得num这个key可以存储到7004实例 这里需要两个新的功能： 添加一个节点到集群中 将部分插槽分配到新插槽 创建新的redis实例创建一个文件夹： 1mkdir 7004 拷贝配置文件： 1cp redis.conf /7004 修改配置文件： 1sed /s/6379/7004/g 7004/redis.conf 启动 1redis-server 7004/redis.conf 添加新节点到redis添加节点的语法如下： 执行命令： 1redis-cli --cluster add-node 192.168.150.101:7004 192.168.150.101:7001 通过命令查看集群状态： 1redis-cli -p 7001 cluster nodes 如图，7004加入了集群，并且默认是一个master节点： 但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上 转移插槽我们要将num存储到7004节点，因此需要先看看num的插槽是多少： 如上图所示，num的插槽为2765. 我们可以将0~3000的插槽从7001转移到7004，命令格式如下： 具体命令如下： 建立连接： 得到下面的反馈： 询问要移动多少个插槽，我们计划是3000个： 新的问题来了： 那个node来接收这些插槽？？ 显然是7004，那么7004节点的id是多少呢？ 复制这个id，然后拷贝到刚才的控制台后： 这里询问，你的插槽是从哪里移动过来的？ all：代表全部，也就是三个节点各转移一部分 具体的id：目标节点的id done：没有了 这里我们要从7001获取，因此填写7001的id： 填完后，点击done，这样插槽转移就准备好了： 确认要转移吗？输入yes： 然后，通过命令查看结果： 可以看到： 目的达成。 故障转移集群初识状态是这样的： 其中7001、7002、7003都是master，我们计划让7002宕机。 自动故障转移当集群中有一个master宕机会发生什么呢？ 直接停止一个redis实例，例如7002： 1redis-cli -p 7002 shutdown 1）首先是该实例与其它实例失去连接 2）然后是疑似宕机： 3）最后是确定下线，自动提升一个slave为新的master： 4）当7002再次启动，就会变为一个slave节点了： 手动故障转移利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下： 这种failover命令可以指定三种模式： 缺省：默认的流程，如图1~6歩 force：省略了对offset的一致性校验 takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见 案例需求：在7002这个slave节点执行手动故障转移，重新夺回master地位 步骤如下： 1）利用redis-cli连接7002这个节点 2）执行cluster failover命令 如图： 效果： RedisTemplate访问分片集群RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致： 1）引入redis的starter依赖 2）配置分片集群地址 3）配置读写分离 与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下： 12345678910spring: redis: cluster: nodes: - 192.168.150.101:7001 - 192.168.150.101:7002 - 192.168.150.101:7003 - 192.168.150.101:8001 - 192.168.150.101:8002 - 192.168.150.101:8003","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"分布式缓存 持久化&主从","slug":"笔记/技术2/分布式缓存1","date":"2022-11-14T07:46:45.324Z","updated":"2022-11-28T06:32:10.904Z","comments":true,"path":"2022/11/14/笔记/技术2/分布式缓存1/","link":"","permalink":"http://example.com/2022/11/14/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%981/","excerpt":"","text":"分布式缓存 持久化&amp;主从– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题： Redis持久化Redis有两种持久化方案： RDB持久化 AOF持久化 RDB持久化RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。 执行时机RDB持久化在四种情况下会执行： 执行save命令 执行bgsave命令 Redis停机时 触发RDB条件时 1）save命令 执行下面的命令，可以立即执行一次RDB： save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。 2）bgsave命令 下面的命令可以异步执行RDB： 这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。 3）停机时 Redis停机时会执行一次save命令，实现RDB持久化。 4）触发RDB条件 Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下： 1234# 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save \"\" 则表示禁用RDBsave 900 1 save 300 10 save 60 10000 RDB的其它配置也可以在redis.conf文件中设置： 12345678# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱rdbcompression yes# RDB文件名称dbfilename dump.rdb # 文件保存的路径目录dir ./ RDB原理bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。 fork采用的是copy-on-write技术： 当主进程执行读操作时，访问共享内存； 当主进程执行写操作时，则会拷贝一份数据，执行写操作。 小结RDB方式bgsave的基本流程？ fork主进程得到一个子进程，共享内存空间 子进程读取内存数据并写入新的RDB文件 用新RDB文件替换旧的RDB文件 RDB会在什么时候执行？save 60 1000代表什么含义？ 默认是服务停止时 代表60秒内至少执行1000次修改则触发RDB RDB的缺点？ RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险 fork子进程、压缩、写出RDB文件都比较耗时 AOF持久化AOF原理AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。 AOF配置AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF： 1234# 是否开启AOF功能，默认是noappendonly yes# AOF文件的名称appendfilename \"appendonly.aof\" AOF的命令记录的频率也可以通过redis.conf文件来配： 123456# 表示每执行一次写命令，立即记录到AOF文件appendfsync always # 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案appendfsync everysec # 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘appendfsync no 三种策略对比： AOF文件重写因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。 如图，AOF原本有三个命令，但是set num 123 和 set num 666都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。 所以重写命令后，AOF文件内容就是：mset name jack num 666 Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置： 1234# AOF文件比上次文件 增长超过多少百分比则触发重写auto-aof-rewrite-percentage 100# AOF文件体积最小多大以上才触发重写 auto-aof-rewrite-min-size 64mb RDB与AOF对比RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会结合两者来使用。 Redis主从搭建主从架构单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。 主从数据同步原理全量同步主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点，流程： 这里有一个问题，master如何得知salve是第一次来连接呢？？ 有几个概念，可以作为判断依据： Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。 因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。 因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。 master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。 master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。 因此，master判断一个节点是否是第一次同步的依据，就是看replid是否一致。 如图： 完整流程描述： slave节点请求增量同步 master节点判断replid，发现不一致，拒绝增量同步 master将完整内存数据生成RDB，发送RDB到slave slave清空本地数据，加载master的RDB master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave slave执行接收到的命令，保持与master之间的同步 增量同步全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做增量同步。 什么是增量同步？就是只更新slave与master存在差异的部分数据。如图： 那么master怎么知道slave与自己的数据差异在哪里呢? repl_backlog原理master怎么知道slave与自己的数据差异在哪里呢? 这就要说到全量同步时的repl_baklog文件了。 这个文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾后，会再次从0开始读写，这样数组头部的数据就会被覆盖。 repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset： slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。 随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset： 直到数组被填满： 此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。 但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： 如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖： 棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。 主从同步优化主从同步可以保证主从数据的一致性，非常重要。 可以从以下几个方面来优化Redis主从就集群： 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。 Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力 主从从架构图： 小结简述全量同步和增量同步区别？ 全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave 什么时候执行全量同步？ slave节点第一次连接master节点时 slave节点断开时间太久，repl_baklog中的offset已经被覆盖时 什么时候执行增量同步？ slave节点断开又恢复，并且在repl_baklog中能找到offset时","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"seata的部署和集成","slug":"笔记/安装部署/seata的部署和集成","date":"2022-11-13T05:21:58.663Z","updated":"2022-11-28T10:13:21.944Z","comments":true,"path":"2022/11/13/笔记/安装部署/seata的部署和集成/","link":"","permalink":"http://example.com/2022/11/13/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/seata%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E9%9B%86%E6%88%90/","excerpt":"","text":"seata的部署和集成部署Seata的tc-server下载首先我们要下载seata-server包，地址在http://seata.io/zh-cn/blog/download.html 解压在非中文目录解压缩这个zip包，其目录结构如下： 修改配置修改conf目录下的application.yml文件： 内容如下： 12345678910111213141516171819202122seata: config: # support: nacos, consul, apollo, zk, etcd3 type: nacos nacos: server-addr: 127.0.0.1:8848 namespace: \"\" #修改 group: SEATA_GROUP #修改 username: nacos password: nacos data-id: seataServer.properties #修改 registry: # support: nacos, eureka, redis, zk, consul, etcd3, sofa type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 group: SEATA_GROUP #修改 namespace: \"\" #修改 cluster: \"SH\" username: nacos #默认 password: nacos #默认 在nacos添加配置特别注意，为了让tc服务的集群可以共享配置，我们选择了nacos作为统一配置中心。因此服务端配置文件seataServer.properties文件需要在nacos中配好。 格式如下： 配置内容如下： 12345678910111213141516171819202122232425262728293031323334# 数据存储方式，db代表数据库store.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;rewriteBatchedStatements=truestore.db.user=rootstore.db.password=111111store.db.minConn=5store.db.maxConn=30store.db.globalTable=global_tablestore.db.branchTable=branch_tablestore.db.queryLimit=100store.db.lockTable=lock_tablestore.db.maxWait=5000# 事务、日志等配置server.recovery.committingRetryPeriod=1000server.recovery.asynCommittingRetryPeriod=1000server.recovery.rollbackingRetryPeriod=1000server.recovery.timeoutRetryPeriod=1000server.maxCommitRetryTimeout=-1server.maxRollbackRetryTimeout=-1server.rollbackRetryTimeoutUnlockEnable=falseserver.undo.logSaveDays=7server.undo.logDeletePeriod=86400000# 客户端与服务端传输方式transport.serialization=seatatransport.compressor=none# 关闭metrics功能，提高性能metrics.enabled=falsemetrics.registryType=compactmetrics.exporterList=prometheusmetrics.exporterPrometheusPort=9898 ==其中的数据库地址、用户名、密码都需要修改成你自己的数据库信息。== 创建数据库表特别注意：tc服务在管理分布式事务时，需要记录事务相关数据到数据库中，你需要提前创建好这些表。 启动TC服务进入bin目录，运行其中的seata-server.bat即可： 启动成功后，seata-server应该已经注册到nacos注册中心了。 打开浏览器，访问nacos地址：http://localhost:8848，然后进入服务列表页面，可以看到seata-tc-server的信息： 微服务集成seata引入依赖首先，我们需要在微服务中引入seata依赖： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--seata starter 采用1.4.2版本--&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.version}&lt;/version&gt;&lt;/dependency&gt; 修改配置文件需要修改application.yml文件，添加一些配置： 1234567891011121314seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 # 参考tc服务自己的registry.conf中的配置 type: nacos nacos: # tc server-addr: 127.0.0.1:8848 namespace: \"\" group: DEFAULT_GROUP application: seata-tc-server # tc服务在nacos中的服务名称 cluster: SH tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称 service: vgroup-mapping: # 事务组与TC服务cluster的映射关系 seata-demo: SH TC服务的高可用和异地容灾模拟异地容灾的TC集群计划启动两台seata的tc服务节点： 节点名称 ip地址 端口号 集群名称 seata 127.0.0.1 8091 SH seata2 127.0.0.1 8092 HZ 之前我们已经启动了一台seata服务，端口是8091，集群名为SH。 现在，将seata目录复制一份，起名为seata2 修改seata2/conf/registry.conf内容如下： 12345678910111213141516171819202122seata: config: # support: nacos, consul, apollo, zk, etcd3 type: nacos nacos: server-addr: 127.0.0.1:8848 namespace: \"\" #修改 group: SEATA_GROUP #修改 username: nacos password: nacos data-id: seataServer.properties #修改 registry: # support: nacos, eureka, redis, zk, consul, etcd3, sofa type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 group: SEATA_GROUP #修改 namespace: \"\" #修改 cluster: \"HZ\" username: nacos #默认 password: nacos #默认 进入seata2/bin目录，然后运行命令： 1seata-server.bat -p 8092 打开nacos控制台，查看服务列表： 点进详情查看： 将事务组映射配置到nacos接下来，我们需要将tx-service-group与cluster的映射关系都配置到nacos配置中心。 新建一个配置： 配置的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 事务组映射关系service.vgroupMapping.seata-demo=SHservice.enableDegrade=falseservice.disableGlobalTransaction=false# 与TC服务的通信配置transport.type=TCPtransport.server=NIOtransport.heartbeat=truetransport.enableClientBatchSendRequest=falsetransport.threadFactory.bossThreadPrefix=NettyBosstransport.threadFactory.workerThreadPrefix=NettyServerNIOWorkertransport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandlertransport.threadFactory.shareBossWorker=falsetransport.threadFactory.clientSelectorThreadPrefix=NettyClientSelectortransport.threadFactory.clientSelectorThreadSize=1transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThreadtransport.threadFactory.bossThreadSize=1transport.threadFactory.workerThreadSize=defaulttransport.shutdown.wait=3# RM配置client.rm.asyncCommitBufferLimit=10000client.rm.lock.retryInterval=10client.rm.lock.retryTimes=30client.rm.lock.retryPolicyBranchRollbackOnConflict=trueclient.rm.reportRetryCount=5client.rm.tableMetaCheckEnable=falseclient.rm.tableMetaCheckerInterval=60000client.rm.sqlParserType=druidclient.rm.reportSuccessEnable=falseclient.rm.sagaBranchRegisterEnable=false# TM配置client.tm.commitRetryCount=5client.tm.rollbackRetryCount=5client.tm.defaultGlobalTransactionTimeout=60000client.tm.degradeCheck=falseclient.tm.degradeCheckAllowTimes=10client.tm.degradeCheckPeriod=2000# undo日志配置client.undo.dataValidation=trueclient.undo.logSerialization=jacksonclient.undo.onlyCareUpdateColumns=trueclient.undo.logTable=undo_logclient.undo.compress.enable=trueclient.undo.compress.type=zipclient.undo.compress.threshold=64kclient.log.exceptionRate=100 微服务读取nacos配置接下来，需要修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件： 123456789seata: config: type: nacos nacos: server-addr: 127.0.0.1:8848 username: nacos password: nacos group: SEATA_GROUP data-id: client.properties 重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"seata","slug":"seata","permalink":"http://example.com/tags/seata/"}]},{"title":"分布式事务","slug":"笔记/技术2/分布式事务","date":"2022-11-13T05:10:51.200Z","updated":"2022-11-28T06:32:10.901Z","comments":true,"path":"2022/11/13/笔记/技术2/分布式事务/","link":"","permalink":"http://example.com/2022/11/13/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"分布式事务分布式事务问题本地事务本地事务，也就是传统的单机事务。在传统数据库事务中，必须要满足四个原则： 分布式事务分布式事务，就是指不是在单个服务或单个数据库架构下，产生的事务，例如： 跨数据源的分布式事务 跨服务的分布式事务 综合情况 在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。例如电商行业中比较常见的下单付款案例，包括下面几个行为： 创建新订单 扣减商品库存 从用户账户余额扣除金额 完成上面的操作需要访问三个不同的微服务和三个不同的数据库。 订单的创建、库存的扣减、账户扣款在每一个服务和数据库内是一个本地事务，可以保证ACID原则。 但是当我们把三件事情看做一个”业务”，要满足保证“业务”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是分布式系统下的事务了。 此时ACID难以满足，这是分布式事务要解决的问题 演示分布式事务问题我们通过一个案例来演示分布式事务的问题： 1）提供的微服务： 微服务结构如下： 其中： seata-demo：父工程，负责管理项目依赖 account-service：账户服务，负责管理用户的资金账户。提供扣减余额的接口 storage-service：库存服务，负责管理商品库存。提供扣减库存的接口 order-service：订单服务，负责管理订单。创建订单时，需要调用account-service和storage-service 2）启动nacos、所有微服务 3）测试下单功能，发出Post请求： 请求如下： 1curl --location --request POST 'http://localhost:8082/order?userId=user202103032042012&amp;commodityCode=100202003032041&amp;count=20&amp;money=200' 如图： 测试发现，当库存不足时，如果余额已经扣减，并不会回滚，出现了分布式事务问题。 理论基础解决分布式事务问题，需要一些分布式系统的基础知识作为理论指导。 CAP定理1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。 Consistency（一致性） Availability（可用性） Partition tolerance （分区容错性） 它们的第一个字母分别是 C、A、P。 Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 一致性Consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。 比如现在包含两个节点，其中的初始数据是一致的： 当我们修改其中一个节点的数据时，两者的数据产生了差异： 要想保住一致性，就必须实现node01 到 node02的数据 同步： 可用性Availability （可用性）：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝。 如图，有三个节点的集群，访问任何一个都可以及时得到响应： 当有部分节点因为网络故障或其它原因无法访问时，代表节点不可用： 分区容错Partition（分区）：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。 Tolerance（容错）：在集群出现分区时，整个系统也要持续对外提供服务 矛盾在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance不可避免。 当节点接收到新的数据变更时，就会出现问题了： 如果此时要保证一致性，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用。 如果此时要保证可用性，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致。 也就是说，在P一定会出现的情况下，A和C之间只能实现一个。 BASE理论BASE理论是对CAP的一种解决思路，包含三个思想： Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。 Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。 Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。 解决分布式事务的思路分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路： AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。 CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。 但不管是哪一种模式，都需要在子系统事务之间互相通讯，协调事务状态，也就是需要一个**事务协调者(TC)**： 这里的子系统事务，称为分支事务；有关联的各个分支事务在一起称为全局事务。 初识SeataSeata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。 官网地址：http://seata.io/其中的文档、播客中提供了大量的使用说明、源码分析。 Seata的架构Seata事务管理中有三个重要的角色： TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 整体的架构如图： Seata基于上述架构提供了四种不同的分布式事务解决方案： XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入 TCC模式：最终一致的分阶段事务模式，有业务侵入 AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式 SAGA模式：长事务模式，有业务侵入 无论哪种方案，都离不开TC，也就是事务的协调者。 微服务集成Seata我们以order-service为例来演示。 引入依赖首先，在order-service中引入依赖： 123456789101112131415161718&lt;!--seata--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;!--seata starter 采用1.4.2版本--&gt; &lt;version&gt;${seata.version}&lt;/version&gt;&lt;/dependency&gt; 配置TC地址在order-service中的application.yml中，配置TC服务信息，通过注册中心nacos，结合服务名称获取TC地址： 1234567891011121314seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 127.0.0.1:8848 # nacos地址 namespace: \"\" # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-tc-server # seata服务名称 username: nacos password: nacos tx-service-group: seata-demo # 事务组名称 service: vgroup-mapping: # 事务组与cluster的映射关系 seata-demo: SH 微服务如何根据这些配置寻找TC的地址呢？ 我们知道注册到Nacos中的微服务，确定一个具体实例需要四个信息： namespace：命名空间 group：分组 application：服务名 cluster：集群名 以上四个信息，在刚才的yaml文件中都能找到： namespace为空，就是默认的public 结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@SH，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。 其它服务其它两个微服务也都参考order-service的步骤来做，完全一样。 四种不同的事务模式下面我们就一起学习下Seata中的四种不同的事务模式。 XA模式XA 规范 是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准，XA 规范 描述了全局的TM与局部的RM之间的接口，几乎所有主流的数据库都对 XA 规范 提供了支持。 两阶段提交XA是规范，目前主流数据库都实现了这种规范，实现的原理都是基于两阶段提交。 正常情况： 异常情况： 一阶段： 事务协调者通知每个事物参与者执行本地事务 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁 二阶段： 事务协调者基于一阶段的报告来判断下一步操作 如果一阶段都成功，则通知所有事务参与者，提交事务 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务 Seata的XA模型Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型，基本架构如图： RM一阶段的工作： ​ ① 注册分支事务到TC ​ ② 执行分支业务sql但不提交 ​ ③ 报告执行状态到TC TC二阶段的工作： TC检测各分支事务执行状态 a.如果都成功，通知所有RM提交事务 b.如果有失败，通知所有RM回滚事务 RM二阶段的工作： 接收TC指令，提交或回滚事务 优缺点XA模式的优点是什么？ 事务的强一致性，满足ACID原则。 常用数据库都支持，实现简单，并且没有代码侵入 XA模式的缺点是什么？ 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差 依赖关系型数据库实现事务 实现XA模式Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下： 1）修改application.yml文件（每个参与事务的微服务），开启XA模式： 12seata: data-source-proxy-mode: XA 2）给发起全局事务的入口方法添加@GlobalTransactional注解: 本例中是OrderServiceImpl中的create方法. 3）重启服务并测试 重启order-service，再次测试，发现无论怎样，三个微服务都能成功回滚。 AT模式AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。 Seata的AT模型基本流程图： 阶段一RM的工作： 注册分支事务 记录undo-log（数据快照） 执行业务sql并提交 报告事务状态 阶段二提交时RM的工作： 删除undo-log即可 阶段二回滚时RM的工作： 根据undo-log恢复数据到更新前 流程梳理我们用一个真实的业务来梳理下AT模式的原理。 比如，现在又一个数据库表，记录用户余额： id money 1 100 其中一个分支业务要执行的SQL为： 1update tb_account set money = money - 10 where id = 1 AT模式下，当前分支事务执行流程如下： 一阶段： 1）TM发起并注册全局事务到TC 2）TM调用分支事务 3）分支事务准备执行业务SQL 4）RM拦截业务SQL，根据where条件查询原始数据，形成快照。 123{ \"id\": 1, \"money\": 100} 5）RM执行业务SQL，提交本地事务，释放数据库锁。此时 money = 90 6）RM报告本地事务状态给TC 二阶段： 1）TM通知TC事务结束 2）TC检查分支事务状态 ​ a）如果都成功，则立即删除快照 ​ b）如果有分支事务失败，需要回滚。读取快照数据（{\"id\": 1, \"money\": 100}），将快照恢复到数据库。此时数据库再次恢复为100 流程图： AT与XA的区别简述AT模式与XA模式最大的区别是什么？ XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。 XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。 XA模式强一致；AT模式最终一致 脏写问题在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图： 解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。 优缺点AT模式的优点： 一阶段完成直接提交事务，释放数据库资源，性能比较好 利用全局锁实现读写隔离 没有代码侵入，框架自动完成回滚和提交 AT模式的缺点： 两阶段之间属于软状态，属于最终一致 框架的快照功能会影响性能，但比XA模式要好很多 实现AT模式AT模式中的快照生成、回滚等动作都是由框架自动完成，没有任何代码侵入，因此实现非常简单。 只不过，AT模式需要一个表来记录全局锁、另一张表来记录数据快照undo_log。 1）导入数据库表，记录全局锁 2）修改application.yml文件，将事务模式修改为AT模式即可： 12seata: data-source-proxy-mode: AT # 默认就是AT 3）重启服务并测试 TCC模式TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法： Try：资源的检测和预留； Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。 Cancel：预留资源释放，可以理解为try的反向操作。 流程分析举例，一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。 阶段一（ Try ）：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30 初识余额： 余额充足，可以冻结： 此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。 **阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30 确认可以提交，不过之前可用金额已经扣减过了，这里只要清除冻结金额就好了： 此时，总金额 = 冻结金额 + 可用金额 = 0 + 70 = 70元 **阶段二(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30 需要回滚，那么就要释放冻结金额，恢复可用金额： Seata的TCC模型Seata中的TCC模型依然延续之前的事务架构，如图： 优缺点TCC模式的每个阶段是做什么的？ Try：资源检查和预留 Confirm：业务执行和提交 Cancel：预留资源的释放 TCC的优点是什么？ 一阶段完成直接提交事务，释放数据库资源，性能好 相比AT模型，无需生成快照，无需使用全局锁，性能最强 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库 TCC的缺点是什么？ 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦 软状态，事务是最终一致 需要考虑Confirm和Cancel的失败情况，做好幂等处理 事务悬挂和空回滚1）空回滚当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。 如图： 执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。 2）业务悬挂对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。 执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂 实现TCC模式解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在try、还是cancel？ 1）思路分析这里我们定义一张表： 12345678CREATE&nbsp;TABLE&nbsp;`account_freeze_tbl`&nbsp;(&nbsp;&nbsp;`xid`&nbsp;varchar(128)&nbsp;NOT&nbsp;NULL,&nbsp;&nbsp;`user_id`&nbsp;varchar(255)&nbsp;DEFAULT&nbsp;NULL&nbsp;COMMENT&nbsp;'用户id',&nbsp;&nbsp;`freeze_money`&nbsp;int(11)&nbsp;unsigned&nbsp;DEFAULT&nbsp;'0'&nbsp;COMMENT&nbsp;'冻结金额',&nbsp;&nbsp;`state`&nbsp;int(1)&nbsp;DEFAULT&nbsp;NULL&nbsp;COMMENT&nbsp;'事务状态，0:try，1:confirm，2:cancel',&nbsp;&nbsp;PRIMARY&nbsp;KEY&nbsp;(`xid`)&nbsp;USING&nbsp;BTREE)&nbsp;ENGINE=InnoDB&nbsp;DEFAULT&nbsp;CHARSET=utf8&nbsp;ROW_FORMAT=COMPACT; 其中： xid：是全局事务id freeze_money：用来记录用户冻结金额 state：用来记录事务状态 那此时，我们的业务开怎么做呢？ Try业务： 记录冻结金额和事务状态到account_freeze表 扣减account表可用金额 Confirm业务 根据xid删除account_freeze表的冻结记录 Cancel业务 修改account_freeze表，冻结金额为0，state为2 修改account表，恢复可用金额 如何判断是否空回滚？ cancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚 如何避免业务悬挂？ try业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务 接下来，我们改造account-service，利用TCC实现余额扣减功能。 2）声明TCC接口TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明， 我们在account-service项目中的cn.itcast.account.service包中新建一个接口，声明TCC三个接口： 123456789101112131415161718package cn.itcast.account.service;import io.seata.rm.tcc.api.BusinessActionContext;import io.seata.rm.tcc.api.BusinessActionContextParameter;import io.seata.rm.tcc.api.LocalTCC;import io.seata.rm.tcc.api.TwoPhaseBusinessAction;@LocalTCCpublic interface AccountTCCService { @TwoPhaseBusinessAction(name = \"deduct\", commitMethod = \"confirm\", rollbackMethod = \"cancel\") void deduct(@BusinessActionContextParameter(paramName = \"userId\") String userId, @BusinessActionContextParameter(paramName = \"money\")int money); boolean confirm(BusinessActionContext ctx); boolean cancel(BusinessActionContext ctx);} 3）编写实现类在account-service服务中的cn.itcast.account.service.impl包下新建一个类，实现TCC业务： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.itcast.account.service.impl;import cn.itcast.account.entity.AccountFreeze;import cn.itcast.account.mapper.AccountFreezeMapper;import cn.itcast.account.mapper.AccountMapper;import cn.itcast.account.service.AccountTCCService;import io.seata.core.context.RootContext;import io.seata.rm.tcc.api.BusinessActionContext;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@Service@Slf4jpublic class AccountTCCServiceImpl implements AccountTCCService { @Autowired private AccountMapper accountMapper; @Autowired private AccountFreezeMapper freezeMapper; @Override @Transactional public void deduct(String userId, int money) { // 0.获取事务id String xid = RootContext.getXID(); // 1.扣减可用余额 accountMapper.deduct(userId, money); // 2.记录冻结金额，事务状态 AccountFreeze freeze = new AccountFreeze(); freeze.setUserId(userId); freeze.setFreezeMoney(money); freeze.setState(AccountFreeze.State.TRY); freeze.setXid(xid); freezeMapper.insert(freeze); } @Override public boolean confirm(BusinessActionContext ctx) { // 1.获取事务id String xid = ctx.getXid(); // 2.根据id删除冻结记录 int count = freezeMapper.deleteById(xid); return count == 1; } @Override public boolean cancel(BusinessActionContext ctx) { // 0.查询冻结记录 String xid = ctx.getXid(); AccountFreeze freeze = freezeMapper.selectById(xid); // 1.恢复可用余额 accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney()); // 2.将冻结金额清零，状态改为CANCEL freeze.setFreezeMoney(0); freeze.setState(AccountFreeze.State.CANCEL); int count = freezeMapper.updateById(freeze); return count == 1; }} SAGA模式Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。 其理论基础是Hector &amp; Kenneth 在1987年发表的论文Sagas。 Seata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html 原理在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。 分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。 Saga也分为两个阶段： 一阶段：直接提交本地事务 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚 优缺点优点： 事务参与者可以基于事件驱动实现异步调用，吞吐高 一阶段直接提交事务，无锁，性能好 不用编写TCC中的三个阶段，实现简单 缺点： 软状态持续时间不确定，时效性差 没有锁，没有事务隔离，会有脏写 四种模式对比我们从以下几个方面来对比四种实现： 一致性：能否保证事务的一致性？强一致还是最终一致？ 隔离性：事务之间的隔离性如何？ 代码侵入：是否需要对业务代码改造？ 性能：有无性能损耗？ 场景：常见的业务场景 如图： 高可用Seata的TC服务作为分布式事务核心，一定要保证集群的高可用性。 高可用架构模型搭建TC服务集群非常简单，启动多个TC服务，注册到nacos即可。 但集群并不能确保100%安全，万一集群所在机房故障怎么办？所以如果要求较高，一般都会做异地多机房容灾。 比如一个TC集群在上海，另一个TC集群在杭州： 微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"微服务保护2","slug":"笔记/技术2/微服务保护2","date":"2022-11-10T05:47:56.026Z","updated":"2022-11-28T08:15:42.534Z","comments":true,"path":"2022/11/10/笔记/技术2/微服务保护2/","link":"","permalink":"http://example.com/2022/11/10/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A42/","excerpt":"","text":"微服务保护隔离和降级限流是一种预防措施，虽然限流可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。 而要将这些故障控制在一定范围，避免雪崩，就要靠线程隔离（舱壁模式）和熔断降级手段了。 线程隔离之前讲到过：调用者在调用服务提供者时，给每个调用的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽。 熔断降级：是在调用方这边加入断路器，统计对服务提供者的调用，如果调用的失败比例过高，则熔断该业务，不允许访问该服务的提供者了。 可以看到，不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方 发起远程调用时做线程隔离、或者服务熔断。 而我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。 FeignClient整合SentinelSpringCloud中，微服务调用都是通过Feign来实现的，因此做客户端保护必须整合Feign和Sentinel。 修改配置，开启sentinel功能修改OrderService的application.yml文件，开启Feign的Sentinel功能： 123feign: sentinel: enabled: true # 开启feign对sentinel的支持 编写失败降级逻辑业务失败后，不能直接报错，而应该返回用户一个友好提示或者默认结果，这个就是失败降级逻辑。 给FeignClient编写失败后的降级逻辑 ①方式一：FallbackClass，无法对远程调用的异常做处理 ②方式二：FallbackFactory，可以对远程调用的异常做处理，我们选择这种 这里我们演示方式二的失败降级处理。 步骤一：在feing-api项目中定义类，实现FallbackFactory： 代码： 123456789101112131415161718192021package cn.itcast.feign.clients.fallback;import cn.itcast.feign.clients.UserClient;import cn.itcast.feign.pojo.User;import feign.hystrix.FallbackFactory;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class UserClientFallbackFactory implements FallbackFactory&lt;UserClient&gt; { @Override public UserClient create(Throwable throwable) { return new UserClient() { @Override public User findById(Long id) { log.error(\"查询用户异常\", throwable); return new User(); } }; }} 步骤二：在feing-api项目中的DefaultFeignConfiguration类中将UserClientFallbackFactory注册为一个Bean： 1234@Beanpublic UserClientFallbackFactory userClientFallbackFactory(){ return new UserClientFallbackFactory();} 步骤三：在feing-api项目中的UserClient接口中使用UserClientFallbackFactory： 123456789101112import cn.itcast.feign.clients.fallback.UserClientFallbackFactory;import cn.itcast.feign.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"userservice\", fallbackFactory = UserClientFallbackFactory.class)public interface UserClient { @GetMapping(\"/user/{id}\") User findById(@PathVariable(\"id\") Long id);} 重启后，访问一次订单查询业务，然后查看sentinel控制台，可以看到新的簇点链路： 总结Sentinel支持的雪崩解决方案： 线程隔离（仓壁模式） 降级熔断 Feign整合Sentinel的步骤： 在application.yml中配置：feign.sentienl.enable=true 给FeignClient编写FallbackFactory并注册为Bean 将FallbackFactory配置到FeignClient 线程隔离（舱壁模式）线程隔离的实现方式线程隔离有两种方式实现： 线程池隔离 信号量隔离（Sentinel默认采用） 如图： 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果 信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。 两者的优缺点： sentinel的线程隔离用法说明： 在添加限流规则时，可以选择两种阈值类型： QPS：就是每秒的请求数，在快速入门中已经演示过 线程数：是该资源能使用用的tomcat线程数的最大值。也就是通过限制线程数量，实现线程隔离（舱壁模式）。 案例需求：给 order-service服务中的UserClient的查询用户接口设置流控规则，线程数不能超过 2。然后利用jemeter测试。 1）配置隔离规则选择feign接口后面的流控按钮： 填写表单： 2）Jmeter测试选择《阈值类型-线程数&lt;2》： 一次发生10个请求，有较大概率并发线程数超过2，而超出的请求会走之前定义的失败降级逻辑。 查看运行结果： 发现虽然结果都是通过了，不过部分请求得到的响应是降级返回的null信息。 总结线程隔离的两种手段是？ 信号量隔离 线程池隔离 信号量隔离的特点是？ 基于计数器模式，简单，开销小 线程池隔离的特点是？ 基于线程池模式，有额外开销，但隔离控制更强 熔断降级熔断降级是解决雪崩问题的重要手段。其思路是由断路器统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。 断路器控制熔断和放行是通过状态机来完成的： 状态机包括三个状态： closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态 open：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态 half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。 请求成功：则切换到closed状态 请求失败：则切换到open状态 断路器熔断策略有三种：慢调用、异常比例、异常数 慢调用慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。 例如： 解读：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。 案例 需求：给 UserClient的查询用户接口设置降级规则，慢调用的RT阈值为50ms，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5 1）设置慢调用修改user-service中的/user/{id}这个接口的业务。通过休眠模拟一个延迟时间： 此时，orderId=101的订单，关联的是id为1的用户，调用时长为60ms： orderId=102的订单，关联的是id为2的用户，调用时长为非常短； 2）设置熔断规则下面，给feign接口设置降级规则： 规则： 超过50ms的请求都会被认为是慢请求 3）测试在浏览器访问：http://localhost:8088/order/101，快速刷新5次，可以发现： 触发了熔断，请求时长缩短至5ms，快速失败了，并且走降级逻辑，返回的null 在浏览器访问：http://localhost:8088/order/102，竟然也被熔断了： 异常比例、异常数异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断。 例如，一个异常比例设置： 解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.4，则触发熔断。 一个异常数设置： 解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于2次，则触发熔断。 案例 需求：给 UserClient的查询用户接口设置降级规则，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5s 1）设置异常请求首先，修改user-service中的/user/{id}这个接口的业务。手动抛出异常，以触发异常比例的熔断： 也就是说，id 为 2时，就会触发异常 2）设置熔断规则下面，给feign接口设置降级规则： 规则： 在5次请求中，只要异常比例超过0.4，也就是有2次以上的异常，就会触发熔断。 3）测试在浏览器快速访问：http://localhost:8088/order/102，快速刷新5次，触发熔断： 此时，我们去访问本来应该正常的103： 授权规则授权规则可以对请求方来源做判断和控制。 授权规则基本规则授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。 白名单：来源（origin）在白名单内的调用者允许访问 黑名单：来源（origin）在黑名单内的调用者不允许访问 点击左侧菜单的授权，可以看到授权规则： 资源名：就是受保护的资源，例如/order/{orderId} 流控应用：是来源者的名单， 如果是勾选白名单，则名单中的来源被许可访问。 如果是勾选黑名单，则名单中的来源被禁止访问。 比如： 我们允许请求从gateway到order-service，不允许浏览器访问order-service，那么白名单中就要填写网关的来源名称（origin）。 如何获取originSentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。 123456public interface RequestOriginParser { /** * 从请求request对象中获取origin，获取方式自定义 */ String parseOrigin(HttpServletRequest request);} 这个方法的作用就是从request对象中，获取请求者的origin值并返回。 默认情况下，sentinel不管请求者从哪里来，返回值永远是default，也就是说一切请求的来源都被认为是一样的值default。 因此，我们需要自定义这个接口的实现，让不同的请求，返回不同的origin。 例如order-service服务中，我们定义一个RequestOriginParser的实现类： 123456789101112131415161718192021package cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import javax.servlet.http.HttpServletRequest;@Componentpublic class HeaderOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { // 1.获取请求头 String origin = request.getHeader(\"origin\"); // 2.非空判断 if (StringUtils.isEmpty(origin)) { origin = \"blank\"; } return origin; }} 我们会尝试从request-header中获取origin值。 给网关添加请求头既然获取请求origin的方式是从reques-header中获取origin值，我们必须让所有从gateway路由到微服务的请求都带上origin头。 这个需要利用之前学习的一个GatewayFilter来实现，AddRequestHeaderGatewayFilter。 修改gateway服务中的application.yml，添加一个defaultFilter： 1234567spring: cloud: gateway: default-filters: - AddRequestHeader=origin,gateway routes: # ...略 这样，从gateway路由的所有请求都会带上origin头，值为gateway。而从其它地方到达微服务的请求则没有这个头。 配置授权规则接下来，我们添加一个授权规则，放行origin值为gateway的请求。 配置如下： 现在，我们直接跳过网关，访问order-service服务： 通过网关访问： 自定义异常结果默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。 异常类型而如果要自定义异常时的返回结果，需要实现BlockExceptionHandler接口： 123456public interface BlockExceptionHandler { /** * 处理请求被限流、降级、授权拦截时抛出的异常：BlockException */ void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception;} 这个方法有三个参数： HttpServletRequest request：request对象 HttpServletResponse response：response对象 BlockException e：被sentinel拦截时抛出的异常 这里的BlockException包含多个不同的子类： 异常 说明 FlowException 限流异常 ParamFlowException 热点参数限流的异常 DegradeException 降级异常 AuthorityException 授权规则异常 SystemBlockException 系统规则异常 自定义异常处理下面，我们就在order-service定义一个自定义异常处理类： 123456789101112131415161718192021222324252627282930313233343536package cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.alibaba.csp.sentinel.slots.block.authority.AuthorityException;import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException;import com.alibaba.csp.sentinel.slots.block.flow.FlowException;import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException;import org.springframework.stereotype.Component;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Componentpublic class SentinelExceptionHandler implements BlockExceptionHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { String msg = \"未知异常\"; int status = 429; if (e instanceof FlowException) { msg = \"请求被限流了\"; } else if (e instanceof ParamFlowException) { msg = \"请求被热点参数限流\"; } else if (e instanceof DegradeException) { msg = \"请求被降级了\"; } else if (e instanceof AuthorityException) { msg = \"没有权限访问\"; status = 401; } response.setContentType(\"application/json;charset=utf-8\"); response.setStatus(status); response.getWriter().println(\"{\\\"msg\\\": \" + msg + \", \\\"status\\\": \" + status + \"}\"); }} 重启测试，在不同场景下，会返回不同的异常消息. 限流： 授权拦截时： 规则持久化现在，sentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，我们必须确保这些规则的持久化，避免丢失。 规则管理模式规则是否能持久化，取决于规则管理模式，sentinel支持三种规则管理模式： 原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。 pull模式 push模式 pull模式pull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则。 push模式push模式：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"微服务保护1","slug":"笔记/技术2/微服务保护1","date":"2022-11-10T05:34:43.193Z","updated":"2022-11-28T06:32:10.907Z","comments":true,"path":"2022/11/10/笔记/技术2/微服务保护1/","link":"","permalink":"http://example.com/2022/11/10/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A41/","excerpt":"","text":"微服务保护雪崩问题及解决方案雪崩问题微服务中，服务间调用关系错综复杂，一个微服务往往依赖于多个其它微服务。 如果服务提供者I发生了故障，当前的应用的部分业务因为依赖于服务I，因此也会被阻塞。此时，其它不依赖于服务I的业务似乎不受影响。 但是，依赖服务I的业务请求被阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞： 服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，那么当前服务也就不可用了。 那么，依赖于当前服务的其它服务随着时间的推移，最终也都会变的不可用，形成级联失败，雪崩就发生了： 超时处理解决雪崩问题的常见方式有四种： •超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待 仓壁模式方案2：仓壁模式 仓壁模式来源于船舱的设计： 船舱都会被隔板分离为多个独立空间，当船体破损时，只会导致部分空间进入，将故障控制在一定范围内，避免整个船体都被淹没。 于此类似，我们可以限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离。 断路器断路器模式：由断路器统计业务执行的异常比例，如果超出阈值则会熔断该业务，拦截访问该业务的一切请求。 断路器会统计访问某个服务的请求数量，异常比例： 当发现访问服务D的请求异常比例过高时，认为服务D有导致雪崩的风险，会拦截访问服务D的一切请求，形成熔断： 限流流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。 总结什么是雪崩问题？ 微服务之间相互调用，因为调用链中的一个服务故障，引起整个链路都无法访问的情况。 可以认为： 限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。 超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。 流量控制雪崩问题虽然有四种方案，但是限流是避免服务因突发的流量而发生故障，是对微服务雪崩问题的预防。我们先学习这种模式。 簇点链路当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。 默认情况下sentinel会监控SpringMVC的每一个端点（Endpoint，也就是controller中的方法），因此SpringMVC的每一个端点（Endpoint）就是调用链路中的一个资源。 例如，我们刚才访问的order-service中的OrderController中的端点：/order/{orderId} 流控、熔断等都是针对簇点链路中的资源来设置的，因此我们可以点击对应资源后面的按钮来设置规则： 流控：流量控制 降级：降级熔断 热点：热点参数限流，是限流的一种 授权：请求的权限控制 快速入门示例点击资源/order/{orderId}后面的流控按钮，就可以弹出表单。 表单中可以填写限流规则，如下： 其含义是限制 /order/{orderId}这个资源的单机QPS为1，即每秒只允许1次请求，超出的请求会被拦截并报错。 练习：需求：给 /order/{orderId}这个资源设置流控规则，QPS不能超过 5，然后测试。 1）首先在sentinel控制台添加限流规则 2）利用jmeter测试 选择： 20个用户，2秒内运行完，QPS是10，超过了5. 选中流控入门，QPS&lt;5右键运行： 注意，不要点击菜单中的执行按钮来运行。 结果： 可以看到，成功的请求每次只有5个 流控模式在添加限流规则时，点击高级选项，可以选择三种流控模式： 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流 快速入门测试的就是直接模式。 关联模式关联模式：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 配置规则： 语法说明：当/write资源访问量触发阈值时，就会对/read资源限流，避免影响/write资源。 使用场景：比如用户支付时需要修改订单状态，同时用户要查询订单。查询和修改操作会争抢数据库锁，产生竞争。业务需求是优先支付和更新订单的业务，因此当修改订单业务触发阈值时，需要对查询订单业务限流。 需求说明： 在OrderController新建两个端点：/order/query和/order/update，无需实现业务 配置流控规则，当/order/ update资源被访问的QPS超过5时，对/order/query请求限流 1）定义/order/query端点，模拟订单查询 1234@GetMapping(\"/query\")public String queryOrder() { return \"查询订单成功\";} 2）定义/order/update端点，模拟订单更新 1234@GetMapping(\"/update\")public String updateOrder() { return \"更新订单成功\";} 重启服务，查看sentinel控制台的簇点链路： 3）配置流控规则 对哪个端点限流，就点击哪个端点后面的按钮。我们是对订单查询/order/query限流，因此点击它后面的按钮： 在表单中填写流控规则： 4）在Jmeter测试 选择《流控模式-关联》： 可以看到1000个用户，100秒，因此QPS为10，超过了我们设定的阈值：5 查看http请求： 请求的目标是/order/update，这样这个断点就会触发阈值。 但限流的目标是/order/query，我们在浏览器访问，可以发现： 确实被限流了。 5）总结 链路模式链路模式：只针对从指定链路访问到本资源的请求做统计，判断是否超过阈值。 配置示例： 例如有两条请求链路： /test1 –&gt; /common /test2 –&gt; /common 如果只希望统计从/test2进入到/common的请求，则可以这样配置： 实战案例 需求：有查询订单和创建订单业务，两者都需要查询商品。针对从查询订单进入到查询商品的请求统计，并设置限流。 步骤： 在OrderService中添加一个queryGoods方法，不用实现业务 在OrderController中，改造/order/query端点，调用OrderService中的queryGoods方法 在OrderController中添加一个/order/save的端点，调用OrderService的queryGoods方法 给queryGoods设置限流规则，从/order/query进入queryGoods的方法限制QPS必须小于2 实现： 1）添加查询商品方法在order-service服务中，给OrderService类添加一个queryGoods方法： 123public void queryGoods(){ System.err.println(\"查询商品\");} 2）查询订单时，查询商品在order-service的OrderController中，修改/order/query端点的业务逻辑： 12345678@GetMapping(\"/query\")public String queryOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.out.println(\"查询订单\"); return \"查询订单成功\";} 3）新增订单，查询商品在order-service的OrderController中，修改/order/save端点，模拟新增订单： 12345678@GetMapping(\"/save\")public String saveOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.err.println(\"新增订单\"); return \"新增订单成功\";} 4）给查询商品添加资源标记默认情况下，OrderService中的方法是不被Sentinel监控的，需要我们自己通过注解来标记要监控的方法。 给OrderService的queryGoods方法添加@SentinelResource注解： 1234@SentinelResource(\"goods\")public void queryGoods(){ System.err.println(\"查询商品\");} 链路模式中，是对不同来源的两个链路做监控。但是sentinel默认会给进入SpringMVC的所有请求设置同一个root资源，会导致链路模式失效。 我们需要关闭这种对SpringMVC的资源聚合，修改order-service服务的application.yml文件： 1234spring: cloud: sentinel: web-context-unify: false # 关闭context整合 重启服务，访问/order/query和/order/save，可以查看到sentinel的簇点链路规则中，出现了新的资源： 5）添加流控规则点击goods资源后面的流控按钮，在弹出的表单中填写下面信息： 只统计从/order/query进入/goods的资源，QPS阈值为2，超出则被限流。 6）Jmeter测试选择《流控模式-链路》： 可以看到这里200个用户，50秒内发完，QPS为4，超过了我们设定的阈值2 一个http请求是访问/order/save： 运行的结果： 完全不受影响。 另一个是访问/order/query： 运行结果： 每次只有2个通过。 总结流控模式有哪些？ •直接：对当前资源限流 •关联：高优先级资源触发阈值，对低优先级资源限流。 •链路：阈值统计时，只统计从指定资源进入当前资源的请求，是对请求来源的限流 流控效果在流控的高级选项中，还有一个流控效果选项： 流控效果是指请求达到流控阈值时应该采取的措施，包括三种： 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。 warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长 warm up阈值一般是一个微服务能承担的最大QPS，但是一个服务刚刚启动时，一切资源尚未初始化（冷启动），如果直接将QPS跑到最大值，可能导致服务瞬间宕机。 warm up也叫预热模式，是应对服务冷启动的一种方案。请求阈值初始值是 maxThreshold / coldFactor，持续指定时长后，逐渐提高到maxThreshold值。而coldFactor的默认值是3. 例如，我设置QPS的maxThreshold为10，预热时间为5秒，那么初始阈值就是 10 / 3 ，也就是3，然后在5秒后逐渐增长到10. 案例 需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用warm up效果，预热时长为5秒 1）配置流控规则： 2）Jmeter测试选择《流控效果，warm up》： QPS为10. 刚刚启动时，大部分请求失败，成功的只有3个，说明QPS被限定在3： 随着时间推移，成功比例越来越高： 到Sentinel控制台查看实时监控： 一段时间后： 排队等待当请求超过QPS阈值时，快速失败和warm up 会拒绝新的请求并抛出异常。 而排队等待则是让所有请求进入一个队列中，然后按照阈值允许的时间间隔依次执行。后来的请求必须等待前面执行完成，如果请求预期的等待时间超出最大时长，则会被拒绝。 工作原理 例如：QPS = 5，意味着每200ms处理一个队列中的请求；timeout = 2000，意味着预期等待时长超过2000ms的请求会被拒绝并抛出异常。 那什么叫做预期等待时长呢？ 比如现在一下子来了12 个请求，因为每200ms执行一个请求，那么： 第6个请求的预期等待时长 = 200 * （6 - 1） = 1000ms 第12个请求的预期等待时长 = 200 * （12-1） = 2200ms 现在，第1秒同时接收到10个请求，但第2秒只有1个请求，此时QPS的曲线这样的： 如果使用队列模式做流控，所有进入的请求都要排队，以固定的200ms的间隔执行，QPS会变的很平滑： 平滑的QPS曲线，对于服务器来说是更友好的。 案例 需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用排队的流控效果，超时时长设置为5s 1）添加流控规则 2）Jmeter测试选择《流控效果，队列》： QPS为15，已经超过了我们设定的10。 如果是之前的 快速失败、warmup模式，超出的请求应该会直接报错。 但是我们看看队列模式的运行结果： 全部都通过了。 再去sentinel查看实时监控的QPS曲线： QPS非常平滑，一致保持在10，但是超出的请求没有被拒绝，而是放入队列。因此响应时间（等待时间）会越来越长。 当队列满了以后，才会有部分请求失败： 总结流控效果有哪些？ 快速失败：QPS超过阈值时，拒绝新的请求 warm up： QPS超过阈值时，拒绝新的请求；QPS阈值是逐渐提升的，可以避免冷启动时高并发导致服务宕机。 排队等待：请求会进入队列，按照阈值允许的时间间隔依次执行请求；如果请求预期等待时长大于超时时间，直接拒绝 热点参数限流之前的限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是分别统计参数值相同的请求，判断是否超过QPS阈值。 全局参数限流例如，一个根据id查询商品的接口： 访问/goods/{id}的请求中，id参数值会有变化，热点参数限流会根据参数值分别统计QPS，统计结果： 当id=1的请求触发阈值被限流时，id值不为1的请求不受影响。 配置示例： 代表的含义是：对hot这个资源的0号参数（第一个参数）做统计，每1秒相同参数值的请求数不能超过5 热点参数限流刚才的配置中，对查询商品这个接口的所有商品一视同仁，QPS都限定为5. 而在实际开发中，可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的QPS限制与其它商品不一样，高一些。那就需要配置热点参数限流的高级选项了： 结合上一个配置，这里的含义是对0号的long类型参数限流，每1秒相同参数的QPS不能超过5，有两个例外： •如果参数值是100，则每1秒允许的QPS为10 •如果参数值是101，则每1秒允许的QPS为15 案例案例需求：给/order/{orderId}这个资源添加热点参数限流，规则如下： •默认的热点参数规则是每1秒请求量不超过2 •给102这个参数设置例外：每1秒请求量不超过4 •给103这个参数设置例外：每1秒请求量不超过10 注意事项：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource注解标记资源 1）标记资源给order-service中的OrderController中的/order/{orderId}资源添加注解： 2）热点参数限流规则访问该接口，可以看到我们标记的hot资源出现了： 这里不要点击hot后面的按钮，页面有BUG 点击左侧菜单中热点规则菜单： 点击新增，填写表单： 3）Jmeter测试选择《热点参数限流 QPS1》： 这里发起请求的QPS为5. 包含3个http请求： 普通参数，QPS阈值为2 运行结果： 例外项，QPS阈值为4 运行结果： 例外项，QPS阈值为10 运行结果：","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"Sentinel介绍和安装","slug":"笔记/安装部署/sentinel","date":"2022-11-08T09:04:09.208Z","updated":"2022-11-28T10:13:40.247Z","comments":true,"path":"2022/11/08/笔记/安装部署/sentinel/","link":"","permalink":"http://example.com/2022/11/08/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/sentinel/","excerpt":"","text":"服务保护技术对比在SpringCloud当中支持多种服务保护技术： Netfix Hystrix Sentinel Resilience4J 早期比较流行的是Hystrix框架，但目前国内实用最广泛的还是阿里巴巴的Sentinel框架，这里我们做下对比： Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于慢调用比例或异常比例 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 流量整形 支持慢启动、匀速排队模式 不支持 系统自适应保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix Sentinel介绍和安装初识SentinelSentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：https://sentinelguard.io/zh-cn/index.html Sentinel 具有以下特征: •丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 •完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 •广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 •完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 安装Sentinel1）下载 sentinel官方提供了UI控制台，方便我们对系统做限流设置。大家可以在GitHub下载。 课前资料也提供了下载好的jar包： 2）运行 将jar包放到任意非中文目录，执行命令： 1java -jar sentinel-dashboard-1.8.1.jar 如果要修改Sentinel的默认端口、账户、密码，可以通过下列配置： 配置项 默认值 说明 server.port 8080 服务端口 sentinel.dashboard.auth.username sentinel 默认用户名 sentinel.dashboard.auth.password sentinel 默认密码 例如，修改端口： 1java -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar 3）访问 访问http://localhost:8080页面，就可以看到sentinel的控制台了： 需要输入账号和密码，默认都是：sentinel 登录后，发现一片空白，什么都没有： 这是因为我们还没有与微服务整合。 微服务整合Sentinel我们在order-service中整合sentinel，并连接sentinel的控制台，步骤如下： 1）引入sentinel依赖 12345&lt;!--sentinel--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置控制台 修改application.yaml文件，添加下面内容： 1234567server: port: 8088spring: cloud: sentinel: transport: dashboard: localhost:8080 3）访问order-service的任意端点 打开浏览器，访问http://localhost:8088/order/101，这样才能触发sentinel的监控。 然后再访问sentinel的控制台，查看效果：","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"sentinel","slug":"sentinel","permalink":"http://example.com/tags/sentinel/"}]},{"title":"双指针移动数组元素","slug":"算法/数组/双指针移动数组元素","date":"2022-10-14T10:38:05.496Z","updated":"2023-02-07T09:24:59.211Z","comments":true,"path":"2022/10/14/算法/数组/双指针移动数组元素/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/%E5%8F%8C%E6%8C%87%E9%92%88%E7%A7%BB%E5%8A%A8%E6%95%B0%E7%BB%84%E5%85%83%E7%B4%A0/","excerpt":"","text":"双指针移动数组元素:26.删除有序数组中的重复项 [简] 27.移除元素 [简] * 283.移动零 [简] 思路:数组元素移动一般用双指针解法，对于诸如「相同元素最多保留 k 位元素」或者「移除特定元素」的问题，更好的做法是从题目本身性质出发，利用题目给定的要求提炼出具体的「保留逻辑」，将「保留逻辑」应用到我们的遍历到的每一个位置。 26.删除有序数组中的重复项 [简]123456789101112class Solution { public int removeDuplicates(int[] nums) { int n = nums.length; int left = 0; for (int right = 0; right &lt; n; right++) { if (nums[right] != nums[left]) { nums[++left] = nums[right]; } } return left + 1; }} 27.移除元素 [简]12345678910111213class Solution { public int removeElement(int[] nums, int val) { int n = nums.length; int left = 0; for (int right = 0; right &lt; n; right++) { if (nums[right] != val) { nums[left] = nums[right]; left++; } } return left; }} 283.移动零 [简]双指针解法移动零时间复杂度过高 123456789101112131415161718class Solution { public void moveZeroes(int[] nums) { int n = nums.length; int left = 0; for (int right = 0; right &lt; n; right++) { if (nums[right] != 0) { swap(nums,left,right); left++; } } } void swap(int[] nums, int left, int right) { int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; }} 遍历数组，遇到非0数，前面有几个0就往前面移动几格 12345678910111213141516class Solution { public void moveZeroes(int[] nums) { int n=nums.length; int t=0; for(int i=0;i&lt;n;i++){ if(nums[i]==0){ ++t; }else{ nums[i-t]=nums[i]; } } for(int i=n-1;i&gt;n-t-1;--i){ nums[i]=0; } }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"滑动窗口","slug":"算法/滑动窗口","date":"2022-10-14T10:38:05.480Z","updated":"2023-02-11T10:40:19.985Z","comments":true,"path":"2022/10/14/算法/滑动窗口/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/","excerpt":"","text":"滑动窗口:3.无重复字符的最长子串 [中] * 567.字符串中的变位词,字符串的排列 [中] 438.找到字符串中所有字母异位词 [中] * 76.最小覆盖子串,含有所有字符的最短字符串 [难] * 3,76,438,567同一类型,能共用一套模板map解法时间复杂度均较高，用数组更快 12345678910111213141516171819202122232425262728/* 滑动窗口算法框架 */void slidingWindow(string s) { unordered_map&lt;char, int&gt; window; int left = 0, right = 0; while (right &lt; s.size()) { // c 是将移入窗口的字符 char c = s[right]; // 增大窗口 right++; // 进行窗口内数据的一系列更新 ... /*** debug 输出的位置 ***/ printf(\"window: [%d, %d)\\n\", left, right); /********************/ // 判断左侧窗口是否要收缩 while (window needs shrink) { // d 是将移出窗口的字符 char d = s[left]; // 缩小窗口 left++; // 进行窗口内数据的一系列更新 ... } }} 3.无重复字符的最长子串 [中]注意 1,窗口的收缩条件 2,最长子串的取值 1234567891011121314151617181920class Solution { public int lengthOfLongestSubstring(String s) { HashMap&lt;Character,Integer&gt; window = new HashMap&lt;&gt;(); int left = 0; int right = 0; int maxLen = 0; while(right &lt; s.length()){ char r = s.charAt(right); right ++; window.put(r,window.getOrDefault(r,0) + 1); while(window.get(r) &gt; 1){ char l = s.charAt(left); left ++; window.put(l,window.get(l) - 1); } maxLen = Math.max(maxLen,right - left); } return maxLen; }} 用数组代替map 12345678910111213141516171819class Solution { public int lengthOfLongestSubstring(String s) { int[] last = new int[128]; int left = 0, right = 0; int maxLen = 0; while (right &lt; s.length()) { char r = s.charAt(right); right ++; last[r] ++; while (last[r] &gt; 1) { char l = s.charAt(left); left ++; last[l] --; } maxLen = Math.max(maxLen,right - left); } return maxLen; }} 76.最小覆盖子串,含有所有字符的最短字符串 [难]注意： 1, containsKey 2，Map中value的比较要用equals方法 3, 字符串长度的截取 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public String minWindow(String s, String t) { HashMap&lt;Character,Integer&gt; window = new HashMap&lt;&gt;(); HashMap&lt;Character,Integer&gt; need = new HashMap&lt;&gt;(); for(int i = 0;i &lt; t.length();i ++){ char c = t.charAt(i); need.put(c,need.getOrDefault(c,0) + 1); } int left = 0,right = 0; int count = 0; int start = 0; int len = Integer.MAX_VALUE; while(right &lt; s.length()){ char r = s.charAt(right); right ++; if(need.containsKey(r)){ window.put(r,window.getOrDefault(r,0) + 1); if(window.get(r).equals(need.get(r))){ count ++; } } while(need.size() == count){ if(right - left &lt; len){ len = right - left; start = left; } char l = s.charAt(left); left ++; if(window.containsKey(l)){ if(window.get(l).equals(need.get(l))){ count --; } window.put(l,window.get(l) - 1); } } } return len == Integer.MAX_VALUE ? \"\" : s.substring(start,start+len); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution { public String minWindow(String s, String t) { if (s == null || s == \"\" || t == null || t == \"\" || s.length() &lt; t.length()) { return \"\"; } int[] need = new int[128]; int[] have = new int[128]; for (int i = 0; i &lt; t.length(); i++) { need[t.charAt(i)]++; } int left = 0, right = 0, min = s.length() + 1, count = 0, start = 0; while (right &lt; s.length()) { char r = s.charAt(right); if (need[r] == 0) { right++; continue; } if (have[r] &lt; need[r]) { count++; } have[r]++; right++; while (count == t.length()) { if (right - left &lt; min) { min = right - left; start = left; } char l = s.charAt(left); if (need[l] == 0) { left++; continue; } if (have[l] == need[l]) { count--; } have[l]--; left++; } } if (min == s.length() + 1) { return \"\"; } return s.substring(start, start + min); }} 438.找到字符串中所有字母异位词 [中]12345678910111213141516171819202122232425262728293031323334353637class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { HashMap&lt;Character,Integer&gt; window = new HashMap&lt;&gt;(); HashMap&lt;Character,Integer&gt; need = new HashMap&lt;&gt;(); List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); int left = 0,right = 0; int count = 0; for(int i = 0;i &lt; p.length();i ++){ char c = p.charAt(i); need.put(c,need.getOrDefault(c,0) + 1); } while(right &lt; s.length()){ char r = s.charAt(right); right ++; if(need.containsKey(r)){ window.put(r,window.getOrDefault(r,0) + 1); if(window.get(r).equals(need.get(r))){ count ++; } } while(right - left == p.length()){ if(need.size() == count){ list.add(left); } char l = s.charAt(left); left ++; if(need.containsKey(l)){ if(window.get(l).equals(need.get(l))){ count --; } window.put(l,window.getOrDefault(l,0) - 1); } } } return list; }} 12345678910111213141516171819202122232425262728293031class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { int sLen = s.length(), pLen = p.length(); if (sLen &lt; pLen) { return new ArrayList&lt;Integer&gt;(); } List&lt;Integer&gt; ans = new ArrayList&lt;Integer&gt;(); int[] sCount = new int[26]; int[] pCount = new int[26]; for (int i = 0; i &lt; pLen; ++i) { ++sCount[s.charAt(i) - 'a']; ++pCount[p.charAt(i) - 'a']; } if (Arrays.equals(sCount, pCount)) { ans.add(0); } for (int i = 0; i &lt; sLen - pLen; ++i) { --sCount[s.charAt(i) - 'a']; ++sCount[s.charAt(i + pLen) - 'a']; if (Arrays.equals(sCount, pCount)) { ans.add(i + 1); } } return ans; }} 567.字符串中的变位词,字符串的排列 [中]123456789101112131415161718192021222324252627282930313233343536class Solution { public boolean checkInclusion(String s1, String s2) { HashMap&lt;Character,Integer&gt; window = new HashMap&lt;&gt;(); HashMap&lt;Character,Integer&gt; need = new HashMap&lt;&gt;(); for(int i = 0;i &lt; s1.length();i ++){ char c = s1.charAt(i); need.put(c,need.getOrDefault(c,0) + 1); } int left = 0,right = 0; int count = 0; while(right &lt; s2.length()){ char r = s2.charAt(right); right ++; if(need.containsKey(r)){ window.put(r,window.getOrDefault(r,0) + 1); if(window.get(r).equals(need.get(r))){ count ++; } } while(right - left == s1.length()){ if(need.size() == count){ return true; } char l = s2.charAt(left); left ++; if(window.containsKey(l)){ if(window.get(l).equals(need.get(l))){ count --; } window.put(l,window.get(l) - 1); } } } return false; }} 12345678910111213141516171819202122232425class Solution { public boolean checkInclusion(String s1, String s2) { int n = s1.length(), m = s2.length(); if (n &gt; m) { return false; } int[] cnt1 = new int[26]; int[] cnt2 = new int[26]; for (int i = 0; i &lt; n; ++i) { ++cnt1[s1.charAt(i) - 'a']; ++cnt2[s2.charAt(i) - 'a']; } if (Arrays.equals(cnt1, cnt2)) { return true; } for (int i = n; i &lt; m; ++i) { ++cnt2[s2.charAt(i) - 'a']; --cnt2[s2.charAt(i - n) - 'a']; if (Arrays.equals(cnt1, cnt2)) { return true; } } return false; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"}]},{"title":"哈希表常见题","slug":"算法/哈希表/哈希表","date":"2022-10-14T10:38:05.480Z","updated":"2023-02-13T07:51:42.274Z","comments":true,"path":"2022/10/14/算法/哈希表/哈希表/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C%E8%A1%A8/%E5%93%88%E5%B8%8C%E8%A1%A8/","excerpt":"","text":"哈希表:383.赎金信 242.有效的字母异位词 202.快乐数 349.两个数组的交集 350.两个数组的交集 II 1.两数之和 哈希表一般用来判断一个元素是否出现集合里。 常见的三种哈希结构： 数组 set（集合） map（映射） 数组作为哈希表在 242.有效的字母异位词 中，我们提到了数组就是简单的哈希表，但是数组的大小是受限的！ 这道题目仅包含小写字母，那么使用数组来做哈希最合适不过。 在 383.赎金信 中同样要求只有小写字母，那么就给我们浓浓的暗示，用数组！ 242.有效的字母异位词 是求 字符串a 和 字符串b 是否可以相互组成，在 383.赎金信 中是求字符串a能否组成字符串b，而不用管字符串b 能不能组成字符串a。 上面两道题目用map确实可以，但使用map的空间消耗要比数组大一些，因为map要维护红黑树或者符号表，而且还要做哈希函数的运算。所以数组更加简单直接有效！ 383.赎金信字符统计,哈希映射123456789101112131415161718class Solution { public boolean canConstruct(String ransomNote, String magazine) { if (ransomNote.length() &gt; magazine.length()) { return false; } int[] cnt = new int[26]; for (char c : magazine.toCharArray()) { cnt[c - 'a']++; } for (char c : ransomNote.toCharArray()) { cnt[c - 'a']--; if(cnt[c - 'a'] &lt; 0) { return false; } } return true; }} 242.有效的字母异位词字符统计,哈希映射123456789101112131415161718class Solution { public boolean isAnagram(String s, String t) { if (s.length() != t.length()) { return false; } int[] arr = new int[26]; for (char c : s.toCharArray()) { arr[c - 'a'] ++; } for (char c : t.toCharArray()) { arr[c - 'a'] --; if (arr[c - 'a'] &lt; 0) { return false; } } return true; }} 排序时间复杂度比上一个方法高 123456789101112class Solution { public boolean isAnagram(String s, String t) { if (s.length() != t.length()) { return false; } char[] str1 = s.toCharArray(); char[] str2 = t.toCharArray(); Arrays.sort(str1); Arrays.sort(str2); return Arrays.equals(str1, str2); }} set作为哈希表在 349. 两个数组的交集 202.快乐数 中我们给出了什么时候用数组就不行了，需要用set。 这道题目没有限制数值的大小，就无法使用数组来做哈希表了。 主要因为如下两点： 数组的大小是有限的，受到系统栈空间（不是数据结构的栈）的限制。 如果数组空间够大，但哈希值比较少、特别分散、跨度非常大，使用数组就造成空间的极大浪费。 202.快乐数从 7 开始。则下一个数字是 49，然后下一个数字是 97，我们可以不断重复该的过程，直到我们得到 11。因为我们得到了 11，我们知道 77 是一个快乐数，函数应该返回 true。 从 116 开始。通过反复通过平方和计算下一个数字，我们最终得到 58，再继续计算之后，我们又回到 58。由于我们回到了一个已经计算过的数字，可以知道有一个循环，因此不可能达到 1。所以对于 116，函数应该返回 false。 用哈希集合检测循环 1234567891011121314151617181920class Solution { private int getNext(int n) { int totalSum = 0; while (n &gt; 0) { int d = n % 10; n = n / 10; totalSum += d * d; } return totalSum; } public boolean isHappy(int n) { Set&lt;Integer&gt; seen = new HashSet&lt;&gt;(); while (n != 1 &amp;&amp; !seen.contains(n)) { seen.add(n); n = getNext(n); } return n == 1; }} 快慢指针法 12345678910111213141516171819202122class Solution { public int getNext(int n) { int totalSum = 0; while (n &gt; 0) { int d = n % 10; n = n / 10; totalSum += d * d; } return totalSum; } public boolean isHappy(int n) { int slowRunner = n; int fastRunner = getNext(n); while (fastRunner != 1 &amp;&amp; slowRunner != fastRunner) { slowRunner = getNext(slowRunner); fastRunner = getNext(getNext(fastRunner)); } return fastRunner == 1; }} 349.两个数组的交集12345678910111213141516171819202122232425262728293031class Solution { public int[] intersection(int[] nums1, int[] nums2) { Set&lt;Integer&gt; set1 = new HashSet&lt;Integer&gt;(); Set&lt;Integer&gt; set2 = new HashSet&lt;Integer&gt;(); for (int num : nums1) { set1.add(num); } for (int num : nums2) { set2.add(num); } return getIntersection(set1, set2); } public int[] getIntersection(Set&lt;Integer&gt; set1, Set&lt;Integer&gt; set2) { if (set1.size() &gt; set2.size()) { return getIntersection(set2, set1); } Set&lt;Integer&gt; intersectionSet = new HashSet&lt;Integer&gt;(); for (int num : set1) { if (set2.contains(num)) { intersectionSet.add(num); } } int[] intersection = new int[intersectionSet.size()]; int index = 0; for (int num : intersectionSet) { intersection[index++] = num; } return intersection; }} 如果直接用数组，会出现带零的情况 12345678int[] intersection = new int[set1.size()]; int index = 0; for (int num : set1) { if (set2.contains(num)) { intersection[index++] = num; } } return intersection; 用Arrays.copyOfRange 12345678910111213public int[] getIntersection(Set&lt;Integer&gt; set1, Set&lt;Integer&gt; set2) { if (set1.size() &gt; set2.size()) { return getIntersection(set2, set1); } int[] intersection = new int[set1.size()]; int index = 0; for (int num : set1) { if (set2.contains(num)) { intersection[index++] = num; } } return Arrays.copyOfRange(intersection,0,index); } map作为哈希表使用数组和set来做哈希法的局限。 数组的大小是受限制的，而且如果元素很少，而哈希值太大会造成内存空间的浪费。 set是一个集合，里面放的元素只能是一个key，而两数之和这道题目，不仅要判断y是否存在而且还要记录y的下标位置，因为要返回x 和 y的下标。所以set 也不能用。 map是一种&lt;key, value&gt;的结构，本题可以用key保存数值，用value在保存数值所在的下标。所以使用map最为合适。 350.两个数组的交集 IIArrays.copyOfRange 12345678910111213141516171819202122class Solution { public int[] intersect(int[] nums1, int[] nums2) { if (nums1.length &gt; nums2.length) { return intersect(nums2, nums1); } HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); int index = 0; for(int num : nums1){ map.put(num,map.getOrDefault(num,0) + 1); } int [] re = new int[nums1.length]; for(int num : nums2){ if(map.containsKey(num)){ if(map.get(num) &gt; 0){ re[index ++] = num; map.put(num,map.getOrDefault(num,0) - 1); } } } return Arrays.copyOfRange(re,0,index); }} 1.两数之和123456789101112class Solution { public int[] twoSum(int[] nums, int target) { Map&lt;Integer, Integer&gt; hashtable = new HashMap&lt;Integer, Integer&gt;(); for (int i = 0; i &lt; nums.length; ++i) { if (hashtable.containsKey(target - nums[i])) { return new int[]{hashtable.get(target - nums[i]), i}; } hashtable.put(nums[i], i); } return new int[0]; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"排序","slug":"排序","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"数组前缀和","slug":"算法/数组/前缀和","date":"2022-10-14T10:38:05.480Z","updated":"2022-12-05T01:21:47.978Z","comments":true,"path":"2022/10/14/算法/数组/前缀和/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/%E5%89%8D%E7%BC%80%E5%92%8C/","excerpt":"","text":"前缀和:303.区域和检索 - 数组不可变 [简] 304.二维区域和检索 - 矩阵不可变 [中] 303.区域和检索 - 数组不可变 [简]暴力解法，因为 sumRange 方法会被频繁调用，而它的时间复杂度是 O(N)，其中 N 代表 nums 数组的长度，时间复杂度过高。 12345678910111213141516class NumArray { private int[] nums; public NumArray(int[] nums) { this.nums = nums; } public int sumRange(int left, int right) { int res = 0; for (int i = left; i &lt;= right; i++) { res += nums[i]; } return res; }} new 一个新的数组 preSum 出来，preSum[i] 记录 nums[0..i-1] 的累加和 看这个 preSum 数组，如果我想求索引区间 [1, 4] 内的所有元素之和，就可以通过 preSum[5] - preSum[1] 得出。这样，sumRange 函数仅仅需要做一次减法运算，避免了每次进行 for 循环调用，最坏时间复杂度为常数 O(1)。 123456789101112131415class NumArray { int[] sums; public NumArray(int[] nums) { int n = nums.length; sums = new int[n + 1]; for (int i = 0; i &lt; n; i++) { sums[i + 1] = sums[i] + nums[i]; } } public int sumRange(int i, int j) { return sums[j + 1] - sums[i]; }} 304.二维区域和检索 - 矩阵不可变 [中] 12345678910111213141516171819class NumMatrix { private int[][] preSum; public NumMatrix(int[][] matrix) { if (matrix.length &gt; 0) { preSum = new int[matrix.length + 1][matrix[0].length + 1]; for (int i = 0; i &lt; matrix.length; i++) { for (int j = 0; j &lt; matrix[0].length; j++) { preSum[i+1][j+1] = preSum[i][j+1] + preSum[i+1][j] - preSum[i][j] + matrix[i][j]; } } } } public int sumRegion(int row1, int col1, int row2, int col2) { return preSum[row2 + 1][col2 + 1] - preSum[row2 + 1][col1] - preSum[row1][col2 + 1] + preSum[row1][col1]; }} 参考原文地址","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"矩阵","slug":"矩阵","permalink":"http://example.com/tags/%E7%9F%A9%E9%98%B5/"},{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"},{"name":"前缀和","slug":"前缀和","permalink":"http://example.com/tags/%E5%89%8D%E7%BC%80%E5%92%8C/"}]},{"title":"n数之和","slug":"算法/数组/n数之和","date":"2022-10-14T10:38:05.480Z","updated":"2023-03-19T02:27:37.736Z","comments":true,"path":"2022/10/14/算法/数组/n数之和/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/n%E6%95%B0%E4%B9%8B%E5%92%8C/","excerpt":"","text":"n数之和:15.三数之和 18.四数之和 排序 + 双指针本题的难点在于如何去除重复解。 三数之和算法流程： 特判，对于数组长度 n，如果数组为 null 或者数组长度小于 3，返回 [][][] 对数组进行排序。 遍历排序后数组： （1）若 nums[i]&gt;0：因为已经排序好，所以后面不可能有三个数加和等于 0，直接返回结果。（2）对于重复元素：跳过，避免出现重复解（3）令左指针 L=i+1，右指针 R=n-1，当 L&lt;R 时，执行循环：当 nums[i]+nums[L]+nums[R]==0，执行循环，判断左界和右界是否和下一位置重复，去除重复解。并同时将 L,R 移到下一位置，寻找新的解若和大于 0，说明 nums[R] 太大，R 左移若和小于 0，说明 nums[L] 太小，L 右移 和三数之和一样，本题的难点依旧在于如何去除重复解取两个数组合，将问题转化为三数之和 四数之和算法流程： 特判，对于数组长度n，如果数组为Null或者数组长度小于4，返回 对数组进行排序 遍历排序后数组：（1）对于重复元素，跳过，条件：i&gt;0 且 nums[i]==nums[i-1]，避免出现重复解 （2）二次遍历，重复元素跳过，判断重复元素从i后第二个元素开始，所以条件：j-i&gt;1 且 nums[j]==nums[j-1] （3）令左指针L=j+1,右指针R=n-1,当L&lt;R时，执行循环：当nums[i]+nums[j]+nums[L]+nums[R]==target时,将结果加入res并执行循环，判断左界和右界是否和下一位置重复，以去除重复解。并同时将L,R移到下一位置，寻找新的解若和大于0，说明nums[R]太大，R左移若和小于0，说明nums[L]太小，L右移 剪枝条件：对于本题，按照上述流程写下来，可以通过。我们继续对算法进行剪枝优化 第一次遍历 若nums[i]+nums[i+1]+nums[i+2]+nums[i+3]&gt;target,则可以退出，因为最小四数之和大于目标，则不可能存在结果。 注意：和三数之和的优化条件不同，三数之和中target=0,所以只要nums[i]&gt;0,则可退出，这里则需要更为严格的条件。若当前值和数组中最大的三个值相加依旧小于目标，nums[i] + nums[n- 1] + nums[n- 2] + nums[n- 3] &lt; target,则continue 第二次遍历 同理，若nums[i] + nums[j] + nums[j + 1] + nums[j + 2] &gt; target,breaknums[i] + nums[j] + nums[n - 1] + nums[n - 2] &lt; target,continue 15.三数之和注意： 1,剪枝条件 2,去除重复值 3,判断左界和右界是否和下一位置重复，去除重复解不要用if，用while 1234567891011121314151617181920212223242526272829303132333435363738class Solution { public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); //排序 Arrays.sort(nums); //双指针 int len = nums.length; for(int i = 0;i &lt; len;++i) { if(nums[i] &gt; 0) return lists; if(i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue; int curr = nums[i]; int L = i+1, R = len-1; while (L &lt; R) { int tmp = curr + nums[L] + nums[R]; if(tmp == 0) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(curr); list.add(nums[L]); list.add(nums[R]); lists.add(list); //代码简洁但时间复杂度更高 //lists.add(new ArrayList&lt;&gt;(Arrays.asList(nums[i], nums[L], nums[R]))); while(L &lt; R &amp;&amp; nums[L+1] == nums[L]) ++L; while (L &lt; R &amp;&amp; nums[R-1] == nums[R]) --R; ++L; --R; } else if(tmp &lt; 0) { ++L; } else { --R; } } } return lists; }} 18.四数之和注意： 1,len小于4的情况 2,测试数据过大，需要转型long 3,剪枝条件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution { public List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) { List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(); int len = nums.length; if(len &lt; 4){ return lists; } Arrays.sort(nums); for(int i = 0;i &lt; len - 3;i ++){ if((long)nums[i]+nums[i+1]+nums[i+2]+nums[i+3]&gt;target) break; if((long)nums[i]+nums[len-1]+nums[len-2]+nums[len-3]&lt;target) continue; if(i&gt;0 &amp;&amp; nums[i]==nums[i-1]) continue; for(int j = i +1;j &lt; len - 2;j ++){ if((long)nums[i] + nums[j] + nums[j+1] + nums[j+2] &gt; target) break; if((long)nums[i] + nums[j] + nums[len-1] + nums[len-2] &lt; target) continue; if(j-i&gt;1 &amp;&amp; nums[j]==nums[j-1]) continue; int L = j+1, R = len-1; while(L &lt; R){ int sum = nums[i] + nums[j] + nums[L] + nums[R]; if(sum == target){ List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(nums[i]); list.add(nums[j]); list.add(nums[L]); list.add(nums[R]); lists.add(list); while(L &lt; R &amp;&amp; nums[L+1] == nums[L]) ++L; while (L &lt; R &amp;&amp; nums[R-1] == nums[R]) --R; ++L; --R; } else if(sum &gt; target){ R --; } else { L ++; } } } } return lists; }} 那么一样的道理，五数之和、六数之和等等都采用这种解法。 对于 15.三数之和 双指针法就是将原本暴力O(n^3)的解法，降为O(n^2)的解法，四数之和的双指针解法就是将原本暴力O(n^4)的解法，降为O(n^3)的解法。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"排序","slug":"排序","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"链表的倒数第k个结点","slug":"算法/链表/倒数k节点","date":"2022-10-14T10:38:05.480Z","updated":"2022-12-03T01:13:43.956Z","comments":true,"path":"2022/10/14/算法/链表/倒数k节点/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/%E5%80%92%E6%95%B0k%E8%8A%82%E7%82%B9/","excerpt":"","text":"链表的倒数第k个结点19.删除链表的倒数第 N 个结点 [中] 剑指 Offer 22. 链表中倒数第k个节点 [简] 方法一:计算链表长度12345678public int getLength(ListNode head) { int length = 0; while (head != null) { ++length; head = head.next; } return length; } 方法二：栈方法三：双指针双指针 first 和 second的话，当 first 指向末尾的 NULL，first 与 second 之间相隔的元素个数为 n 时，那么删除掉 second 的下一个指针就完成了要求。 19.删除链表的倒数第 N 个结点 [中]1234567891011121314151617class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0, head); ListNode first = head; ListNode second = dummy; for (int i = 0; i &lt; n; ++i) { first = first.next; } while (first != null) { first = first.next; second = second.next; } second.next = second.next.next; ListNode ans = dummy.next; return ans; }} 剑指 Offer 22. 链表中倒数第k个节点 [简]123456789101112class Solution { public ListNode getKthFromEnd(ListNode head, int k) { ListNode former = head, latter = head; for(int i = 0; i &lt; k; i++) former = former.next; while(former != null) { former = former.next; latter = latter.next; } return latter; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"螺旋矩阵","slug":"算法/数组/螺旋矩阵","date":"2022-10-14T10:38:05.480Z","updated":"2022-12-10T02:52:24.189Z","comments":true,"path":"2022/10/14/算法/数组/螺旋矩阵/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/%E8%9E%BA%E6%97%8B%E7%9F%A9%E9%98%B5/","excerpt":"","text":"螺旋矩阵:54.螺旋矩阵 [中] 59.螺旋矩阵 II [中] 剑指 Offer 29. 顺时针打印矩阵 [简] 48.旋转图像 [中] 顺/逆时针旋转矩阵用翻转代替旋转 48.旋转图像 [中]123456789101112131415161718192021222324252627282930class Solution { public void rotate(int[][] matrix) { int n = matrix.length; int temp = 0; for(int i = 0;i &lt; n;i ++){ for(int j = i;j &lt; n;j ++){ temp = matrix[j][i]; matrix[j][i] = matrix[i][j]; matrix[i][j] = temp; } } for(int[] row : matrix){ reverse(row); } } void reverse(int[] row){ int i = 0; int j = row.length - 1; int temp = 0; while(i &lt; j){ temp = row[i]; row[i] = row[j]; row[j] = temp; i ++; j --; } }} 54,59,剑指 Offer 29都和顺时针打印二维矩阵有关,能共用一套模板思路是按照右、下、左、上的顺序遍历数组，并使用四个变量圈定未遍历元素的边界 随着螺旋遍历，相应的边界会收缩，直到螺旋遍历完整个数组 123456789101112131415161718192021while(true){ for(int i = left;i &lt;= right;i ++){ } if(++upper &gt; down) break; for(int i = upper;i &lt;= down;i ++){ } if(left &gt; --right) break; for(int i = right;i &gt;= left; i --){ } if(upper &gt; --down) break; for(int i = down;i &gt;= upper;i --){ } if(++left &gt; right) break;} 54.螺旋矩阵 [中]123456789101112131415161718192021222324252627282930313233class Solution { public List&lt;Integer&gt; spiralOrder(int[][] matrix) { List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); int upper = 0,down = matrix.length - 1; int left = 0,right = matrix[0].length - 1; while(true){ for(int i = left;i &lt;= right;i ++){ list.add(matrix[upper][i]); } upper ++; if(upper &gt; down) break; for(int i = upper;i &lt;= down;i ++){ list.add(matrix[i][right]); } right --; if(left &gt; right) break; for(int i = right;i &gt;= left; i --){ list.add(matrix[down][i]); } down --; if(upper &gt; down) break; for(int i = down;i &gt;= upper;i --){ list.add(matrix[i][left]); } left ++; if(left &gt; right) break; } return list; }} 59.螺旋矩阵 II [中]12345678910111213141516171819202122232425262728293031323334class Solution { public int[][] generateMatrix(int n) { int[][] matrix = new int[n][n]; int nums = 1; int upper = 0,down = matrix.length - 1; int left = 0,right = matrix.length - 1; while(true){ for(int i = left;i &lt;= right;i ++){ matrix[upper][i] = nums ++; } upper ++; if(upper &gt; down) break; for(int i = upper;i &lt;= down;i ++){ matrix[i][right] = nums ++; } right --; if(left &gt; right) break; for(int i = right;i &gt;= left; i --){ matrix[down][i] = nums ++; } down --; if(upper &gt; down) break; for(int i = down;i &gt;= upper;i --){ matrix[i][left] = nums ++; } left ++; if(left &gt; right) break; } return matrix; }} 剑指 Offer 29. 顺时针打印矩阵 [简]1,未考虑限制情况: 0 &lt;= matrix.length &lt;= 100 0 &lt;= matrix[i].length &lt;= 100 2,长和宽弄错 1234567891011121314151617181920212223242526272829303132333435363738class Solution { public int[] spiralOrder(int[][] matrix) { if (matrix == null || matrix.length == 0 || matrix[0].length == 0) { return new int[0]; } int m = matrix.length,n = matrix[0].length; int[] sum = new int[n * m]; int num = 0; int upper = 0,down = m - 1; int left = 0,right = n - 1; while(true){ for(int i = left;i &lt;= right;i ++){ sum[num++] = matrix[upper][i]; } upper ++; if(upper &gt; down) break; for(int i = upper;i &lt;= down;i ++){ sum[num++] = matrix[i][right]; } right --; if(left &gt; right) break; for(int i = right;i &gt;= left; i --){ sum[num++] = matrix[down][i]; } down --; if(upper &gt; down) break; for(int i = down;i &gt;= upper;i --){ sum[num++] = matrix[i][left]; } left ++; if(left &gt; right) break; } return sum; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"矩阵","slug":"矩阵","permalink":"http://example.com/tags/%E7%9F%A9%E9%98%B5/"},{"name":"模拟","slug":"模拟","permalink":"http://example.com/tags/%E6%A8%A1%E6%8B%9F/"}]},{"title":"首尾指针的应用","slug":"算法/数组/首尾指针的应用","date":"2022-10-14T10:38:05.480Z","updated":"2023-02-07T09:26:38.342Z","comments":true,"path":"2022/10/14/算法/数组/首尾指针的应用/","link":"","permalink":"http://example.com/2022/10/14/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/%E9%A6%96%E5%B0%BE%E6%8C%87%E9%92%88%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"","text":"首尾指针的应用:167.两数之和 II - 输入有序数组 [中] 剑指 Offer 57. 和为s的两个数字 [简] 剑指 Offer II 006. 排序数组中两个数字之和 [简] 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面 思路:使用双指针，一个指针指向值较小的元素，一个指针指向值较大的元素。指向较小元素的指针从头向尾遍历，指向较大元素的指针从尾向头遍历。 如果两个指针指向元素的和 sum == targetsum==target，那么得到要求的结果； 如果 sum &gt; targetsum&gt;target，移动较大的元素，使 sumsum 变小一些； 如果 sum &lt; targetsum&lt;target，移动较小的元素，使 sumsum 变大一些。 数组中的元素最多遍历一次，时间复杂度为 O(N)O(N)。只使用了两个额外变量，空间复杂度为 O(1)O(1) 167.两数之和 II - 输入有序数组 [中]12345678910111213141516class Solution { public int[] twoSum(int[] nums, int target) { int i = 0,j = nums.length - 1; while(i &lt; j){ int h = nums[i] + nums[j]; if(h &gt; target){ j --; } else if(h &lt; target){ i ++; } else { return new int[] { i + 1, j + 1 }; } } return new int[0]; }} 剑指 Offer 57. 和为s的两个数字 [简]12345678910111213141516class Solution { public int[] twoSum(int[] nums, int target) { int i = 0,j = nums.length - 1; while(i &lt; j){ int h = nums[i] + nums[j]; if (h &gt; target){ j --; } else if(h &lt; target){ i ++; } else { return new int[] { nums[i], nums[j] }; } } return new int[0]; }} 剑指 Offer II 006. 排序数组中两个数字之和 [简]12345678910111213141516class Solution { public int[] twoSum(int[] nums, int target) { int i = 0,j = nums.length - 1; while(i &lt; j){ int h = nums[i] + nums[j]; if(h &gt; target){ j --; } else if(h &lt; target){ i ++; } else { return new int[] { i, j }; } } return new int[0]; }} 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面12345678910111213class Solution { public int[] exchange(int[] nums) { int l = 0, r = nums.length - 1; while (l &lt; r) { while (l &lt; r &amp;&amp; (nums[l] &amp; 1) == 1) l ++; while (l &lt; r &amp;&amp; (nums[r] &amp; 1) == 0) r --; int temp = nums[l]; nums[l] = nums[r]; nums[r] = temp; } return nums; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"链表的反转","slug":"算法/链表/反转链表","date":"2022-09-19T03:09:06.277Z","updated":"2023-02-10T07:30:40.957Z","comments":true,"path":"2022/09/19/算法/链表/反转链表/","link":"","permalink":"http://example.com/2022/09/19/%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/","excerpt":"","text":"链表的反转206.反转链表 [简] 92.反转链表 II [中] 25.K个一组翻转链表 [难] 234.回文链表 [简] 206.反转链表 [简]方法一：双指针 定义两个指针： pre 和 cur ；pre 在前 cur 在后。 每次让 pre 的 next 指向 cur ，实现一次局部反转 局部反转完成之后，pre 和 cur 同时往前移动一个位置 循环上述过程，直至 pre 到达链表尾部 12345678910111213class Solution { public ListNode reverseList(ListNode head) { ListNode newNode = new ListNode(); ListNode cur = head; while (cur != null) { ListNode next = cur.next; cur.next = newNode.next; newNode.next = cur; cur = next; } return newNode.next; }} 1234567891011121314class Solution { public ListNode reverseList(ListNode head) { ListNode pre = null; ListNode cur = head; while (cur != null) { ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; } return pre; }} 方法二：递归 使用递归函数，一直递归到链表的最后一个结点，该结点就是反转后的头结点，记作 return . 此后，每次函数在返回的过程中，让当前结点的下一个结点的 next 指针指向当前节点。 同时让当前结点的 next 指针指向 NULL ，从而实现从链表尾部开始的局部反转 当递归函数全部出栈后，链表反转完成。 1234567891011class Solution { public ListNode reverseList(ListNode head) { if (head == null || head.next == null) { return head; } ListNode newHead = reverseList(head.next); head.next.next = head; head.next = null; return newHead; }} 92.反转链表 II [中] *注意事项: 1,right,left指针的移动 2,虚拟头结点 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution { public ListNode reverseBetween(ListNode head, int left, int right) { // 因为头节点有可能发生变化，使用虚拟头节点可以避免复杂的分类讨论 ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; for (int i = 0; i &lt; left - 1; i++) { pre = pre.next; } ListNode rightNode = pre; for (int i = 0; i &lt; right - left + 1; i++) { rightNode = rightNode.next; } ListNode leftNode = pre.next; ListNode curr = rightNode.next; pre.next = null; rightNode.next = null; reverseLinkedList(leftNode); pre.next = rightNode; leftNode.next = curr; return dummyNode.next; } private void reverseLinkedList(ListNode head) { ListNode pre = null; ListNode cur = head; while (cur != null) { ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; } }} 25.K个一组翻转链表 [难] *注意事项: 1,进入循环的条件 2,end指针的移动 123456789101112131415161718192021222324252627282930313233public ListNode reverseKGroup(ListNode head, int k) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode pre = dummy; ListNode end = dummy; while (end.next != null) { for (int i = 0; i &lt; k &amp;&amp; end != null; i++) end = end.next; if (end == null) break; ListNode start = pre.next; ListNode next = end.next; end.next = null; pre.next = reverse(start); start.next = next; pre = start; end = pre; } return dummy.next;}private ListNode reverse(ListNode head) { ListNode pre = null; ListNode curr = head; while (curr != null) { ListNode next = curr.next; curr.next = pre; pre = curr; curr = next; } return pre;} 234.回文链表 [简] *注意事项: 不能全部反转 1234567891011121314151617181920212223242526272829303132333435class Solution { public boolean isPalindrome(ListNode head) { ListNode pre = new ListNode(-1,head); ListNode succ = new ListNode(-1); ListNode slow = pre; ListNode fast = pre; while(fast.next != null &amp;&amp; fast.next.next != null){ slow = slow.next; fast = fast.next.next; } ListNode newHead = reverse(slow.next); slow.next = null; succ.next = newHead; while(pre.val == succ.val){ pre = pre.next; succ = succ.next; if(pre == null){ return true; } } return false; } ListNode reverse(ListNode head){ ListNode prev = null; ListNode cur = head; while(cur != null){ ListNode next = cur.next; cur.next = prev; prev = cur; cur = next; } return prev; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"合并有序链表","slug":"算法/链表/合并有序链表","date":"2022-09-18T11:08:38.200Z","updated":"2022-12-04T07:12:24.511Z","comments":true,"path":"2022/09/18/算法/链表/合并有序链表/","link":"","permalink":"http://example.com/2022/09/18/%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/","excerpt":"","text":"合并有序链表21.合并两个有序链表 [简] 23.合并K个升序链表 [难] 21.合并两个有序链表 [简]注意事项： 1,循环条件是&amp;&amp;不是|| 下列代码冗长 共同条件可以抽出 不需要next,结点直接移动即可 123456789101112131415161718192021class Solution { public ListNode mergeTwoLists(ListNode list1, ListNode list2) { ListNode dummyNode = new ListNode(0); ListNode pre = dummyNode; while (list1 != null &amp;&amp; list2 != null) { if (list1.val &lt; list2.val) { ListNode next = list1.next; pre.next = list1; pre = list1; list1 = next; } else { ListNode next = list2.next; pre.next = list2; pre = list2; list2 = next; } } pre.next = list1 == null ? list2 : list1; return dummyNode.next; }} 改进之后 123456789101112131415161718class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { ListNode newHead = new ListNode(-1); ListNode pre = newHead; while(l1 != null &amp;&amp; l2 != null){ if(l1.val &lt;= l2.val){ pre.next = l1; l1 = l1.next; } else { pre.next = l2; l2 = l2.next; } pre = pre.next; } pre.next = l1 == null ? l2 : l1; return newHead.next; }} 23.合并K个升序链表 [难] *方法一：顺序合并思路 我们可以想到一种最朴素的方法：用一个变量 ans 来维护以及合并的链表，第 i 次循环把第 i 个链表和 ans 合并，答案保存到 ans 中,该方法时间复杂度大 注意事项: 数组里为空 123456789101112131415161718192021222324252627282930class Solution { public ListNode mergeKLists(ListNode[] lists) { ListNode ans = null; for(int i = 0;i &lt; lists.length;i ++){ ans = mergeTwoLists(ans,lists[i]); } return ans; } ListNode mergeTwoLists(ListNode l1, ListNode l2) { if(l1 == null || l2 == null){ return l1 != null ? l1 : l2; } ListNode newHead = new ListNode(-1); ListNode pre = newHead; while(l1 != null &amp;&amp; l2 != null){ if(l1.val &lt;= l2.val){ pre.next = l1; l1 = l1.next; } else { pre.next = l2; l2 = l2.next; } pre = pre.next; } pre.next = l1 == null ? l2 : l1; return newHead.next; }} 方法二：分治合并思路 考虑优化方法一，用分治的方法进行合并。 将 k 个链表配对并将同一对中的链表合并；第一轮合并以后， k 个链表被合并成了 k/2个链表，平均长度为 2n/k然后是 k/4个链表，k/8个链表等等； 重复这一过程，直到我们得到了最终的有序链表。 12345678910111213141516171819202122232425262728293031323334353637class Solution { public ListNode mergeKLists(ListNode[] lists) { return merge(lists, 0, lists.length - 1); } public ListNode merge(ListNode[] lists, int l, int r) { if (l == r) { return lists[l]; } if (l &gt; r) { return null; } int mid = (l + r) &gt;&gt; 1; return mergeTwoLists(merge(lists, l, mid), merge(lists, mid + 1, r)); } public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if(l1 == null || l2 == null){ return l1 != null ? l1 : l2; } ListNode newHead = new ListNode(-1); ListNode pre = newHead; while(l1 != null &amp;&amp; l2 != null){ if(l1.val &lt;= l2.val){ pre.next = l1; l1 = l1.next; } else { pre.next = l2; l2 = l2.next; } pre = pre.next; } pre.next = l1 == null ? l2 : l1; return newHead.next; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"分治","slug":"分治","permalink":"http://example.com/tags/%E5%88%86%E6%B2%BB/"},{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"环形链表","slug":"算法/链表/环形链表","date":"2022-09-18T07:20:25.905Z","updated":"2022-12-04T06:23:41.359Z","comments":true,"path":"2022/09/18/算法/链表/环形链表/","link":"","permalink":"http://example.com/2022/09/18/%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8/","excerpt":"","text":"环形链表141.环形链表 [简] 142.环形链表 II [中] * 具体解析见代码随想录 141.环形链表 [简]1234567891011121314public class Solution { public boolean hasCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while(fast != null &amp;&amp; fast.next != null){ fast = fast.next.next; slow = slow.next; if(fast == slow){ return true; } } return false; }} 142.环形链表 II [中]123456789101112131415161718192021public class Solution { public ListNode detectCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if (slow == fast) {// 有环 ListNode index1 = fast; ListNode index2 = head; // 两个指针，从头结点和相遇结点，各走一步，直到相遇，相遇点即为环入口 while (index1 != index2) { index1 = index1.next; index2 = index2.next; } return index1; } } return null; }}","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"Jmeter快速入门","slug":"笔记/技术/Jmeter快速入门","date":"2022-07-31T22:22:08.000Z","updated":"2022-11-28T10:10:38.550Z","comments":true,"path":"2022/08/01/笔记/技术/Jmeter快速入门/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Jmeter%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"","text":"Jmeter快速入门安装JmeterJmeter依赖于JDK，所以必须确保当前计算机上已经安装了JDK，并且配置了环境变量。 下载可以Apache Jmeter官网下载，地址：http://jmeter.apache.org/download_jmeter.cgi 解压因为下载的是zip包，解压缩即可使用，目录结构如下： 其中的bin目录就是执行的脚本，其中包含启动脚本： 运行双击即可运行，但是有两点注意： 启动速度比较慢，要耐心等待 启动后黑窗口不能关闭，否则Jmeter也跟着关闭了 快速入门设置中文语言默认Jmeter的语言是英文，需要设置： 效果： 注意：上面的配置只能保证本次运行是中文，如果要永久中文，需要修改Jmeter的配置文件 打开jmeter文件夹，在bin目录中找到 jmeter.properties，添加下面配置： 1language=zh_CN 注意：前面不要出现#，#代表注释，另外这里是下划线，不是中划线 基本用法在测试计划上点鼠标右键，选择添加 &gt; 线程（用户） &gt; 线程组： 在新增的线程组中，填写线程信息： 给线程组点鼠标右键，添加http取样器： 编写取样器内容： 添加监听报告： 添加监听结果树： 汇总报告结果： 结果树：","categories":[{"name":"小技术","slug":"小技术","permalink":"http://example.com/categories/%E5%B0%8F%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"jmeter","slug":"jmeter","permalink":"http://example.com/tags/jmeter/"}]},{"title":"SpringCloud实用篇","slug":"笔记/技术/SpringCloud实用篇","date":"2022-07-31T22:20:09.000Z","updated":"2022-11-28T10:12:22.613Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud实用篇/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%AE%9E%E7%94%A8%E7%AF%87/","excerpt":"","text":"SpringCloud实用篇Nacos配置管理Nacos除了可以做注册中心，同样可以做配置管理来使用。 统一配置管理当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。 Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。 在nacos中添加配置文件如何在nacos中管理配置呢？ 然后在弹出的表单中，填写配置信息： 注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。 从微服务拉取配置微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。 但如果尚未读取application.yml，又如何得知nacos地址呢？ 因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下： 1）引入nacos-config依赖 首先，在user-service服务中，引入nacos-config的客户端依赖： 12345&lt;!--nacos配置管理依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 2）添加bootstrap.yaml 然后，在user-service中添加一个bootstrap.yaml文件，内容如下： 12345678910spring: application: name: userservice # 服务名称 profiles: active: dev #开发环境，这里是dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}作为文件id，来读取配置。 本例中，就是去读取userservice-dev.yaml： 3）读取nacos配置 在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置： 完整代码： 1234567891011121314151617181920212223242526272829package cn.itcast.user.web;import cn.itcast.user.pojo.User;import cn.itcast.user.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;@Slf4j@RestController@RequestMapping(\"/user\")public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } // ...略} 在页面访问，可以看到效果： 配置热更新我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。 要实现配置热更新，可以使用两种方式： 方式一在@Value注入的变量所在类上添加注解@RefreshScope： 方式二使用@ConfigurationProperties注解代替@Value注解。 在user-service服务中，添加一个类，读取patterrn.dateformat属性： 123456789101112package cn.itcast.user.config;import lombok.Data;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@Data@ConfigurationProperties(prefix = \"pattern\")public class PatternProperties { private String dateformat;} 在UserController中使用这个类代替@Value： 完整代码： 123456789101112131415161718192021222324252627282930313233package cn.itcast.user.web;import cn.itcast.user.config.PatternProperties;import cn.itcast.user.pojo.User;import cn.itcast.user.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;@Slf4j@RestController@RequestMapping(\"/user\")public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } // 略} 配置共享其实微服务启动时，会去nacos读取多个配置文件，例如： [spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml [spring.application.name].yaml，例如：userservice.yaml 而[spring.application.name].yaml不包含环境，因此可以被多个环境共享。 下面我们通过案例来测试配置共享 1）添加一个环境共享配置我们在nacos中添加一个userservice.yaml文件： 2）在user-service中读取共享配置在user-service服务中，修改PatternProperties类，读取新添加的属性： 在user-service服务中，修改UserController，添加一个方法： 3）运行两个UserApplication，使用不同的profile修改UserApplication2这个启动项，改变其profile值： 这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。 启动UserApplication和UserApplication2 访问http://localhost:8081/user/prop，结果： 访问http://localhost:8082/user/prop，结果： 可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。 4）配置共享的优先级当nacos、服务本地同时出现相同属性时，优先级有高低之分： Feign远程调用先来看我们以前利用RestTemplate发起远程调用的代码： 存在下面的问题： •代码可读性差，编程体验不统一 •参数复杂URL难以维护 Feign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign 其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。 Feign替代RestTemplateFegin的使用步骤如下： 1）引入依赖我们在order-service服务的pom文件中引入feign的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 2）添加注解在order-service的启动类添加注解开启Feign的功能： 3）编写Feign的客户端在order-service中新建一个接口，内容如下： 123456789101112package cn.itcast.order.client;import cn.itcast.order.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(\"userservice\")public interface UserClient { @GetMapping(\"/user/{id}\") User findById(@PathVariable(\"id\") Long id);} 这个客户端主要是基于SpringMVC的注解来声明远程调用的信息，比如： 服务名称：userservice 请求方式：GET 请求路径：/user/{id} 请求参数：Long id 返回值类型：User 这样，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate来发送了。 4）测试修改order-service中的OrderService类中的queryOrderById方法，使用Feign客户端代替RestTemplate： 是不是看起来优雅多了。 5）总结使用Feign的步骤： ① 引入依赖 ② 添加@EnableFeignClients注解 ③ 编写FeignClient接口 ④ 使用FeignClient中定义的方法代替RestTemplate 自定义配置Feign可以支持很多的自定义配置，如下表所示： 类型 作用 说明 feign.Logger.Level 修改日志级别 包含四种不同的级别：NONE、BASIC、HEADERS、FULL feign.codec.Decoder 响应结果的解析器 http远程调用的结果做解析，例如解析json字符串为java对象 feign.codec.Encoder 请求参数编码 将请求参数编码，便于通过http请求发送 feign. Contract 支持的注解格式 默认是SpringMVC的注解 feign. Retryer 失败重试机制 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。 下面以日志为例来演示如何自定义配置。 配置文件方式基于配置文件修改feign的日志级别可以针对单个服务： 12345feign: client: config: userservice: # 针对某个微服务的配置 loggerLevel: FULL # 日志级别 也可以针对所有服务： 12345feign: client: config: default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置 loggerLevel: FULL # 日志级别 而日志的级别分为四种： NONE：不记录任何日志信息，这是默认值。 BASIC：仅记录请求的方法，URL以及响应状态码和执行时间 HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息 FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。 Java代码方式也可以基于Java代码来修改日志级别，先声明一个类，然后声明一个Logger.Level的对象： 123456public class DefaultFeignConfiguration { @Bean public Logger.Level feignLogLevel(){ return Logger.Level.BASIC; // 日志级别为BASIC }} 如果要全局生效，将其放到启动类的@EnableFeignClients这个注解中： 1@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 如果是局部生效，则把它放到对应的@FeignClient这个注解中： 1@FeignClient(value = \"userservice\", configuration = DefaultFeignConfiguration .class) Feign使用优化Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括： •URLConnection：默认实现，不支持连接池 •Apache HttpClient ：支持连接池 •OKHttp：支持连接池 因此提高Feign的性能主要手段就是使用连接池代替默认的URLConnection。 这里我们用Apache的HttpClient来演示。 1）引入依赖 在order-service的pom文件中引入Apache的HttpClient依赖： 12345&lt;!--httpClient的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置连接池 在order-service的application.yml中添加配置： 123456789feign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 接下来，在FeignClientFactoryBean中的loadBalance方法中打断点： Debug方式启动order-service服务，可以看到这里的client，底层就是Apache HttpClient： 总结，Feign的优化： 1.日志级别尽量用basic 2.使用HttpClient或OKHttp代替URLConnection ① 引入feign-httpClient依赖 ② 配置文件开启httpClient功能，设置连接池参数 最佳实践所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。 自习观察可以发现，Feign的客户端与服务提供者的controller代码非常相似： feign客户端： UserController： 有没有一种办法简化这种重复的代码编写呢？ 继承方式一样的代码可以通过继承来共享： 1）定义一个API接口，利用定义方法，并基于SpringMVC注解做声明。 2）Feign客户端和Controller都集成改接口 优点： 简单 实现了代码共享 缺点： 服务提供方、服务消费方紧耦合 参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表、注解 抽取方式将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。 例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。 实现基于抽取的最佳实践1）抽取首先创建一个module，命名为feign-api： 项目结构： 在feign-api中然后引入feign的starter依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 然后，order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中 2）在order-service中使用feign-api首先，删除order-service中的UserClient、User、DefaultFeignConfiguration等类或接口。 在order-service的pom文件中中引入feign-api的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;cn.itcast.demo&lt;/groupId&gt; &lt;artifactId&gt;feign-api&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 修改order-service中的所有与上述三个组件有关的导包部分，改成导入feign-api中的包 3）重启测试重启后，发现服务报错了： 这是因为UserClient现在在cn.itcast.feign.clients包下， 而order-service的@EnableFeignClients注解是在cn.itcast.order包下，不在同一个包，无法扫描到UserClient。 4）解决扫描包问题方式一： 指定Feign应该扫描的包： 1@EnableFeignClients(basePackages = \"cn.itcast.feign.clients\") 方式二： 指定需要加载的Client接口： 1@EnableFeignClients(clients = {UserClient.class}) Gateway服务网关Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。 为什么需要网关Gateway网关是我们服务的守门神，所有微服务的统一入口。 网关的核心功能特性： 请求路由 权限控制 限流 架构图： 权限控制：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。 路由和负载均衡：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。 限流：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。 在SpringCloud中网关的实现包括两种： gateway zuul Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。 gateway快速入门下面，我们就演示下网关的基本路由功能。基本步骤如下： 创建SpringBoot工程gateway，引入网关依赖 编写启动类 编写基础配置和路由规则 启动网关服务进行测试 1）创建gateway服务，引入依赖创建服务： 引入依赖： 12345678910&lt;!--网关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--nacos服务发现依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 2）编写启动类123456789101112package cn.itcast.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 3）编写基础配置和路由规则创建application.yml文件，内容如下： 123456789101112131415server: port: 10010 # 网关端口spring: application: name: gateway # 服务名称 cloud: nacos: server-addr: localhost:8848 # nacos地址 gateway: routes: # 网关路由配置 - id: user-service # 路由id，自定义，只要唯一即可 # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址 uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称 predicates: # 路由断言，也就是判断请求是否符合路由规则的条件 - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求 我们将符合Path 规则的一切请求，都代理到 uri参数指定的地址。 本例中，我们将 /user/**开头的请求，代理到lb://userservice，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。 4）重启测试重启网关，访问http://localhost:10010/user/1时，符合`/user/**`规则，请求转发到uri：http://userservice/user/1，得到了结果： 5）网关路由的流程图整个访问的流程如下： 总结： 网关搭建步骤： 创建项目，引入nacos服务发现和gateway依赖 配置application.yml，包括服务基本信息、nacos地址、路由 路由配置包括： 路由id：路由的唯一标示 路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡 路由断言（predicates）：判断路由的规则， 路由过滤器（filters）：对请求或响应做处理 接下来，就重点来学习路由断言和路由过滤器的详细知识 断言工厂我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件 例如Path=/user/**是按照路径匹配，这个规则是由 org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来 处理的，像这样的断言工厂在SpringCloudGateway还有十几个: 名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[America/Denver] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/** Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 我们只需要掌握Path这种路由工程就可以了。 过滤器工厂GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理： 路由过滤器的种类Spring提供了31种不同的路由过滤器工厂。例如： 名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 请求头过滤器下面我们以AddRequestHeader 为例来讲解。 需求：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome! 只需要修改gateway服务的application.yml文件，添加路由过滤即可： 12345678910spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** filters: # 过滤器 - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头 当前过滤器写在userservice路由下，因此仅仅对访问userservice的请求有效。 默认过滤器如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下： 12345678910spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** default-filters: # 默认过滤项 - AddRequestHeader=Truth, Itcast is freaking awesome! 总结过滤器的作用是什么？ ① 对路由的请求或响应做加工处理，比如添加请求头 ② 配置在路由下的过滤器只对当前路由的请求生效 defaultFilters的作用是什么？ ① 对所有路由都生效的过滤器 全局过滤器上一节学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。 全局过滤器作用全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。 定义方式是实现GlobalFilter接口。 12345678910public interface GlobalFilter { /** * 处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理 * * @param exchange 请求上下文，里面可以获取Request、Response等信息 * @param chain 用来把请求委托给下一个过滤器 * @return {@code Mono&lt;Void&gt;} 返回标示当前过滤器业务结束 */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);} 在filter中编写自定义逻辑，可以实现下列功能： 登录状态判断 权限校验 请求限流等 自定义全局过滤器需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件： 参数中是否有authorization， authorization参数值是否为admin 如果同时满足则放行，否则拦截 实现： 在gateway中定义一个过滤器： 12345678910111213141516171819202122232425262728293031package cn.itcast.gateway.filters;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.annotation.Order;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;@Order(-1)@Componentpublic class AuthorizeFilter implements GlobalFilter { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求参数 MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams(); // 2.获取authorization参数 String auth = params.getFirst(\"authorization\"); // 3.校验 if (\"admin\".equals(auth)) { // 放行 return chain.filter(exchange); } // 4.拦截 // 4.1.禁止访问，设置状态码 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN); // 4.2.结束处理 return exchange.getResponse().setComplete(); }} 过滤器执行顺序请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter 请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器： 排序的规则是什么呢？ 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前。 GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。 当过滤器的order值一样时，会按照 defaultFilter &gt; 路由过滤器 &gt; GlobalFilter的顺序执行。 详细内容，可以查看源码： org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。 org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链 跨域问题什么是跨域问题跨域：域名不一致就是跨域，主要包括： 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com 域名相同，端口不同：localhost:8080和localhost8081 跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题 解决方案：CORS，这个以前应该学习过，这里不再赘述了。不知道的小伙伴可以查看https://www.ruanyifeng.com/blog/2016/04/cors.html 模拟跨域问题找到页面文件： 放入tomcat或者nginx这样的web服务器中，启动并访问。 可以在浏览器控制台看到下面的错误： 从localhost:8090访问localhost:10010，端口不同，显然是跨域的请求。 解决跨域问题在gateway服务的application.yml文件中，添加下面的配置： 12345678910111213141516171819spring: cloud: gateway: # 。。。 globalcors: # 全局的跨域处理 add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题 corsConfigurations: '[/**]': allowedOrigins: # 允许哪些网站的跨域请求 - \"http://localhost:8090\" allowedMethods: # 允许的跨域ajax的请求方式 - \"GET\" - \"POST\" - \"DELETE\" - \"PUT\" - \"OPTIONS\" allowedHeaders: \"*\" # 允许在请求中携带的头信息 allowCredentials: true # 是否允许携带cookie maxAge: 360000 # 这次跨域检测的有效期","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"hexo发生error：spawn failed错误","slug":"报错日常/hexo错误","date":"2022-07-31T22:16:06.000Z","updated":"2022-11-28T08:13:17.179Z","comments":true,"path":"2022/08/01/报错日常/hexo错误/","link":"","permalink":"http://example.com/2022/08/01/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/hexo%E9%94%99%E8%AF%AF/","excerpt":"","text":"hexo发生error：spawn failed错误例如: 123456789FATAL { err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (/usr/local/src/hexo/cairbin/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:376:20) at Process.ChildProcess._handle.onexit (internal/child_process.js:277:12) { code: 128 }} Something's wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 网上的解决方案基本上是一种 进行以下处理 1234567##进入博客根目录cd /usr/local/src/hexo/blog/##删除git提交文件夹rm -rf .deploy_git/git config --global core.autocrlf false 最后重新生成提交 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 还有一些是对于网络的处理,我在自己的电脑上试了很多种解决方案,都没有作用,后来我进入.deploy_git/目录下,输入cmd,然后运行 1git config --global core.autocrlf false 最后重新生成提交,就解决了 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d","categories":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}]},{"title":"运行docker-compose up -d 报错","slug":"报错日常/docker报错","date":"2022-07-31T22:15:06.000Z","updated":"2022-11-28T06:34:02.179Z","comments":true,"path":"2022/08/01/报错日常/docker报错/","link":"","permalink":"http://example.com/2022/08/01/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/docker%E6%8A%A5%E9%94%99/","excerpt":"","text":"运行docker-compose up -d 报错123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657ubuntu@ip-10-0-2-13:~/myapp/src$ docker-compose downWARNING: The VERSION_TAG variable is not set. Defaulting to a blank string.Traceback (most recent call last): File \"urllib3/connectionpool.py\", line 677, in urlopen File \"urllib3/connectionpool.py\", line 392, in _make_request File \"http/client.py\", line 1252, in request File \"http/client.py\", line 1298, in _send_request File \"http/client.py\", line 1247, in endheaders File \"http/client.py\", line 1026, in _send_output File \"http/client.py\", line 966, in send File \"docker/transport/unixconn.py\", line 43, in connectPermissionError: [Errno 13] Permission deniedDuring handling of the above exception, another exception occurred:Traceback (most recent call last): File \"requests/adapters.py\", line 449, in send File \"urllib3/connectionpool.py\", line 727, in urlopen File \"urllib3/util/retry.py\", line 403, in increment File \"urllib3/packages/six.py\", line 734, in reraise File \"urllib3/connectionpool.py\", line 677, in urlopen File \"urllib3/connectionpool.py\", line 392, in _make_request File \"http/client.py\", line 1252, in request File \"http/client.py\", line 1298, in _send_request File \"http/client.py\", line 1247, in endheaders File \"http/client.py\", line 1026, in _send_output File \"http/client.py\", line 966, in send File \"docker/transport/unixconn.py\", line 43, in connecturllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"docker/api/client.py\", line 205, in _retrieve_server_version File \"docker/api/daemon.py\", line 181, in version File \"docker/utils/decorators.py\", line 46, in inner File \"docker/api/client.py\", line 228, in _get File \"requests/sessions.py\", line 543, in get File \"requests/sessions.py\", line 530, in request File \"requests/sessions.py\", line 643, in send File \"requests/adapters.py\", line 498, in sendrequests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"bin/docker-compose\", line 3, in &lt;module&gt; File \"compose/cli/main.py\", line 67, in main File \"compose/cli/main.py\", line 123, in perform_command File \"compose/cli/command.py\", line 69, in project_from_options File \"compose/cli/command.py\", line 132, in get_project File \"compose/cli/docker_client.py\", line 43, in get_client File \"compose/cli/docker_client.py\", line 170, in docker_client File \"docker/api/client.py\", line 188, in __init__ File \"docker/api/client.py\", line 213, in _retrieve_server_versiondocker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))[19602] Failed to execute script docker-compose 解决方案 使用sudo usermod -aG docker $USER将您的用户添加到docker组，然后重启docker服务器 12sudo usermod -aG docker $USERsudo systemctl start docker","categories":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}]},{"title":"SpringCloud基础02","slug":"笔记/技术/SpringCloud基础02","date":"2022-07-31T22:13:09.000Z","updated":"2022-11-28T10:12:12.951Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud基础02/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%9F%BA%E7%A1%8002/","excerpt":"","text":"SpringCloudEureka注册中心假如我们的服务提供者user-service部署了多个实例，如图： 大家思考几个问题： order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？ 有多个user-service实例地址，order-service调用时该如何选择？ order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ Eureka的结构和作用这些问题都需要利用SpringCloud中的注册中心来解决，其中最广为人知的注册中心就是Eureka，其结构如下： 回答之前的各个问题。 问题1：order-service如何得知user-service实例地址？ 获取地址信息的流程如下： user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。这个叫服务注册 eureka-server保存服务名称到服务实例地址列表的映射关系 order-service根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取 问题2：order-service如何从多个user-service实例中选择具体的实例？ order-service从实例列表中利用负载均衡算法选中一个实例地址 向该实例地址发起远程调用 问题3：order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态，称为心跳 当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除 order-service拉取服务时，就能将故障实例排除了 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端 因此，接下来我们动手实践的步骤包括： 搭建eureka-server首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务 创建eureka-server服务在cloud-demo父工程下，创建一个子模块： 填写模块信息： 然后填写服务信息： 引入eureka依赖引入SpringCloud为eureka提供的starter依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 编写启动类给eureka-server服务编写一个启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能： 12345678910111213package cn.itcast.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); }} 编写配置文件编写一个application.yml文件，内容如下： 123456789server: port: 10086spring: application: name: eureka-servereureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 启动服务启动微服务，然后在浏览器访问：http://127.0.0.1:10086 看到下面结果应该是成功了： 服务注册下面，我们将user-service注册到eureka-server中去。 1）引入依赖在user-service的pom文件中，引入下面的eureka-client依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置文件在user-service中，修改application.yml文件，添加服务名称、eureka地址： 1234567spring: application: name: userserviceeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）启动多个user-service实例为了演示一个服务有多个实例的场景，我们添加一个SpringBoot的启动配置，再启动一个user-service。 首先，复制原来的user-service启动配置： 然后，在弹出的窗口中，填写信息： 现在，SpringBoot窗口会出现两个user-service启动配置： 不过，第一个是8081端口，第二个是8082端口。 启动两个user-service实例： 查看eureka-server管理页面： 服务发现下面，我们将order-service的逻辑修改：向eureka-server拉取user-service的信息，实现服务发现。 1）引入依赖之前说过，服务发现、服务注册统一都封装在eureka-client依赖，因此这一步与服务注册时一致。 在order-service的pom文件中，引入下面的eureka-client依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置文件服务发现也需要知道eureka地址，因此第二步与服务注册一致，都是配置eureka信息： 在order-service中，修改application.yml文件，添加服务名称、eureka地址： 1234567spring: application: name: orderserviceeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）服务拉取和负载均衡最后，我们要去eureka-server中拉取user-service服务的实例列表，并且实现负载均衡。 不过这些动作不用我们去做，只需要添加一些注解即可。 在order-service的OrderApplication中，给RestTemplate这个Bean添加一个@LoadBalanced注解： 修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法。修改访问的url路径，用服务名代替ip、端口： spring会自动帮助我们从eureka-server端，根据userservice这个服务名称，获取实例列表，而后完成负载均衡。 Ribbon负载均衡上一节中，我们添加了@LoadBalanced注解，即可实现负载均衡功能，这是什么原理呢？ 负载均衡原理SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。 那么我们发出的请求明明是http://userservice/user/1，怎么变成了http://localhost:8081的呢？ 源码跟踪为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。 显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是LoadBalancerInterceptor，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。 我们进行源码跟踪： 1）LoadBalancerIntercepor 可以看到这里的intercept方法，拦截了用户的HttpRequest请求，然后做了几件事： request.getURI()：获取请求uri，本例中就是 http://user-service/user/8 originalUri.getHost()：获取uri路径的主机名，其实就是服务id，user-service this.loadBalancer.execute()：处理服务id，和用户请求。 这里的this.loadBalancer是LoadBalancerClient类型，我们继续跟入。 2）LoadBalancerClient继续跟入execute方法： 代码是这样的： getLoadBalancer(serviceId)：根据服务id获取ILoadBalancer，而ILoadBalancer会拿着服务id去eureka中获取服务列表并保存起来。 getServer(loadBalancer)：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8082端口的服务 放行后，再次访问并跟踪，发现获取的是8081： 果然实现了负载均衡。 3）负载均衡策略IRule在刚才的代码中，可以看到获取服务使通过一个getServer方法来做负载均衡: 我们继续跟入： 继续跟踪源码chooseServer方法，发现这么一段代码： 我们看看这个rule是谁： 这里的rule默认值是一个RoundRobinRule，看类的介绍： 这不就是轮询的意思嘛。 到这里，整个负载均衡的流程我们就清楚了。 4）总结SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下： 基本流程如下： 拦截我们的RestTemplate请求http://userservice/user/1 RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表 eureka返回列表，localhost:8081、localhost:8082 IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081 RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求 负载均衡策略负载均衡策略负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类： 不同规则的含义如下： 内置负载均衡规则类 规则描述 RoundRobinRule 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 BestAvailableRule 忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机选择一个可用的服务器。 RetryRule 重试机制的选择逻辑 默认的实现就是ZoneAvoidanceRule，是一种轮询方案 自定义负载均衡策略通过定义IRule实现可以修改负载均衡规则，有两种方式： 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule： 1234@Beanpublic IRule randomRule(){ return new RandomRule();} 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则： 123userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 注意，一般用默认的负载均衡规则，不做修改。 饥饿加载Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。 而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载： 1234ribbon: eager-load: enabled: true clients: userservice Nacos注册中心国内公司一般都推崇阿里巴巴的技术，比如注册中心，SpringCloudAlibaba也推出了一个名为Nacos的注册中心。 认识和安装NacosNacos是阿里巴巴的产品，现在是SpringCloud中的一个组件。相比Eureka功能更加丰富，在国内受欢迎程度较高。 服务注册到nacosNacos是SpringCloudAlibaba的组件，而SpringCloudAlibaba也遵循SpringCloud中定义的服务注册、服务发现规范。因此使用Nacos和使用Eureka对于微服务来说，并没有太大区别。 主要差异在于： 依赖不同 服务地址不同 1）引入依赖在cloud-demo父工程的pom文件中的&lt;dependencyManagement&gt;中引入SpringCloudAlibaba的依赖： 1234567&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 然后在user-service和order-service中的pom文件中引入nacos-discovery依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 注意：不要忘了注释掉eureka的依赖。 2）配置nacos地址在user-service和order-service的application.yml中添加nacos地址： 1234spring: cloud: nacos: server-addr: localhost:8848 注意：不要忘了注释掉eureka的地址 3）重启重启微服务后，登录nacos管理页面，可以看到微服务信息： 服务分级存储模型一个服务可以有多个实例，例如我们的user-service，可以有: 127.0.0.1:8081 127.0.0.1:8082 127.0.0.1:8083 假如这些实例分布于全国各地的不同机房，例如： 127.0.0.1:8081，在上海机房 127.0.0.1:8082，在上海机房 127.0.0.1:8083，在杭州机房 Nacos就将同一机房内的实例 划分为一个集群。 也就是说，user-service是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图： 微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如： 杭州机房内的order-service应该优先访问同机房的user-service。 给user-service配置集群修改user-service的application.yml文件，添加集群配置： 123456spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 重启两个user-service实例后，我们可以在nacos控制台看到下面结果： 我们再次复制一个user-service启动配置，添加属性： 1-Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH 配置如图所示： 启动UserApplication3后再次查看nacos控制台： 同集群优先的负载均衡默认的ZoneAvoidanceRule并不能实现根据同集群优先来实现负载均衡。 因此Nacos中提供了一个NacosRule的实现，可以优先从同集群中挑选实例。 1）给order-service配置集群信息 修改order-service的application.yml文件，添加集群配置： 123456spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 2）修改负载均衡规则 修改order-service的application.yml文件，修改负载均衡规则： 123userservice: ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 权重配置实际部署中会出现这样的场景： 服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。 但默认情况下NacosRule是同集群内随机挑选，不会考虑机器的性能问题。 因此，Nacos提供了权重配置来控制访问频率，权重越大则访问频率越高。 在nacos控制台，找到user-service的实例列表，点击编辑，即可修改权重： 在弹出的编辑窗口，修改权重： 注意：如果权重修改为0，则该实例永远不会被访问 环境隔离Nacos提供了namespace来实现环境隔离功能。 nacos中可以有多个namespace namespace下可以有group、service等 不同namespace之间相互隔离，例如不同namespace的服务互相不可见 创建namespace默认情况下，所有service、data、group都在同一个namespace，名为public： 我们可以点击页面新增按钮，添加一个namespace： 然后，填写表单： 就能在页面看到一个新的namespace： 给微服务配置namespace给微服务配置namespace只能通过修改配置来实现。 例如，修改order-service的application.yml文件： 1234567spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID 重启order-service后，访问控制台，可以看到下面的结果： 此时访问order-service，因为namespace不同，会导致找不到userservice，控制台会报错： Nacos与Eureka的区别Nacos的服务实例分为两种l类型： 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。 配置一个服务实例为永久实例： 12345spring: cloud: nacos: discovery: ephemeral: false # 设置为非临时实例 Nacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异： Nacos与eureka的共同点 都支持服务注册和服务拉取 都支持服务提供者心跳方式做健康检测 Nacos与Eureka的区别 Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式 临时实例心跳不正常会被剔除，非临时实例则不会被剔除 Nacos支持服务列表变更的消息推送模式，服务列表更新更及时 Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud基础01","slug":"笔记/技术/SpringCloud基础01","date":"2022-07-31T22:12:09.000Z","updated":"2022-11-28T10:12:04.665Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud基础01/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%9F%BA%E7%A1%8001/","excerpt":"","text":"SpringCloud认识微服务随着互联网行业的发展，对服务的要求也越来越高，服务架构也从单体架构逐渐演变为现在流行的微服务架构。这些架构之间有怎样的差别呢？ 单体架构单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。 单体架构的优缺点如下： 优点： 架构简单 部署成本低 缺点： 耦合度高（维护困难、升级困难） 分布式架构分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。 分布式架构的优缺点： 优点： 降低服务耦合 有利于服务升级和拓展 缺点： 服务调用关系错综复杂 分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考： 服务拆分的粒度如何界定？ 服务之间如何调用？ 服务的调用关系如何管理？ 人们需要制定一套行之有效的标准来约束分布式架构。 微服务微服务的架构特征： 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责 自治：团队独立、技术独立、数据独立，独立部署和交付 面向服务：服务提供统一标准的接口，与语言和技术无关 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。 因此，可以认为微服务是一种经过良好架构设计的分布式架构方案 。 但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。 其中在Java领域最引人注目的就是SpringCloud提供的方案了。 SpringCloudSpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。 SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。 其中常见的组件包括： 另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下： Hoxton.SR10对应的SpringBoot版本是2.3.x版本。 总结 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝 微服务：一种良好的分布式架构方案 ①优点：拆分粒度更小、服务更独立、耦合度更低 ②缺点：架构非常复杂，运维、监控、部署难度提高 SpringCloud是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件 服务拆分和远程调用任何分布式架构都离不开服务的拆分，微服务也是一样。 服务拆分原则这里我总结了微服务拆分时的几个原则： 不同微服务，不要重复开发相同业务 微服务数据独立，不要访问其它微服务的数据库 微服务可以将自己的业务暴露为接口，供其它微服务调用 服务拆分示例以课前资料中的微服务cloud-demo为例，其结构如下： cloud-demo：父工程，管理依赖 order-service：订单微服务，负责订单相关业务 user-service：用户微服务，负责用户相关业务 要求： 订单微服务和用户微服务都必须有各自的数据库，相互独立 订单服务和用户服务都对外暴露Restful的接口 订单服务如果需要查询用户信息，只能调用用户服务的Restful接口，不能查询用户数据库 导入Sql语句首先，将课前资料提供的cloud-order.sql和cloud-user.sql导入到mysql中： cloud-user表中初始数据如下： cloud-order表中初始数据如下： cloud-order表中持有cloud-user表中的id字段。 导入demo工程用IDEA导入课前资料提供的Demo： 项目结构如下： 导入后，会在IDEA右下角出现弹窗： 点击弹窗，然后按下图选择： 会出现这样的菜单： 配置下项目使用的JDK： 实现远程调用案例在order-service服务中，有一个根据id查询订单的接口： 根据id查询订单，返回值是Order对象，如图： 其中的user为null 在user-service中有一个根据id查询用户的接口： 查询的结果如图： 案例需求：修改order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。 因此，我们需要在order-service中 向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口。 大概的步骤是这样的： 注册一个RestTemplate的实例到Spring容器 修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User 将查询的User填充到Order对象，一起返回 注册RestTemplate首先，我们在order-service服务中的OrderApplication启动类中，注册RestTemplate实例： 123456789101112131415161718192021package cn.itcast.order;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@MapperScan(\"cn.itcast.order.mapper\")@SpringBootApplicationpublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); }} 实现远程调用修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法： 提供者与消费者在服务调用关系中，会有两个不同的角色： 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务） 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口） 但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。 如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？ 对于A调用B的业务而言：A是服务消费者，B是服务提供者 对于B调用C的业务而言：B是服务消费者，C是服务提供者 因此，服务B既可以是服务提供者，也可以是服务消费者。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"MyBatisPlus基础","slug":"笔记/技术/MyBatisPlus基础","date":"2022-07-31T22:11:09.000Z","updated":"2022-11-28T10:11:15.791Z","comments":true,"path":"2022/08/01/笔记/技术/MyBatisPlus基础/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/MyBatisPlus%E5%9F%BA%E7%A1%80/","excerpt":"","text":"MyBatisPlus简介入门案例问题导入MyBatisPlus环境搭建的步骤？ SpringBoot整合MyBatisPlus入门程序①：创建新模块，选择Spring初始化，并配置模块相关基础信息 ②：选择当前模块需要使用的技术集（仅保留JDBC） ③：手动添加MyBatisPlus起步依赖12345678910&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 注意事项1：由于mp并未被收录到idea的系统内置配置，无法直接选择加入 注意事项2：如果使用Druid数据源，需要导入对应坐标 注意事项3：mybatis的jar包和springboot整合mybatis的jar包已经导进去了 ④：制作实体类与表结构（类名与表名对应，属性名与字段名对应） 12345678910111213141516create database if not exists mybatisplus_db character set utf8;use mybatisplus_db;CREATE TABLE user ( id bigint(20) primary key auto_increment, name varchar(32) not null, password varchar(32) not null, age int(3) not null , tel varchar(32) not null);insert into user values(null,'tom','123456',12,'12345678910');insert into user values(null,'jack','123456',8,'12345678910');insert into user values(null,'jerry','123456',15,'12345678910');insert into user values(null,'tom','123456',9,'12345678910');insert into user values(null,'snake','123456',28,'12345678910');insert into user values(null,'张益达','123456',22,'12345678910');insert into user values(null,'张大炮','123456',16,'12345678910'); 12345678public class User { private Long id; private String name; private String password; private Integer age; private String tel; //自行添加getter、setter、toString()等方法} ⑤：设置Jdbc参数（application.yml）1234567spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root ⑥：定义数据接口，继承BaseMapper12345678910package com.itheima.dao;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.itheima.domain.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserDao extends BaseMapper&lt;User&gt; {} ⑦：测试类中注入dao接口，测试功能12345678910111213141516171819202122package com.itheima;import com.itheima.dao.UserDao;import com.itheima.domain.User;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.List;@SpringBootTestpublic class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); }} MyBatisPlus概述问题导入通过入门案例制作，MyBatisPlus的优点有哪些？ MyBatis介绍 MyBatisPlus（简称MP）是基于MyBatis框架基础上开发的增强型工具，旨在简化开发、提高效率 官网：https://mybatis.plus/ https://mp.baomidou.com/ MyBatisPlus特性 无侵入：只做增强不做改变，不会对现有工程产生影响 强大的 CRUD 操作：内置通用 Mapper，少量配置即可实现单表CRUD 操作 支持 Lambda：编写查询条件无需担心字段写错 支持主键自动生成 内置分页插件 …… 标准数据层开发MyBatisPlus的CRUD操作 注意事项1：update提供哪些字段就修改哪些字段 注意事项2：对齐 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.itheima;import com.itheima.dao.UserDao;import com.itheima.domain.User;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.List;@SpringBootTestclass Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testSave() { User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } @Test void testDelete() { userDao.deleteById(1401856123725713409L); } @Test void testUpdate() { User user = new User(); user.setId(1L); user.setName(\"Tom888\"); user.setPassword(\"tom888\"); userDao.updateById(user); } @Test void testGetById() { User user = userDao.selectById(2L); System.out.println(user); } @Test void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); }} Lombok插件介绍问题导入有什么简单的办法可以自动生成实体类的GET、SET方法？ Lombok，一个Java类库，提供了一组注解，简化POJO实体类开发。 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt;&lt;/dependency&gt; 常用注解：==@Data==，为当前实体类在编译期设置对应的get/set方法，无参/无参构造方法，toString方法，hashCode方法，equals方法等 123456789101112131415161718192021222324package com.itheima.domain;import lombok.*;/* 1 生成getter和setter方法：@Getter、@Setter 生成toString方法：@ToString 生成equals和hashcode方法：@EqualsAndHashCode 2 统一成以上所有：@Data 3 生成空参构造： @NoArgsConstructor 生成全参构造： @AllArgsConstructor 4 lombok还给我们提供了builder的方式创建对象,好处就是可以链式编程。 @Builder【扩展】 */@Datapublic class User { private Long id; private String name; private String password; private Integer age; private String tel;} MyBatisPlus分页功能问题导入思考一下Mybatis分页插件是如何用的？ 分页功能接口 MyBatisPlus分页使用①：设置分页拦截器作为Spring管理的bean 12345678910111213141516171819package com.itheima.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ //1 创建MybatisPlusInterceptor拦截器对象 MybatisPlusInterceptor mpInterceptor=new MybatisPlusInterceptor(); //2 添加分页拦截器 mpInterceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return mpInterceptor; }} ②：执行分页查询 1234567891011121314//分页查询@Testvoid testSelectPage(){ //1 创建IPage分页对象,设置分页参数 IPage&lt;User&gt; page=new Page&lt;&gt;(1,3); //2 执行分页查询 userDao.selectPage(page,null); //3 获取分页结果 System.out.println(\"当前页码值：\"+page.getCurrent()); System.out.println(\"每页显示数：\"+page.getSize()); System.out.println(\"总页数：\"+page.getPages()); System.out.println(\"总条数：\"+page.getTotal()); System.out.println(\"当前页数据：\"+page.getRecords());} 开启MyBatisPlus日志1234567891011spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root# 开启mp的日志（输出到控制台）mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 解决日志打印过多问题取消初始化spring日志打印 做法：在resources下新建一个logback.xml文件，名称固定，内容如下： 1234&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt;&lt;/configuration&gt; 关于logback参考播客：https://www.jianshu.com/p/75f9d11ae011 取消SpringBoot启动banner图标 123spring: main: banner-mode: off # 关闭SpringBoot启动图标(banner) 取消MybatisPlus启动banner图标 123456# mybatis-plus日志控制台输出mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: banner: off # 关闭mybatisplus启动图标 DQL编程控制条件查询方式 MyBatisPlus将书写复杂的SQL查询条件进行了封装，使用编程的形式完成查询条件的组合 条件查询方式一：按条件查询12345//方式一：按条件查询QueryWrapper&lt;User&gt; qw=new QueryWrapper&lt;&gt;();qw.lt(\"age\", 18);List&lt;User&gt; userList = userDao.selectList(qw);System.out.println(userList); 方式二：lambda格式按条件查询12345//方式二：lambda格式按条件查询QueryWrapper&lt;User&gt; qw = new QueryWrapper&lt;User&gt;();qw.lambda().lt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(qw);System.out.println(userList); 方式三：lambda格式按条件查询（推荐）12345//方式三：lambda格式按条件查询LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();lqw.lt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 组合条件并且关系（and）123456//并且关系LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//并且关系：10到30岁之间lqw.lt(User::getAge, 30).gt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 或者关系（or）123456//或者关系LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//或者关系：小于10岁或者大于30岁lqw.lt(User::getAge, 10).or().gt(User::getAge, 30);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); NULL值处理问题导入如下搜索场景，在多条件查询中，有条件的值为空应该怎么解决？ if语句控制条件追加1234567891011Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();if(minAge!=null){ lqw.gt(User::getAge, minAge);}if(maxAge!=null){ lqw.lt(User::getAge, maxAge);}List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 条件参数控制12345678Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//参数1：如果表达式为true，那么查询才使用该条件lqw.gt(minAge!=null,User::getAge, minAge);lqw.lt(maxAge!=null,User::getAge, maxAge);List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 条件参数控制（链式编程）12345678Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//参数1：如果表达式为true，那么查询才使用该条件lqw.gt(minAge!=null,User::getAge, minAge) .lt(maxAge!=null,User::getAge, maxAge);List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 查询投影-设置【查询字段、分组、分页】查询结果包含模型类中部分属性1234567/*LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();lqw.select(User::getId, User::getName, User::getAge);*///或者QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;();lqw.select(\"id\", \"name\", \"age\", \"tel\");List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 查询结果包含模型类中未定义的属性12345QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;();lqw.select(\"count(*) as count, tel\");lqw.groupBy(\"tel\");List&lt;Map&lt;String, Object&gt;&gt; userList = userDao.selectMaps(lqw);System.out.println(userList); 查询条件设定问题导入多条件查询有哪些组合？ 范围匹配（&gt; 、 = 、between） 模糊匹配（like） 空判定（null） 包含性匹配（in） 分组（group） 排序（order） …… 查询条件 用户登录（eq匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//等同于=lqw.eq(User::getName, \"Jerry\").eq(User::getPassword, \"jerry\");User loginUser = userDao.selectOne(lqw);System.out.println(loginUser); 购物设定价格区间、户籍设定年龄区间（le ge匹配 或 between匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//范围查询 lt le gt ge eq betweenlqw.between(User::getAge, 10, 30);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 查信息，搜索新闻（非全文检索版：like匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//模糊匹配 likelqw.likeLeft(User::getName, \"J\");List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 统计报表（分组查询聚合函数） 12345QueryWrapper&lt;User&gt; qw = new QueryWrapper&lt;User&gt;();qw.select(\"gender\",\"count(*) as nums\");qw.groupBy(\"gender\");List&lt;Map&lt;String, Object&gt;&gt; maps = userDao.selectMaps(qw);System.out.println(maps); 查询API 更多查询条件设置参看 https://mybatis.plus/guide/wrapper.html#abstractwrapper 字段映射与表名映射问题导入思考表的字段和实体类的属性不对应，查询会怎么样？ 问题一：表字段与编码属性设计不同步 在模型类属性上方，使用**@TableField**属性注解，通过==value==属性，设置当前属性对应的数据库表中的字段关系。 问题二：编码中添加了数据库中未定义的属性 在模型类属性上方，使用**@TableField注解，通过==exist==**属性，设置属性在数据库表字段中是否存在，默认为true。此属性无法与value合并使用。 问题三：采用默认查询开放了更多的字段查看权限 在模型类属性上方，使用**@TableField注解，通过==select==**属性：设置该属性是否参与查询。此属性与select()映射配置不冲突。 问题四：表名与编码开发设计不同步 在模型类上方，使用**@TableName注解，通过==value==**属性，设置当前类对应的数据库表名称。 12345678910111213141516@Data@TableName(\"tbl_user\")public class User { /* id为Long类型，因为数据库中id为bigint类型， 并且mybatis有自己的一套id生成方案，生成出来的id必须是Long类型 */ private Long id; private String name; @TableField(value = \"pwd\",select = false) private String password; private Integer age; private String tel; @TableField(exist = false) //表示online字段不参与CRUD操作 private Boolean online;} DML编程控制id生成策略控制（Insert）问题导入主键生成的策略有哪几种方式？ 不同的表应用不同的id生成策略 日志：自增（1,2,3,4，……） 购物订单：特殊规则（FQ23948AK3843） 外卖单：关联地区日期等信息（10 04 20200314 34 91） 关系表：可省略id …… id生成策略控制（@TableId注解） 名称：@TableId 类型：属性注解 位置：模型类中用于表示主键的属性定义上方 作用：设置当前类中主键属性的生成策略 相关属性 ​ type：设置主键属性的生成策略，值参照IdType枚举值 全局策略配置12345mybatis-plus: global-config: db-config: id-type: assign_id table-prefix: tbl_ id生成策略全局配置 表名前缀全局配置 多记录操作（批量Delete/Select）问题导入MyBatisPlus是否支持批量操作？ 按照主键删除多条记录1234567//删除指定多条数据List&lt;Long&gt; list = new ArrayList&lt;&gt;();list.add(1402551342481838081L);list.add(1402553134049501186L);list.add(1402553619611430913L);userDao.deleteBatchIds(list); 根据主键查询多条记录123456//查询指定多条数据List&lt;Long&gt; list = new ArrayList&lt;&gt;();list.add(1L);list.add(3L);list.add(4L);userDao.selectBatchIds(list); 逻辑删除（Delete/Update）问题导入在实际环境中，如果想删除一条数据，是否会真的从数据库中删除该条数据？ 删除操作业务问题：业务数据从数据库中丢弃 逻辑删除：为数据设置是否可用状态字段，删除时设置状态字段为不可用状态，数据保留在数据库中 逻辑删除案例①：数据库表中添加逻辑删除标记字段 ②：实体类中添加对应字段，并设定当前字段为逻辑删除标记字段12345678910111213141516package com.itheima.domain;import com.baomidou.mybatisplus.annotation.*;import lombok.Data;@Datapublic class User { private Long id; //逻辑删除字段，标记当前记录是否被删除 @TableLogic private Integer deleted; } ③：配置逻辑删除字面值12345678910mybatis-plus: global-config: db-config: table-prefix: tbl_ # 逻辑删除字段名 logic-delete-field: deleted # 逻辑删除字面值：未删除为0 logic-not-delete-value: 0 # 逻辑删除字面值：删除为1 logic-delete-value: 1 逻辑删除本质：逻辑删除的本质其实是修改操作。如果加了逻辑删除字段，查询数据时也会自动带上逻辑删除字段。 乐观锁（Update）问题导入乐观锁主张的思想是什么？ 业务并发现象带来的问题：秒杀 乐观锁案例①：数据库表中添加锁标记字段 ②：实体类中添加对应字段，并设定当前字段为逻辑删除标记字段12345678910111213141516package com.itheima.domain;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableLogic;import com.baomidou.mybatisplus.annotation.Version;import lombok.Data;@Datapublic class User { private Long id; @Version private Integer version;} ③：配置乐观锁拦截器实现锁机制对应的动态SQL语句拼装12345678910111213141516171819202122package com.itheima.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MpConfig { @Bean public MybatisPlusInterceptor mpInterceptor() { //1.定义Mp拦截器 MybatisPlusInterceptor mpInterceptor = new MybatisPlusInterceptor(); //2.添加乐观锁拦截器 mpInterceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return mpInterceptor; }} ④：使用乐观锁机制在修改前必须先获取到对应数据的verion方可正常进行12345678910111213141516171819202122@Testpublic void testUpdate() { /*User user = new User(); user.setId(3L); user.setName(\"Jock666\"); user.setVersion(1); userDao.updateById(user);*/ //1.先通过要修改的数据id将当前数据查询出来 //User user = userDao.selectById(3L); //2.将要修改的属性逐一设置进去 //user.setName(\"Jock888\"); //userDao.updateById(user); //1.先通过要修改的数据id将当前数据查询出来 User user = userDao.selectById(3L); //version=3 User user2 = userDao.selectById(3L); //version=3 user2.setName(\"Jock aaa\"); userDao.updateById(user2); //version=&gt;4 user.setName(\"Jock bbb\"); userDao.updateById(user); //verion=3?条件还成立吗？} 快速开发-代码生成器问题导入如果只给一张表的字段信息，能够推演出Domain、Dao层的代码？ MyBatisPlus提供模板 Mapper接口模板 实体对象类模板 工程搭建和基本代码编写 第一步：创建SpringBoot工程，添加代码生成器相关依赖，其他依赖自行添加 12345678910111213&lt;!--代码生成器--&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--velocity模板引擎--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt; 第二步：编写代码生成器类 1234567891011121314151617181920212223package com.itheima;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.config.DataSourceConfig;public class Generator { public static void main(String[] args) { //1. 创建代码生成器对象，执行生成代码操作 AutoGenerator autoGenerator = new AutoGenerator(); //2. 数据源相关配置：读取数据库中的信息，根据数据库表结构生成代码 DataSourceConfig dataSource = new DataSourceConfig(); dataSource.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"root\"); autoGenerator.setDataSource(dataSource); //3. 执行生成操作 autoGenerator.execute(); }} 开发者自定义配置 设置全局配置 123456789//设置全局配置GlobalConfig globalConfig = new GlobalConfig();globalConfig.setOutputDir(System.getProperty(\"user.dir\")+\"/mybatisplus_04_generator/src/main/java\"); //设置代码生成位置globalConfig.setOpen(false); //设置生成完毕后是否打开生成代码所在的目录globalConfig.setAuthor(\"黑马程序员\"); //设置作者globalConfig.setFileOverride(true); //设置是否覆盖原始生成的文件globalConfig.setMapperName(\"%sDao\"); //设置数据层接口名，%s为占位符，指代模块名称globalConfig.setIdType(IdType.ASSIGN_ID); //设置Id生成策略autoGenerator.setGlobalConfig(globalConfig); 设置包名相关配置 123456//设置包名相关配置PackageConfig packageInfo = new PackageConfig();packageInfo.setParent(\"com.aaa\"); //设置生成的包名，与代码所在位置不冲突，二者叠加组成完整路径packageInfo.setEntity(\"domain\"); //设置实体类包名packageInfo.setMapper(\"dao\"); //设置数据层包名autoGenerator.setPackageInfo(packageInfo); 策略设置 123456789//策略设置StrategyConfig strategyConfig = new StrategyConfig();strategyConfig.setInclude(\"tbl_user\"); //设置当前参与生成的表名，参数为可变参数strategyConfig.setTablePrefix(\"tbl_\"); //设置数据库表的前缀名称，模块名 = 数据库表名 - 前缀名 例如： User = tbl_user - tbl_strategyConfig.setRestControllerStyle(true); //设置是否启用Rest风格strategyConfig.setVersionFieldName(\"version\"); //设置乐观锁字段名strategyConfig.setLogicDeleteFieldName(\"deleted\"); //设置逻辑删除字段名strategyConfig.setEntityLombokModel(true); //设置是否启用lombokautoGenerator.setStrategy(strategyConfig); 说明：在资料中也提供了CodeGenerator代码生成器类，根据实际情况修改后可以直接使用。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"MyBatisPlus","slug":"MyBatisPlus","permalink":"http://example.com/tags/MyBatisPlus/"}]},{"title":"Redis基础","slug":"笔记/技术/Redis基础","date":"2022-07-31T22:10:09.000Z","updated":"2022-11-28T10:11:36.184Z","comments":true,"path":"2022/08/01/笔记/技术/Redis基础/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Redis%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Redis基础前言什么是RedisRedis是一个基于内存的key-value结构数据库。Redis 是互联网技术领域使用最为广泛的存储中间件，它是「Remote Dictionary Service」的首字母缩写，也就是「远程字典服务」。 基于内存存储，读写性能高 适合存储热点数据（热点商品、资讯、新闻） 企业应用广泛 使用Redis能做什么 数据缓存 消息队列 注册中心 发布订阅 Redis入门Redis简介Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker. 翻译为：Redis是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。 官网：https://redis.io Redis是用C语言开发的一个开源的高性能键值对(key-value)数据库，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。它存储的value类型比较丰富，也被称为结构化的NoSql数据库。 NoSql（Not Only SQL），不仅仅是SQL，泛指非关系型数据库。NoSql数据库并不是要取代关系型数据库，而是关系型数据库的补充。 关系型数据库(RDBMS)： Mysql Oracle DB2 SQLServer 非关系型数据库(NoSql)： Redis Mongo db MemCached Redis数据类型介绍Redis存储的是key-value结构的数据，其中key是字符串类型，value有5种常用的数据类型： 字符串 string 哈希 hash 列表 list 集合 set 有序集合 sorted set / zset Redis 5种常用数据类型 解释说明： 字符串(string)：普通字符串，常用 哈希(hash)：适合存储对象 列表(list)：按照插入顺序排序，可以有重复元素 集合(set)：无序集合，没有重复元素 有序集合(sorted set / zset)：集合中每个元素关联一个分数（score），根据分数升序排序，没有重复元素 Redis常用命令字符串string操作命令Redis 中字符串类型常用命令： SET key value 设置指定key的值 GET key 获取指定key的值 SETEX key seconds value 设置指定key的值，并将 key 的过期时间设为 seconds 秒 SETNX key value 只有在 key 不存在时设置 key 的值 更多命令可以参考Redis中文网：https://www.redis.net.cn 哈希hash操作命令Redis hash 是一个string类型的 field 和 value 的映射表，hash特别适合用于存储对象，常用命令： HSET key field value 将哈希表 key 中的字段 field 的值设为 value HGET key field 获取存储在哈希表中指定字段的值 HDEL key field 删除存储在哈希表中的指定字段 HKEYS key 获取哈希表中所有字段 HVALS key 获取哈希表中所有值 HGETALL key 获取在哈希表中指定 key 的所有字段和值 列表list操作命令Redis 列表是简单的字符串列表，按照插入顺序排序，常用命令： LPUSH key value1 [value2] 将一个或多个值插入到列表头部 LRANGE key start stop 获取列表指定范围内的元素 RPOP key 移除并获取列表最后一个元素 LLEN key 获取列表长度 BRPOP key1 [key2 ] timeout 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超 时或发现可弹出元素为止 集合set操作命令Redis set 是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据，常用命令： SADD key member1 [member2] 向集合添加一个或多个成员 SMEMBERS key 返回集合中的所有成员 SCARD key 获取集合的成员数 SINTER key1 [key2] 返回给定所有集合的交集 SUNION key1 [key2] 返回所有给定集合的并集 SDIFF key1 [key2] 返回给定所有集合的差集 SREM key member1 [member2] 移除集合中一个或多个成员 有序集合sorted set操作命令Redis sorted set 有序集合是 string 类型元素的集合，且不允许重复的成员。每个元素都会关联一个double类型的分数(score) 。redis正是通过分数来为集合中的成员进行从小到大排序。有序集合的成员是唯一的，但分数却可以重复。 常用命令： ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的 分数 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合中指定区间内的成员 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量 increment ZREM key member [member …] 移除有序集合中的一个或多个成员 通用命令Redis中的通用命令，主要是针对key进行操作的相关命令： KEYS pattern 查找所有符合给定模式( pattern)的 key EXISTS key 检查给定 key 是否存在 TYPE key 返回 key 所储存的值的类型 TTL key 返回给定 key 的剩余生存时间(TTL, time to live)，以秒为单位 DEL key 该命令用于在 key 存在是删除 key 在Java中操作Redis介绍前面我们讲解了Redis的常用命令，这些命令是我们操作Redis的基础，那么我们在java程序中应该如何操作Redis呢？这就需要使用Redis的Java客户端，就如同我们使用JDBC操作MySQL数据库一样。 Redis 的 Java 客户端很多，官方推荐的有三种： Jedis Lettuce Redisson Spring 对 Redis 客户端进行了整合，提供了 Spring Data Redis，在Spring Boot项目中还提供了对应的Starter，即 spring-boot-starter-data-redis。 JedisJedis 是 Redis 的 Java 版本的客户端实现。 maven坐标： 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 使用 Jedis 操作 Redis 的步骤： 获取连接 执行操作 关闭连接 示例代码： 12345678910111213141516171819202122232425262728293031323334353637package com.itheima.test;import org.junit.Test;import redis.clients.jedis.Jedis;import java.util.Set;/** * 使用Jedis操作Redis */public class JedisTest { @Test public void testRedis(){ //1 获取连接 Jedis jedis = new Jedis(\"localhost\",6379); //2 执行具体的操作 jedis.set(\"username\",\"xiaoming\"); String value = jedis.get(\"username\"); System.out.println(value); //jedis.del(\"username\"); jedis.hset(\"myhash\",\"addr\",\"bj\"); String hValue = jedis.hget(\"myhash\", \"addr\"); System.out.println(hValue); Set&lt;String&gt; keys = jedis.keys(\"*\"); for (String key : keys) { System.out.println(key); } //3 关闭连接 jedis.close(); }} Spring Data Redis介绍Spring Data Redis 是 Spring 的一部分，提供了在 Spring 应用中通过简单的配置就可以访问 Redis 服务，对 Redis 底层开发包进行了高度封装。在 Spring 项目中，可以使用Spring Data Redis来简化 Redis 操作。 网址：https://spring.io/projects/spring-data-redis maven坐标： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.4.8&lt;/version&gt;&lt;/dependency&gt; Spring Boot提供了对应的Starter，maven坐标： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Spring Data Redis中提供了一个高度封装的类：RedisTemplate，针对 Jedis 客户端中大量api进行了归类封装,将同一类型操作封装为operation接口，具体分类如下： ValueOperations：简单K-V操作 SetOperations：set类型数据操作 ZSetOperations：zset类型数据操作 HashOperations：针对hash类型的数据操作 ListOperations：针对list类型的数据操作 使用方式环境搭建第一步：创建maven项目springdataredis_demo，配置pom.xml文件 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springdataredis_demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 第二步：编写启动类 12345678910111213package com.itheima;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class App { public static void main(String[] args) { SpringApplication.run(App.class,args); }} 第三步：配置application.yml 12345678910111213141516spring: application: name: springdataredis_demo #Redis相关配置 redis: host: localhost port: 6379 #password: 123456 database: 0 #操作的是0号数据库 jedis: #Redis连接池配置 pool: max-active: 8 #最大连接数 max-wait: 1ms #连接池最大阻塞等待时间 max-idle: 4 #连接池中的最大空闲连接 min-idle: 0 #连接池中的最小空闲连接 解释说明： spring.redis.database：指定使用Redis的哪个数据库，Redis服务启动后默认有16个数据库，编号分别是从0到15。 可以通过修改Redis配置文件来指定数据库的数量。 第四步：提供配置类 123456789101112131415161718192021222324252627282930package com.itheima.config;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * Redis配置类 */@Configurationpublic class RedisConfig extends CachingConfigurerSupport { @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); //默认的Key序列化器为：JdkSerializationRedisSerializer redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; }} 解释说明： 当前配置类不是必须的，因为 Spring Boot 框架会自动装配 RedisTemplate 对象，但是默认的key序列化器为JdkSerializationRedisSerializer，导致我们存到Redis中后的数据和原始数据有差别 第五步：提供测试类 123456789101112131415package com.itheima.test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@SpringBootTest@RunWith(SpringRunner.class)public class SpringDataRedisTest { @Autowired private RedisTemplate redisTemplate; } 操作字符串类型数据12345678910111213141516171819/** * 操作String类型数据*/@Testpublic void testString(){ //存值 redisTemplate.opsForValue().set(\"city123\",\"beijing\"); //取值 String value = (String) redisTemplate.opsForValue().get(\"city123\"); System.out.println(value); //存值，同时设置过期时间 redisTemplate.opsForValue().set(\"key1\",\"value1\",10l, TimeUnit.SECONDS); //存值，如果存在则不执行任何操作 Boolean aBoolean = redisTemplate.opsForValue().setIfAbsent(\"city1234\", \"nanjing\"); System.out.println(aBoolean);} 操作哈希类型数据12345678910111213141516171819202122232425262728/** * 操作Hash类型数据*/@Testpublic void testHash(){ HashOperations hashOperations = redisTemplate.opsForHash(); //存值 hashOperations.put(\"002\",\"name\",\"xiaoming\"); hashOperations.put(\"002\",\"age\",\"20\"); hashOperations.put(\"002\",\"address\",\"bj\"); //取值 String age = (String) hashOperations.get(\"002\", \"age\"); System.out.println(age); //获得hash结构中的所有字段 Set keys = hashOperations.keys(\"002\"); for (Object key : keys) { System.out.println(key); } //获得hash结构中的所有值 List values = hashOperations.values(\"002\"); for (Object value : values) { System.out.println(value); }} 操作列表类型数据1234567891011121314151617181920212223242526/** * 操作List类型的数据*/@Testpublic void testList(){ ListOperations listOperations = redisTemplate.opsForList(); //存值 listOperations.leftPush(\"mylist\",\"a\"); listOperations.leftPushAll(\"mylist\",\"b\",\"c\",\"d\"); //取值 List&lt;String&gt; mylist = listOperations.range(\"mylist\", 0, -1); for (String value : mylist) { System.out.println(value); } //获得列表长度 llen Long size = listOperations.size(\"mylist\"); int lSize = size.intValue(); for (int i = 0; i &lt; lSize; i++) { //出队列 String element = (String) listOperations.rightPop(\"mylist\"); System.out.println(element); }} 操作集合类型数据1234567891011121314151617181920212223242526/** * 操作Set类型的数据*/@Testpublic void testSet(){ SetOperations setOperations = redisTemplate.opsForSet(); //存值 setOperations.add(\"myset\",\"a\",\"b\",\"c\",\"a\"); //取值 Set&lt;String&gt; myset = setOperations.members(\"myset\"); for (String o : myset) { System.out.println(o); } //删除成员 setOperations.remove(\"myset\",\"a\",\"b\"); //取值 myset = setOperations.members(\"myset\"); for (String o : myset) { System.out.println(o); }} 操作有序集合类型数据12345678910111213141516171819202122232425262728293031323334353637/** * 操作ZSet类型的数据*/@Testpublic void testZset(){ ZSetOperations zSetOperations = redisTemplate.opsForZSet(); //存值 zSetOperations.add(\"myZset\",\"a\",10.0); zSetOperations.add(\"myZset\",\"b\",11.0); zSetOperations.add(\"myZset\",\"c\",12.0); zSetOperations.add(\"myZset\",\"a\",13.0); //取值 Set&lt;String&gt; myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); } //修改分数 zSetOperations.incrementScore(\"myZset\",\"b\",20.0); //取值 myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); } //删除成员 zSetOperations.remove(\"myZset\",\"a\",\"b\"); //取值 myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); }} 通用操作1234567891011121314151617181920212223/** * 通用操作，针对不同的数据类型都可以操作*/@Testpublic void testCommon(){ //获取Redis中所有的key Set&lt;String&gt; keys = redisTemplate.keys(\"*\"); for (String key : keys) { System.out.println(key); } //判断某个key是否存在 Boolean itcast = redisTemplate.hasKey(\"itcast\"); System.out.println(itcast); //删除指定key redisTemplate.delete(\"myZset\"); //获取指定key对应的value的数据类型 DataType dataType = redisTemplate.type(\"myset\"); System.out.println(dataType.name());}","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"docker基础使用","slug":"笔记/技术/Docker实用篇","date":"2022-07-31T22:07:08.000Z","updated":"2022-11-28T10:09:44.886Z","comments":true,"path":"2022/08/01/笔记/技术/Docker实用篇/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/","excerpt":"","text":"Docker实用篇学习目标初识Docker什么是Docker微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。 分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。 在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题 应用部署的环境问题大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题： 依赖关系复杂，容易出现兼容性问题 开发、测试、生产环境有差异 例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。 Docker解决依赖兼容问题而Docker确巧妙的解决了这些问题，Docker是如何实现的呢？ Docker为了解决依赖的兼容问题的，采用了两个手段： 将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包 将每个应用放到一个隔离容器去运行，避免互相干扰 这样打包好的应用包中，既包含应用本身，也保护应用所需要的Libs、Deps，无需再操作系统上安装这些，自然就不存在不同应用之间的兼容问题了。 虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？ Docker解决操作系统环境差异要解决不同操作系统环境差异问题，必须先了解操作系统结构。以一个Ubuntu操作系统为例，结构如下： 结构包括： 计算机硬件：例如CPU、内存、磁盘等 系统内核：所有Linux发行版的内核都是Linux，例如CentOS、Ubuntu、Fedora等。内核可以与计算机硬件交互，对外提供内核指令，用于操作计算机硬件。 系统应用：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。 应用于计算机交互的流程如下： 1）应用调用操作系统应用（函数库），实现各种功能 2）系统函数库是对内核指令集的封装，会调用内核指令 3）内核指令操作计算机硬件 Ubuntu和CentOSpringBoot都是基于Linux内核，无非是系统应用不同，提供的函数库有差异： 此时，如果将一个Ubuntu版本的MySQL应用安装到CentOS系统，MySQL在调用Ubuntu函数库时，会发现找不到或者不匹配，就会报错了： Docker如何解决不同系统环境的问题？ Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包 Docker运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的Linux内核来运行 如图： 小结Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？ Docker允许开发中将应用、依赖、函数库、配置一起打包，形成可移植镜像 Docker应用运行在容器中，使用沙箱机制，相互隔离 Docker如何解决开发、测试、生产环境有差异的问题？ Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行 Docker是一个快速交付应用、运行应用的技术，具备下列优势： 可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统 运行时利用沙箱机制形成隔离容器，各个应用互不干扰 启动、移除都可以通过一行命令完成，方便快捷 Docker和虚拟机的区别Docker可以让一个应用在任何操作系统中非常方便的运行。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。 两者有什么差异呢？ 虚拟机（virtual machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。 Docker仅仅是封装函数库，并没有模拟完整的操作系统，如图： 对比来看： 小结： Docker和虚拟机的差异： docker是一个系统进程；虚拟机是在操作系统中的操作系统 docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般 Docker架构镜像和容器Docker中有几个重要的概念： 镜像（Image）：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。 容器（Container）：镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器进程做隔离，对外不可见。 一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的文件。只有运行时，才会加载到内存，形成进程。 而镜像，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。 容器呢，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。因此一个镜像可以启动多次，形成多个容器进程。 例如你下载了一个QQ，如果我们将QQ在磁盘上的运行文件及其运行的操作系统依赖打包，形成QQ镜像。然后你可以启动多次，双开、甚至三开QQ，跟多个妹子聊天。 DockerHub开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。 DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。 国内也有类似于DockerHub 的公开服务，比如 网易云镜像服务、阿里云镜像库等。 我们一方面可以将自己的镜像共享到DockerHub，另一方面也可以从DockerHub拉取镜像： Docker架构我们要使用Docker来操作镜像、容器，就必须要安装Docker。 Docker是一个CS架构的程序，由两部分组成： 服务端(server)：Docker守护进程，负责处理Docker指令，管理镜像、容器等 客户端(client)：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。 如图： 小结镜像： 将应用程序及其依赖、环境、配置打包在一起 容器： 镜像运行起来就是容器，一个镜像可以运行多个容器 Docker结构： 服务端：接收命令或远程请求，操作镜像或容器 客户端：发送命令或者请求到Docker服务端 DockerHub： 一个镜像托管的服务器，类似的还有阿里云镜像服务，统称为DockerRegistry Docker的基本操作镜像操作镜像名称首先来看下镜像的名称组成： 镜名称一般分两部分组成：[repository]:[tag]。 在没有指定tag时，默认是latest，代表最新版本的镜像 如图： 这里的mysql就是repository，5.7就是tag，合一起就是镜像名称，代表5.7版本的MySQL镜像。 镜像命令常见的镜像操作命令如图： 案例1-拉取、查看镜像需求：从DockerHub中拉取一个nginx镜像并查看 1）首先去镜像仓库搜索nginx镜像，比如DockerHub: 2）根据查看到的镜像名称，拉取自己需要的镜像，通过命令：docker pull nginx 3）通过命令：docker images 查看拉取到的镜像 案例2-保存、导入镜像需求：利用docker save将nginx镜像导出磁盘，然后再通过load加载回来 1）利用docker xx –help命令查看docker save和docker load的语法 例如，查看save命令用法，可以输入命令： 1docker save --help 结果： 命令格式： 1docker save -o [保存的目标文件名称] [镜像名称] 2）使用docker save导出镜像到磁盘 运行命令： 1docker save -o nginx.tar nginx:latest 结果如图： 3）使用docker load加载镜像 先删除本地的nginx镜像： 1docker rmi nginx:latest 然后运行命令，加载本地文件： 1docker load -i nginx.tar 结果： 容器操作容器相关命令容器操作的命令如图： 容器保护三个状态： 运行：进程正常运行 暂停：进程暂停，CPU不再运行，并不释放内存 停止：进程终止，回收进程占用的内存、CPU等资源 其中： docker run：创建并运行一个容器，处于运行状态 docker pause：让一个运行的容器暂停 docker unpause：让一个容器从暂停状态恢复运行 docker stop：停止一个运行的容器 docker start：让一个停止的容器再次运行 docker rm：删除一个容器 案例-创建并运行一个容器创建并运行nginx容器的命令： 1docker run --name containerName -p 80:80 -d nginx 命令解读： docker run ：创建并运行一个容器 –name : 给容器起一个名字，比如叫做mn -p ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口 -d：后台运行容器 nginx：镜像名称，例如nginx 这里的-p参数，是将容器端口映射到宿主机端口。 默认情况下，容器是隔离环境，我们直接访问宿主机的80端口，肯定访问不到容器中的nginx。 现在，将容器的80与宿主机的80关联起来，当我们访问宿主机的80端口时，就会被映射到容器的80，这样就能访问到nginx了： 案例-进入容器，修改文件需求：进入Nginx容器，修改HTML文件内容，添加“传智教育欢迎您” 提示：进入容器要用到docker exec命令。 步骤： 1）进入容器。进入我们刚刚创建的nginx容器的命令为： 1docker exec -it mn bash 命令解读： docker exec ：进入容器内部，执行一个命令 -it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互 mn ：要进入的容器的名称 bash：进入容器后执行的命令，bash是一个linux终端交互命令 2）进入nginx的HTML所在目录 /usr/share/nginx/html 容器内部会模拟一个独立的Linux文件系统，看起来如同一个linux服务器一样： nginx的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的html文件。 查看DockerHub网站中的nginx页面，可以知道nginx的html目录位置在/usr/share/nginx/html 我们执行命令，进入该目录： 1cd /usr/share/nginx/html 查看目录下文件： 3）修改index.html的内容 容器内没有vi命令，无法直接修改，我们用下面的命令来修改： 1sed -i -e 's#Welcome to nginx#传智教育欢迎您#g' -e 's#&lt;head&gt;#&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;#g' index.html 在浏览器访问自己的虚拟机地址，例如我的是：http://192.168.150.101，即可看到结果： 小结docker run命令的常见参数有哪些？ –name：指定容器名称 -p：指定端口映射 -d：让容器后台运行 查看容器日志的命令： docker logs 添加 -f 参数可以持续查看日志 查看容器状态： docker ps docker ps -a 查看所有容器，包括已经停止的 数据卷（容器数据管理）在之前的nginx案例中，修改nginx的html页面时，需要进入nginx内部。并且因为没有编辑器，修改文件也很麻烦。 这就是因为容器与数据（容器内文件）耦合带来的后果。 要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。 什么是数据卷数据卷（volume）是一个虚拟目录，指向宿主机文件系统中的某个目录。 一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。 这样，我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了 数据集操作命令数据卷操作的基本语法如下： 1docker volume [COMMAND] docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作： create 创建一个volume inspect 显示一个或多个volume的信息 ls 列出所有的volume prune 删除未使用的volume rm 删除一个或多个指定的volume 创建和查看数据卷需求：创建一个数据卷，并查看数据卷在宿主机的目录位置 ① 创建数据卷 1docker volume create html ② 查看所有数据 1docker volume ls 结果： ③ 查看数据卷详细信息卷 1docker volume inspect html 结果： 可以看到，我们创建的html这个数据卷关联的宿主机目录为/var/lib/docker/volumes/html/_data目录。 小结： 数据卷的作用： 将容器与数据分离，解耦合，方便操作容器内数据，保证数据安全 数据卷操作： docker volume create：创建数据卷 docker volume ls：查看所有数据卷 docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置 docker volume rm：删除指定数据卷 docker volume prune：删除所有未使用的数据卷 挂载数据卷我们在创建容器时，可以通过 -v 参数来挂载一个数据卷到某个容器内目录，命令格式如下： 12345docker run \\ --name mn \\ -v html:/root/html \\ -p 82:80 nginx \\ 这里的-v就是挂载数据卷的命令： -v html:/root/htm ：把html数据卷挂载到容器内的/root/html这个目录中 案例-给nginx挂载数据卷需求：创建一个nginx容器，修改容器内的html目录内的index.html内容 分析：上个案例中，我们进入nginx容器内部，已经知道nginx的html目录所在位置/usr/share/nginx/html ，我们需要把这个目录挂载到html这个数据卷上，方便操作其中的内容。 提示：运行容器时使用 -v 参数挂载数据卷 步骤： ① 创建容器并挂载数据卷到容器内的HTML目录 1docker run --name mn -v html:/usr/share/nginx/html -p 80:80 -d nginx ② 进入html数据卷所在位置，并修改HTML内容 123456# 查看html数据卷的位置docker volume inspect html# 进入该目录cd /var/lib/docker/volumes/html/_data# 修改文件vi index.html 案例-给MySQL挂载本地目录容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下： 带数据卷模式：宿主机目录 –&gt; 数据卷 —&gt; 容器内目录 直接挂载模式：宿主机目录 —&gt; 容器内目录 如图： 语法： 目录挂载与数据卷挂载的语法是类似的： -v [宿主机目录]:[容器内目录] -v [宿主机文件]:[容器内文件] 需求：创建并运行一个MySQL容器，将宿主机目录直接挂载到容器 实现思路如下： 1）在将课前资料中的mysql.tar文件上传到虚拟机，通过load命令加载为镜像 2）创建目录/tmp/mysql/data 3）创建目录/tmp/mysql/conf，将课前资料提供的hmy.cnf文件上传到/tmp/mysql/conf 4）去DockerHub查阅资料，创建并运行MySQL容器，要求： ① 挂载/tmp/mysql/data到mysql容器内数据存储目录 ② 挂载/tmp/mysql/conf/hmy.cnf到mysql容器的配置文件 ③ 设置MySQL密码 小结docker run的命令中通过 -v 参数挂载文件或目录到容器中： -v volume名称:容器内目录 -v 宿主机文件:容器内文 -v 宿主机目录:容器内目录 数据卷挂载与目录直接挂载的 数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找 目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看 Dockerfile自定义镜像常见的镜像在DockerHub就能找到，但是我们自己写的项目就必须自己构建镜像了。 而要自定义镜像，就必须先了解镜像的结构才行。 镜像结构镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。 我们以MySQL为例，来看看镜像的组成结构： 简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。 我们要构建镜像，其实就是实现上述打包的过程。 Dockerfile语法构建自定义的镜像时，并不需要一个个文件去拷贝，打包。 我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。 而描述上述信息的文件就是Dockerfile文件。 Dockerfile就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。 更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder 构建Java项目基于Ubuntu构建Java项目需求：基于Ubuntu镜像构建一个新镜像，运行一个java项目 步骤1：新建一个空文件夹docker-demo 步骤2：拷贝课前资料中的docker-demo.jar文件到docker-demo这个目录 步骤3：拷贝课前资料中的jdk8.tar.gz文件到docker-demo这个目录 步骤4：拷贝课前资料提供的Dockerfile到docker-demo这个目录 其中的内容如下： 12345678910111213141516171819202122# 指定基础镜像FROM ubuntu:16.04# 配置环境变量，JDK的安装目录ENV JAVA_DIR=/usr/local# 拷贝jdk和java项目的包COPY ./jdk8.tar.gz $JAVA_DIR/COPY ./docker-demo.jar /tmp/app.jar# 安装JDKRUN cd $JAVA_DIR \\ &amp;&amp; tar -xf ./jdk8.tar.gz \\ &amp;&amp; mv ./jdk1.8.0_144 ./java8# 配置环境变量ENV JAVA_HOME=$JAVA_DIR/java8ENV PATH=$PATH:$JAVA_HOME/bin# 暴露端口EXPOSE 8090# 入口，java项目的启动命令ENTRYPOINT java -jar /tmp/app.jar 步骤5：进入docker-demo 将准备好的docker-demo上传到虚拟机任意目录，然后进入docker-demo目录下 步骤6：运行命令： 1docker build -t javaweb:1.0 . 最后访问 http://192.168.150.101:8090/hello/count，其中的ip改成你的虚拟机ip 基于java8构建Java项目虽然我们可以基于Ubuntu基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。 例如，构建java项目的镜像，可以在已经准备了JDK的基础镜像基础上构建。 需求：基于java:8-alpine镜像，将一个Java项目构建为镜像 实现思路如下： ① 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile ② 拷贝课前资料提供的docker-demo.jar到这个目录中 ③ 编写Dockerfile文件： a ）基于java:8-alpine作为基础镜像 b ）将app.jar拷贝到镜像中 c ）暴露端口 d ）编写入口ENTRYPOINT 内容如下： 1234FROM java:8-alpineCOPY ./app.jar /tmp/app.jarEXPOSE 8090ENTRYPOINT java -jar /tmp/app.jar ④ 使用docker build命令构建镜像 ⑤ 使用docker run创建容器并运行 小结小结： Dockerfile的本质是一个文件，通过指令描述镜像的构建过程 Dockerfile的第一行必须是FROM，从一个基础镜像来构建 基础镜像可以是基本操作系统，如Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine Docker-ComposeDocker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！ 初识DockerComposeCompose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下： 1234567891011121314version:&nbsp;\"3.8\" services:&nbsp;&nbsp;mysql:&nbsp;&nbsp;&nbsp;&nbsp;image:&nbsp;mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 &nbsp;&nbsp;&nbsp;&nbsp;volumes:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;\"/tmp/mysql/data:/var/lib/mysql\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;\"/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf\"&nbsp;&nbsp;web:&nbsp;&nbsp;&nbsp;&nbsp;build:&nbsp;.&nbsp;&nbsp;&nbsp;&nbsp;ports:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- \"8090:8090\" 上面的Compose文件就描述一个项目，其中包含两个容器： mysql：一个基于mysql:5.7.25镜像构建的容器，并且挂载了两个目录 web：一个基于docker build临时构建的镜像容器，映射端口时8090 DockerCompose的详细语法参考官网：https://docs.docker.com/compose/compose-file/ 其实DockerCompose文件可以看做是将多个docker run命令写到一个文件，只是语法稍有差异。 安装DockerComposecompose文件查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录： 内容如下： 123456789101112131415161718192021222324version: \"3.2\"services: nacos: image: nacos/nacos-server environment: MODE: standalone ports: - \"8848:8848\" mysql: image: mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 volumes: - \"$PWD/mysql/data:/var/lib/mysql\" - \"$PWD/mysql/conf:/etc/mysql/conf.d/\" userservice: build: ./user-service orderservice: build: ./order-service gateway: build: ./gateway ports: - \"10010:10010\" 可以看到，其中包含5个service服务： nacos：作为注册中心和配置中心 image: nacos/nacos-server： 基于nacos/nacos-server镜像构建 environment：环境变量 MODE: standalone：单点模式启动 ports：端口映射，这里暴露了8848端口 mysql：数据库 image: mysql:5.7.25：镜像版本是mysql:5.7.25 environment：环境变量 MYSQL_ROOT_PASSWORD: 123：设置数据库root账户的密码为123 volumes：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据 userservice、orderservice、gateway：都是基于Dockerfile临时构建的 查看mysql目录，可以看到其中已经准备好了cloud_order、cloud_user表： 查看微服务目录，可以看到都包含Dockerfile文件： 内容如下： 123FROM java:8-alpineCOPY ./app.jar /tmp/app.jarENTRYPOINT java -jar /tmp/app.jar 修改微服务配置因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。 如下所示： 1234567891011spring: datasource: url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false username: root password: 123 driver-class-name: com.mysql.jdbc.Driver application: name: orderservice cloud: nacos: server-addr: nacos:8848 # nacos服务地址 打包接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。 可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改： 12345678910&lt;build&gt; &lt;!-- 服务打包的最终名称 --&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 打包后： 拷贝jar包到部署目录编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，别搞错了。 user-service： order-service： gateway： 部署最后，我们需要将文件整个cloud-demo文件夹上传到虚拟机中，理由DockerCompose部署。 上传到任意目录： 部署： 进入cloud-demo目录，然后运行下面的命令： 1docker-compose up -d Docker镜像仓库推送、拉取镜像推送镜像到私有镜像服务必须先tag，步骤如下： ① 重新tag本地镜像，名称前缀为私有仓库的地址：192.168.150.101:8080/ 1docker tag nginx:latest 192.168.147.129:8080/nginx:1.0 ② 推送镜像 1docker push 192.168.147.129:8080/nginx:1.0 ③ 拉取镜像 1docker pull 192.168.147.129:8080/nginx:1.0","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"RabbitMQ部署指南","slug":"笔记/安装部署/RabbitMQ部署指南","date":"2022-07-31T22:06:09.000Z","updated":"2022-11-28T10:14:21.468Z","comments":true,"path":"2022/08/01/笔记/安装部署/RabbitMQ部署指南/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/RabbitMQ%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/","excerpt":"","text":"RabbitMQ部署指南单机部署我们在Centos7虚拟机中使用Docker来安装。 下载镜像方式一：在线拉取 1docker pull rabbitmq:3.8-management 方式二：从本地加载 在课前资料已经提供了镜像包： 上传到虚拟机中后，使用命令加载镜像即可： 1docker load -i mq.tar 安装MQ执行下面的命令来运行MQ容器： 12345678910docker run \\ -e RABBITMQ_DEFAULT_USER=admin \\ -e RABBITMQ_DEFAULT_PASS=111111 \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3.8-management","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"RabbitMQ入门","slug":"笔记/技术/RabbitMQ","date":"2022-07-31T22:06:09.000Z","updated":"2022-11-28T10:11:27.348Z","comments":true,"path":"2022/08/01/笔记/技术/RabbitMQ/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/RabbitMQ/","excerpt":"","text":"RabbitMQ初识MQ同步和异步通讯微服务间通讯有同步和异步两种方式： 同步通讯：就像打电话，需要实时响应。 异步通讯：就像发邮件，不需要马上回复。 两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。 同步通讯我们之前学习的Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题： 总结： 同步调用的优点： 时效性较强，可以立即得到结果 同步调用的问题： 耦合度高 性能和吞吐能力下降 有额外的资源消耗 有级联失败问题 异步通讯异步调用则可以避免上述问题： 我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。 在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。 订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。 为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。 Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。 好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。 技术对比：MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。 比较常见的MQ实现： ActiveMQ RabbitMQ RocketMQ Kafka 几种常见MQ的对比： RabbitMQ ActiveMQ RocketMQ Kafka 公司/社区 Rabbit Apache 阿里 Apache 开发语言 Erlang Java Java Scala&amp;Java 协议支持 AMQP，XMPP，SMTP，STOMP OpenWire,STOMP，REST,XMPP,AMQP 自定义协议 自定义协议 可用性 高 一般 高 高 单机吞吐量 一般 差 高 非常高 消息延迟 微秒级 毫秒级 毫秒级 毫秒以内 消息可靠性 高 一般 高 一般 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka 追求消息低延迟：RabbitMQ、Kafka 快速入门安装RabbitMQ安装RabbitMQ，参考课前资料： MQ的基本结构： RabbitMQ中的一些角色： publisher：生产者 consumer：消费者 exchange个：交换机，负责消息路由 queue：队列，存储消息 virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离 RabbitMQ消息模型RabbitMQ官方提供了5个不同的Demo示例，对应了不同的消息模型： 导入Demo工程课前资料提供了一个Demo工程，mq-demo: 导入后可以看到结构如下： 包括三部分： mq-demo：父工程，管理项目依赖 publisher：消息的发送者 consumer：消息的消费者 入门案例简单队列模式的模型图： 官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色： publisher：消息发布者，将消息发送到队列queue queue：消息队列，负责接受并缓存消息 consumer：订阅队列，处理队列中的消息 publisher实现思路： 建立连接 创建Channel 声明队列 发送消息 关闭连接和channel 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142package cn.itcast.mq.helloworld;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import org.junit.Test;import java.io.IOException;import java.util.concurrent.TimeoutException;public class PublisherTest { @Test public void testSendMessage() throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.150.101\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"itcast\"); factory.setPassword(\"123321\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.发送消息 String message = \"hello, rabbitmq!\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); System.out.println(\"发送消息成功：【\" + message + \"】\"); // 5.关闭通道和连接 channel.close(); connection.close(); }} consumer实现代码思路： 建立连接 创建Channel 声明队列 订阅消息 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041package cn.itcast.mq.helloworld;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class ConsumerTest { public static void main(String[] args) throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.150.101\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"itcast\"); factory.setPassword(\"123321\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.订阅消息 channel.basicConsume(queueName, true, new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // 5.处理消息 String message = new String(body); System.out.println(\"接收到消息：【\" + message + \"】\"); } }); System.out.println(\"等待接收消息。。。。\"); }} 总结基本消息队列的消息发送流程： 建立connection 创建channel 利用channel声明队列 利用channel向队列发送消息 基本消息队列的消息接收流程： 建立connection 创建channel 利用channel声明队列 定义consumer的消费行为handleDelivery() 利用channel将消费者与队列绑定 SpringAMQPSpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。 SpringAmqp的官方地址：https://spring.io/projects/spring-amqp SpringAMQP提供了三个功能： 自动声明队列、交换机及其绑定关系 基于注解的监听器模式，异步接收消息 封装了RabbitTemplate工具，用于发送消息 Basic Queue 简单队列模型在父工程mq-demo中引入依赖 12345&lt;!--AMQP依赖，包含RabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 消息发送首先配置MQ地址，在publisher服务的application.yml中添加配置： 1234567spring: rabbitmq: host: 192.168.147.129 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: admin # 用户名 password: 111111 # 密码 然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送： 1234567891011121314151617181920212223242526package cn.itcast.mq.spring;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringAmqpTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSimpleQueue() { // 队列名称 String queueName = \"simple.queue\"; // 消息 String message = \"hello, spring amqp!\"; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); }} 消息接收首先配置MQ地址，在consumer服务的application.yml中添加配置： 1234567spring: rabbitmq: host: 192.168.147.129 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: admin # 用户名 password: 111111 # 密码 然后在consumer服务的cn.itcast.mq.listener包中新建一个类SpringRabbitListener，代码如下： 12345678910111213package cn.itcast.mq.listener;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;@Componentpublic class SpringRabbitListener { @RabbitListener(queues = \"simple.queue\") public void listenSimpleQueueMessage(String msg) throws InterruptedException { System.out.println(\"spring 消费者接收到消息：【\" + msg + \"】\"); }} 测试启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息 WorkQueueWork queues，也被称为（Task queues），任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息。 当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。 此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。 消息发送这次我们循环发送，模拟大量消息堆积现象。 在publisher服务中的SpringAmqpTest类中添加一个测试方法： 12345678910111213141516/** * workQueue * 向队列中不停发送消息，模拟消息堆积。 */@Testpublic void testWorkQueue() throws InterruptedException { // 队列名称 String queueName = \"simple.queue\"; // 消息 String message = \"hello, message_\"; for (int i = 0; i &lt; 50; i++) { // 发送消息 rabbitTemplate.convertAndSend(queueName, message + i); Thread.sleep(20); }} 消息接收要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法： 1234567891011@RabbitListener(queues = \"simple.queue\")public void listenWorkQueue1(String msg) throws InterruptedException { System.out.println(\"消费者1接收到消息：【\" + msg + \"】\" + LocalTime.now()); Thread.sleep(20);}@RabbitListener(queues = \"simple.queue\")public void listenWorkQueue2(String msg) throws InterruptedException { System.err.println(\"消费者2........接收到消息：【\" + msg + \"】\" + LocalTime.now()); Thread.sleep(200);} 注意到这个消费者sleep了1000秒，模拟任务耗时。 测试启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。 可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。 也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。 能者多劳在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置： 12345spring: rabbitmq: listener: simple: prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息 总结Work模型的使用： 多个消费者绑定到一个队列，同一条消息只会被一个消费者处理 通过设置prefetch来控制消费者预取的消息数量 发布/订阅发布订阅的模型如图： 可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化： Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Consumer：消费者，与以前一样，订阅队列，没有变化 Queue：消息队列也与以前一样，接收消息、缓存消息。 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！ FanoutFanout，英文翻译是扇出，我觉得在MQ中叫广播更合适。 在广播模式下，消息发送流程是这样的： 1） 可以有多个队列 2） 每个队列都要绑定到Exchange（交换机） 3） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定 4） 交换机把消息发送给绑定过的所有队列 5） 订阅队列的消费者都能拿到消息 我们的计划是这样的： 创建一个交换机 itcast.fanout，类型是Fanout 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout 声明队列和交换机Spring提供了一个接口Exchange，来表示所有不同类型的交换机： 在consumer中创建一个类，声明队列和交换机： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package cn.itcast.mq.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FanoutConfig { /** * 声明交换机 * @return Fanout类型交换机 */ @Bean public FanoutExchange fanoutExchange(){ return new FanoutExchange(\"itcast.fanout\"); } /** * 第1个队列 */ @Bean public Queue fanoutQueue1(){ return new Queue(\"fanout.queue1\"); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } /** * 第2个队列 */ @Bean public Queue fanoutQueue2(){ return new Queue(\"fanout.queue2\"); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); }} 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 12345678@Testpublic void testFanoutExchange() { // 队列名称 String exchangeName = \"itcast.fanout\"; // 消息 String message = \"hello, everyone!\"; rabbitTemplate.convertAndSend(exchangeName, \"\", message);} 消息接收在consumer服务的SpringRabbitListener中添加两个方法，作为消费者： 123456789@RabbitListener(queues = \"fanout.queue1\")public void listenFanoutQueue1(String msg) { System.out.println(\"消费者1接收到Fanout消息：【\" + msg + \"】\");}@RabbitListener(queues = \"fanout.queue2\")public void listenFanoutQueue2(String msg) { System.out.println(\"消费者2接收到Fanout消息：【\" + msg + \"】\");} 总结交换机的作用是什么？ 接收publisher发送的消息 将消息按照规则路由到与之绑定的队列 不能缓存消息，路由失败，消息丢失 FanoutExchange的会将消息路由到每个绑定的队列 声明队列、交换机、绑定关系的Bean是什么？ Queue FanoutExchange Binding Direct在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。 在Direct模型下： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 案例需求如下： 利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2 在publisher中编写测试方法，向itcast. direct发送消息 基于注解声明队列和交换机基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。 在consumer的SpringRabbitListener中添加两个消费者，同时基于注解来声明队列和交换机： 1234567891011121314151617@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"direct.queue1\"), exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT), key = {\"red\", \"blue\"}))public void listenDirectQueue1(String msg){ System.out.println(\"消费者接收到direct.queue1的消息：【\" + msg + \"】\");}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"direct.queue2\"), exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT), key = {\"red\", \"yellow\"}))public void listenDirectQueue2(String msg){ System.out.println(\"消费者接收到direct.queue2的消息：【\" + msg + \"】\");} 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 123456789@Testpublic void testSendDirectExchange() { // 交换机名称 String exchangeName = \"itcast.direct\"; // 消息 String message = \"红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！\"; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \"red\", message);} 总结描述下Direct交换机与Fanout交换机的差异？ Fanout交换机将消息路由给每一个与之绑定的队列 Direct交换机根据RoutingKey判断路由给哪个队列 如果多个队列具有相同的RoutingKey，则与Fanout功能类似 基于@RabbitListener注解声明队列和交换机有哪些常见注解？ @Queue @Exchange Topic说明Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： item.#：能够匹配item.spu.insert 或者 item.spu item.*：只能匹配item.spu ​ 图示： 解释： Queue1：绑定的是china.# ，因此凡是以 china.开头的routing key 都会被匹配到。包括china.news和china.weather Queue2：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配。包括china.news和japan.news 案例需求： 实现思路如下： 并利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2 在publisher中编写测试方法，向itcast. topic发送消息 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 123456789101112/** * topicExchange */@Testpublic void testSendTopicExchange() { // 交换机名称 String exchangeName = \"itcast.topic\"; // 消息 String message = \"喜报！孙悟空大战哥斯拉，胜!\"; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \"china.news\", message);} 消息接收在consumer服务的SpringRabbitListener中添加方法： 1234567891011121314151617@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"topic.queue1\"), exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC), key = \"china.#\"))public void listenTopicQueue1(String msg){ System.out.println(\"消费者接收到topic.queue1的消息：【\" + msg + \"】\");}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"topic.queue2\"), exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC), key = \"#.news\"))public void listenTopicQueue2(String msg){ System.out.println(\"消费者接收到topic.queue2的消息：【\" + msg + \"】\");} 总结描述下Direct交换机与Topic交换机的差异？ Topic交换机接收的消息RoutingKey必须是多个单词，以 **.** 分割 Topic交换机与队列绑定时的bindingKey可以指定通配符 #：代表0个或多个词 *：代表1个词 消息转换器之前说过，Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。 只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题： 数据体积过大 有安全漏洞 可读性差 我们来测试一下。 测试默认转换器我们修改消息发送的代码，发送一个Map对象： 123456789@Testpublic void testSendMap() throws InterruptedException { // 准备消息 Map&lt;String,Object&gt; msg = new HashMap&lt;&gt;(); msg.put(\"name\", \"Jack\"); msg.put(\"age\", 21); // 发送消息 rabbitTemplate.convertAndSend(\"simple.queue\",\"\", msg);} 停止consumer服务 发送消息后查看控制台： 配置JSON转换器显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。 在publisher和consumer两个服务中都引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt; &lt;version&gt;2.9.10&lt;/version&gt;&lt;/dependency&gt; 配置消息转换器。 在启动类中添加一个Bean即可： 1234@Beanpublic MessageConverter jsonMessageConverter(){ return new Jackson2JsonMessageConverter();}","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"Maven私服","slug":"笔记/技术/Maven私服","date":"2022-07-31T22:06:08.000Z","updated":"2022-11-28T10:10:57.660Z","comments":true,"path":"2022/08/01/笔记/技术/Maven私服/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Maven%E7%A7%81%E6%9C%8D/","excerpt":"","text":"私服私服介绍问题导入这里的私服和平时我们听的国服、体验服、欧服等等有什么区别？ 介绍 团队开发现状分析 私服是一台独立的服务器，用于解决团队内部的资源共享与资源同步问题 Nexus Sonatype公司的一款maven私服产品 下载地址：https://help.sonatype.com/repomanager3/download Nexus安装与启动 启动服务器（命令行启动） nexus.exe /run nexus 访问服务器（默认端口：8081） http://localhost:8081 修改基础配置信息 安装路径下etc目录中nexus-default.properties文件保存有nexus基础配置信息，例如默认访问端口。 修改服务器运行配置信息 安装路径下bin目录中nexus.vmoptions文件保存有nexus服务器启动对应的配置信息，例如默认占用内存空间。 私服资源操作流程分析 私服仓库分类问题导入私服仓库分为哪几种？ 资源上传与下载问题导入往私服上传资源是否需要身份认证？在哪里设置认证信息？ 配置访问私服的权限 私服访问路径 从私服中下载依赖【第一步】在maven的settings.xml中&lt;mirrors&gt;标签中配置，此时就需要注释掉aliyun的配置。 12345&lt;mirror&gt; &lt;id&gt;nexus-heima&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt;&lt;/mirror&gt; 【第二步】在nexus中设置允许匿名下载，如果不允许将不会从私服中下载依赖 如果私服中没有对应的jar，会去中央仓库下载，速度很慢。可以配置让私服去阿里云中下载依赖。 http://maven.aliyun.com/nexus/content/groups/public 上传依赖到私服中【第一步】配置本地仓库访问私服的权限（在maven的settings.xml的servers标签中配置） 123456&lt;server&gt; &lt;!--id任意，多个server的id不重复就行，后面会用到--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt;&lt;!--填写自己nexus设定的登录秘密--&gt;&lt;/server&gt; 【第一步】配置当前项目访问私服上传资源的保存位置（项目的pom.xml文件中配置） 1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;!--如果jar的版本是release版本，那么就上传到这个仓库，根据自己情况修改--&gt; &lt;url&gt;http://localhost:8081/repository/heima-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;!--如果jar的版本是snapshot版本，那么就上传到这个仓库，根据自己情况修改--&gt; &lt;url&gt;http://localhost:8081/repository/heima-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; ==注意：要和maven的settings.xml中server中定义的&lt;id&gt;heima-nexus&lt;/id&gt;对应== 【第三步】发布资源到私服命令 1mvn deploy","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Maven","slug":"Maven","permalink":"http://example.com/tags/Maven/"}]},{"title":"Redis安装说明","slug":"笔记/安装部署/Redis安装说明","date":"2022-07-31T22:06:07.000Z","updated":"2022-11-28T10:14:31.666Z","comments":true,"path":"2022/08/01/笔记/安装部署/Redis安装说明/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Redis%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E/","excerpt":"","text":"Redis安装说明大多数企业都是基于Linux服务器来部署项目，而且Redis官方也没有提供Windows版本的安装包。因此课程中我们会基于Linux系统来安装Redis. 此处选择的Linux版本为CentOS 7. Redis的官方网站地址：https://redis.io/ 1.单机安装Redis安装Redis依赖Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖： 1yum install -y gcc tcl 上传安装包并解压然后将课前资料提供的Redis安装包上传到虚拟机的任意目录： 例如，我放到了/usr/local/src 目录： 解压缩： 1tar -xzf redis-6.2.6.tar.gz 解压后： 进入redis目录： 1cd redis-6.2.6 运行编译命令： 1make &amp;&amp; make install 如果没有出错，应该就安装成功了。 默认的安装路径是在 /usr/local/bin目录下： 该目录以及默认配置到环境变量，因此可以在任意目录下运行这些命令。其中： redis-cli：是redis提供的命令行客户端 redis-server：是redis的服务端启动脚本 redis-sentinel：是redis的哨兵启动脚本 启动redis的启动方式有很多种，例如： 默认启动 指定配置启动 开机自启 默认启动安装完成后，在任意目录输入redis-server命令即可启动Redis： 1redis-server 如图： 这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。 指定配置启动如果要让Redis以后台方式启动，则必须修改Redis配置文件，就在我们之前解压的redis安装包下（/usr/local/src/redis-6.2.6），名字叫redis.conf： 我们先将这个配置文件备份一份： 1cp redis.conf redis.conf.bck 然后修改redis.conf文件中的一些配置： 123456# 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0bind 0.0.0.0# 守护进程，修改为yes后即可后台运行daemonize yes # 密码，设置后访问Redis必须输入密码requirepass 123321 Redis的其它常见配置： 12345678910# 监听的端口port 6379# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录dir .# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15databases 1# 设置redis能够使用的最大内存maxmemory 512mb# 日志文件，默认为空，不记录日志，可以指定日志文件名logfile \"redis.log\" 启动Redis： 1234# 进入redis安装目录 cd /usr/local/src/redis-6.2.6# 启动redis-server redis.conf 停止服务： 123# 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务，# 因为之前配置了密码，因此需要通过 -u 来指定密码redis-cli -u 123321 shutdown 开机自启我们也可以通过配置来实现开机自启。 首先，新建一个系统服务文件： 1vi /etc/systemd/system/redis.service 内容如下： 1234567891011[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/bin/redis-server /usr/local/src/redis-6.2.6/redis.confPrivateTmp=true[Install]WantedBy=multi-user.target 然后重载系统服务： 1systemctl daemon-reload 现在，我们可以用下面这组命令来操作redis了： 12345678# 启动systemctl start redis# 停止systemctl stop redis# 重启systemctl restart redis# 查看状态systemctl status redis 执行下面的命令，可以让redis开机自启： 1systemctl enable redis Redis客户端安装完成Redis，我们就可以操作Redis，实现数据的CRUD了。这需要用到Redis客户端，包括： 命令行客户端 图形化桌面客户端 编程客户端 Redis命令行客户端Redis安装完成后就自带了命令行客户端：redis-cli，使用方式如下： 1redis-cli [options] [commonds] 其中常见的options有： -h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1 -p 6379：指定要连接的redis节点的端口，默认是6379 -a 123321：指定redis的访问密码 其中的commonds就是Redis的操作命令，例如： ping：与redis服务端做心跳测试，服务端正常会返回pong 不指定commond时，会进入redis-cli的交互控制台： 图形化桌面客户端GitHub上的大神编写了Redis的图形化桌面客户端，地址：https://github.com/uglide/RedisDesktopManager 不过该仓库提供的是RedisDesktopManager的源码，并未提供windows安装包。 在下面这个仓库可以找到安装包：https://github.com/lework/RedisDesktopManager-Windows/releases 安装在课前资料中可以找到Redis的图形化桌面客户端： 解压缩后，运行安装程序即可安装： 此处略。 安装完成后，在安装目录下找到rdm.exe文件： 双击即可运行： 建立连接点击左上角的连接到Redis服务器按钮： 在弹出的窗口中填写Redis服务信息： 点击确定后，在左侧菜单会出现这个链接： 点击即可建立连接了： Redis默认有16个仓库，编号从0至15. 通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。 如果是基于redis-cli连接Redis服务，可以通过select命令来选择数据库： 12# 选择 0号库select 0","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Nacos安装指南","slug":"笔记/安装部署/Nacos安装指南","date":"2022-07-31T22:06:06.000Z","updated":"2022-11-28T10:14:13.310Z","comments":true,"path":"2022/08/01/笔记/安装部署/Nacos安装指南/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Nacos%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/","excerpt":"","text":"Nacos安装指南Windows安装开发阶段采用单机安装即可。 下载安装包在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码： GitHub主页：https://github.com/alibaba/nacos GitHub的Release下载页：https://github.com/alibaba/nacos/releases 如图： 本课程采用1.4.1.版本的Nacos，课前资料已经准备了安装包： windows版本使用nacos-server-1.4.1.zip包即可。 解压将这个包解压到任意非中文目录下，如图： 目录说明： bin：启动脚本 conf：配置文件 端口配置Nacos的默认端口是8848，如果你电脑上的其它进程占用了8848端口，请先尝试关闭该进程。 如果无法关闭占用8848端口的进程，也可以进入nacos的conf目录，修改配置文件中的端口： 修改其中的内容： 启动启动非常简单，进入bin目录，结构如下： 然后执行命令即可： windows命令： 1startup.cmd -m standalone 执行后的效果如图： 访问在浏览器输入地址：http://127.0.0.1:8848/nacos即可： 默认的账号和密码都是nacos，进入后： Linux安装Linux或者Mac安装方式与Windows类似。 安装JDKNacos依赖于JDK运行，索引Linux上也需要安装JDK才行。 上传jdk安装包： 上传到某个目录，例如：/usr/local/ 然后解压缩： 1tar -xvf jdk-8u144-linux-x64.tar.gz 然后重命名为java 配置环境变量： 12export JAVA_HOME=/usr/local/javaexport PATH=$PATH:$JAVA_HOME/bin 设置环境变量： 1source /etc/profile 上传安装包如图： 也可以直接使用课前资料中的tar.gz： 上传到Linux服务器的某个目录，例如/usr/local/src目录下： 解压命令解压缩安装包： 1tar -xvf nacos-server-1.4.1.tar.gz 然后删除安装包： 1rm -rf nacos-server-1.4.1.tar.gz 目录中最终样式： 目录内部： 端口配置与windows中类似 启动在nacos/bin目录中，输入命令启动Nacos： 1sh startup.sh -m standalone Nacos的依赖父工程： 1234567&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 客户端： 123456&lt;!-- nacos客户端依赖包 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"}]},{"title":"Centos7安装Docker","slug":"笔记/安装部署/Centos7安装Docker","date":"2022-07-31T22:06:06.000Z","updated":"2022-11-28T10:15:04.997Z","comments":true,"path":"2022/08/01/笔记/安装部署/Centos7安装Docker/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Centos7%E5%AE%89%E8%A3%85Docker/","excerpt":"","text":"安装DockerDocker 分为 CE 和 EE 两大版本。CE 即社区版（免费，支持周期 7 个月），EE 即企业版，强调安全，付费使用，支持周期 24 个月。 Docker CE 分为 stable test 和 nightly 三个更新频道。 官方网站上有各种环境下的 安装指南，这里主要介绍 Docker CE 在 CentOS上的安装。 CentOS安装DockerDocker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10， CentOS 7 满足最低内核的要求，所以我们在CentOS 7安装Docker。 卸载（可选）如果之前安装过旧版本的Docker，可以使用下面命令卸载： 1234567891011yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 安装docker首先需要大家虚拟机联网，安装yum工具 123yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 --skip-broken 然后更新本地镜像源： 12345678# 设置docker镜像源yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repoyum makecache fast 然后输入命令： 1yum install -y docker-ce docker-ce为社区免费版本。稍等片刻，docker即可安装成功。 启动dockerDocker应用需要用到各种端口，逐一去修改防火墙设置。非常麻烦，因此建议大家直接关闭防火墙！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ 1234# 关闭systemctl stop firewalld# 禁止开机启动防火墙systemctl disable firewalld 通过命令启动docker： 12345systemctl start docker # 启动docker服务systemctl stop docker # 停止docker服务systemctl restart docker # 重启docker服务 然后输入命令，可以查看docker版本： 1docker -v 如图： 配置镜像加速docker官方镜像仓库网速较差，我们需要设置国内镜像服务： 参考阿里云的镜像加速文档：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors CentOS7安装DockerCompose下载Linux下需要通过命令下载： 12# 安装curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose 如果下载速度较慢，或者下载失败，可以使用课前资料提供的docker-compose文件： 上传到/usr/local/bin/目录也可以。 修改文件权限修改文件权限： 12# 修改权限chmod +x /usr/local/bin/docker-compose Base自动补全命令：12# 补全命令curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 如果这里出现错误，需要修改自己的hosts文件： 1echo \"199.232.68.133 raw.githubusercontent.com\" &gt;&gt; /etc/hosts Docker镜像仓库搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。 官网地址：https://hub.docker.com/_/registry 简化版镜像仓库Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。 搭建方式比较简单，命令如下： 123456docker run -d \\ --restart=always \\ --name registry \\ -p 5000:5000 \\ -v registry-data:/var/lib/registry \\ registry 命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。 访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像 带有图形化界面版本使用DockerCompose部署带有图象界面的DockerRegistry，命令如下： 123456789101112131415version: '3.0'services: registry: image: registry volumes: - ./registry-data:/var/lib/registry ui: image: joxit/docker-registry-ui:static ports: - 8080:80 environment: - REGISTRY_TITLE=传智教育私有仓库 - REGISTRY_URL=http://registry:5000 depends_on: - registry 1234mkdir registry-uicd registry-ui/touch docker-compose.ymldocker-compose up -d 配置Docker信任地址我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置： 12345678# 打开要修改的文件vi /etc/docker/daemon.json# 添加内容：\"insecure-registries\":[\"http://192.168.147.129:8080\"]# 重加载systemctl daemon-reload# 重启dockersystemctl restart docker","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]}],"categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"基础","slug":"基础","permalink":"http://example.com/categories/%E5%9F%BA%E7%A1%80/"},{"name":"笔试","slug":"笔试","permalink":"http://example.com/categories/%E7%AC%94%E8%AF%95/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"并发","slug":"并发","permalink":"http://example.com/categories/%E5%B9%B6%E5%8F%91/"},{"name":"日常","slug":"日常","permalink":"http://example.com/categories/%E6%97%A5%E5%B8%B8/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"小技术","slug":"小技术","permalink":"http://example.com/categories/%E5%B0%8F%E6%8A%80%E6%9C%AF/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"数组","slug":"数组","permalink":"http://example.com/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"StringTable","slug":"StringTable","permalink":"http://example.com/tags/StringTable/"},{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"二分查找","slug":"二分查找","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"哈夫曼编码","slug":"哈夫曼编码","permalink":"http://example.com/tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"哈夫曼树","slug":"哈夫曼树","permalink":"http://example.com/tags/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91/"},{"name":"磁盘","slug":"磁盘","permalink":"http://example.com/tags/%E7%A3%81%E7%9B%98/"},{"name":"树","slug":"树","permalink":"http://example.com/tags/%E6%A0%91/"},{"name":"栈","slug":"栈","permalink":"http://example.com/tags/%E6%A0%88/"},{"name":"GC","slug":"GC","permalink":"http://example.com/tags/GC/"},{"name":"interface","slug":"interface","permalink":"http://example.com/tags/interface/"},{"name":"abstract","slug":"abstract","permalink":"http://example.com/tags/abstract/"},{"name":"线程类","slug":"线程类","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B%E7%B1%BB/"},{"name":"基础","slug":"基础","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"智力题","slug":"智力题","permalink":"http://example.com/tags/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"name":"红黑树","slug":"红黑树","permalink":"http://example.com/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"b+数","slug":"b-数","permalink":"http://example.com/tags/b-%E6%95%B0/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"银行家算法","slug":"银行家算法","permalink":"http://example.com/tags/%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95/"},{"name":"二叉树","slug":"二叉树","permalink":"http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"http://example.com/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"},{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"},{"name":"ArrayList","slug":"ArrayList","permalink":"http://example.com/tags/ArrayList/"},{"name":"迭代器","slug":"迭代器","permalink":"http://example.com/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"},{"name":"CopyOnWrite","slug":"CopyOnWrite","permalink":"http://example.com/tags/CopyOnWrite/"},{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"数学","slug":"数学","permalink":"http://example.com/tags/%E6%95%B0%E5%AD%A6/"},{"name":"矩阵","slug":"矩阵","permalink":"http://example.com/tags/%E7%9F%A9%E9%98%B5/"},{"name":"记忆化搜索","slug":"记忆化搜索","permalink":"http://example.com/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"},{"name":"堆(优先队列)","slug":"堆-优先队列","permalink":"http://example.com/tags/%E5%A0%86-%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"},{"name":"单调队列","slug":"单调队列","permalink":"http://example.com/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/"},{"name":"设计","slug":"设计","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1/"},{"name":"回溯","slug":"回溯","permalink":"http://example.com/tags/%E5%9B%9E%E6%BA%AF/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"分治","slug":"分治","permalink":"http://example.com/tags/%E5%88%86%E6%B2%BB/"},{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"},{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"seata","slug":"seata","permalink":"http://example.com/tags/seata/"},{"name":"sentinel","slug":"sentinel","permalink":"http://example.com/tags/sentinel/"},{"name":"双指针","slug":"双指针","permalink":"http://example.com/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"排序","slug":"排序","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F/"},{"name":"前缀和","slug":"前缀和","permalink":"http://example.com/tags/%E5%89%8D%E7%BC%80%E5%92%8C/"},{"name":"模拟","slug":"模拟","permalink":"http://example.com/tags/%E6%A8%A1%E6%8B%9F/"},{"name":"jmeter","slug":"jmeter","permalink":"http://example.com/tags/jmeter/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"MyBatisPlus","slug":"MyBatisPlus","permalink":"http://example.com/tags/MyBatisPlus/"},{"name":"Maven","slug":"Maven","permalink":"http://example.com/tags/Maven/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]}