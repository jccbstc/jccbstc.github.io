{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"标题","date":"2022-11-28T07:05:15.343Z","updated":"2022-11-28T07:05:15.343Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"","date":"2022-11-27T12:56:47.586Z","updated":"2022-11-27T12:56:47.586Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-11-27T12:57:09.450Z","updated":"2022-11-27T12:57:09.450Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Hello World","slug":"hello-world","date":"2022-11-27T12:53:16.993Z","updated":"2022-11-27T12:53:16.993Z","comments":true,"path":"2022/11/27/hello-world/","link":"","permalink":"http://example.com/2022/11/27/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"分布式缓存\t哨兵&分片集群","slug":"笔记/技术2/分布式缓存2","date":"2022-11-14T07:57:37.850Z","updated":"2022-11-28T06:32:10.903Z","comments":true,"path":"2022/11/14/笔记/技术2/分布式缓存2/","link":"","permalink":"http://example.com/2022/11/14/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%982/","excerpt":"","text":"分布式缓存 哨兵&amp;分片集群– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题： Redis哨兵Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。 哨兵原理集群结构和作用哨兵的结构如图： 哨兵的作用如下： 监控：Sentinel 会不断检查您的master和slave是否按预期工作 自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主 通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端 集群监控原理Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令： •主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。 •客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。 集群故障恢复原理一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的： 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高 最后是判断slave节点的运行id大小，越小优先级越高。 当选出一个新的master后，该如何实现切换呢？ 流程如下： sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点 小结Sentinel的三个作用是什么？ 监控 故障转移 通知 Sentinel如何判断一个redis实例是否健康？ 每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线 如果大多数sentinel都认为实例主观下线，则判定服务下线 故障转移步骤有哪些？ 首先选定一个slave作为新的master，执行slaveof no one 然后让所有节点都执行slaveof 新master 修改故障节点配置，添加slaveof 新master RedisTemplate在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。 下面，我们通过一个测试来实现RedisTemplate集成哨兵机制。 导入Demo工程引入依赖在项目的pom文件中引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置Redis地址然后在配置文件application.yml中指定redis的sentinel相关信息： 12345678spring: redis: sentinel: master: mymaster nodes: - 192.168.150.101:27001 - 192.168.150.101:27002 - 192.168.150.101:27003 配置读写分离在项目的启动类中，添加一个新的bean： 1234@Beanpublic LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){ return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);} 这个bean中配置的就是读写策略，包括四种： MASTER：从主节点读取 MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica REPLICA：从slave（replica）节点读取 REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master Redis分片集群搭建分片集群主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决： 海量数据存储问题 高并发写的问题 使用分片集群可以解决上述问题，如图: 分片集群特征： 集群中有多个master，每个master保存不同数据 每个master都可以有多个slave节点 master之间通过ping监测彼此健康状态 客户端请求可以访问集群任意节点，最终都会被转发到正确节点 散列插槽插槽原理Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到： 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况： key中包含”{}”，且“{}”中至少包含1个字符，“{}”中的部分是有效部分 key中不包含“{}”，整个key都是有效部分 例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。 如图，在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到103节点。 到了7003后，执行get num时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点 小结Redis如何判断某个key应该在哪个实例？ 将16384个插槽分配到不同的实例 根据key的有效部分计算哈希值，对16384取余 余数作为插槽，寻找插槽所在实例即可 如何将同一类数据固定的保存在同一个Redis实例？ 这一类数据使用相同的有效部分，例如key都以{typeId}为前缀 集群伸缩redis-cli –cluster提供了很多操作集群的命令，可以通过下面方式查看： 比如，添加节点的命令： 需求分析需求：向集群中添加一个新的master节点，并向其中存储 num = 10 启动一个新的redis实例，端口为7004 添加7004到之前的集群，并作为一个master节点 给7004节点分配插槽，使得num这个key可以存储到7004实例 这里需要两个新的功能： 添加一个节点到集群中 将部分插槽分配到新插槽 创建新的redis实例创建一个文件夹： 1mkdir 7004 拷贝配置文件： 1cp redis.conf /7004 修改配置文件： 1sed /s/6379/7004/g 7004/redis.conf 启动 1redis-server 7004/redis.conf 添加新节点到redis添加节点的语法如下： 执行命令： 1redis-cli --cluster add-node 192.168.150.101:7004 192.168.150.101:7001 通过命令查看集群状态： 1redis-cli -p 7001 cluster nodes 如图，7004加入了集群，并且默认是一个master节点： 但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上 转移插槽我们要将num存储到7004节点，因此需要先看看num的插槽是多少： 如上图所示，num的插槽为2765. 我们可以将0~3000的插槽从7001转移到7004，命令格式如下： 具体命令如下： 建立连接： 得到下面的反馈： 询问要移动多少个插槽，我们计划是3000个： 新的问题来了： 那个node来接收这些插槽？？ 显然是7004，那么7004节点的id是多少呢？ 复制这个id，然后拷贝到刚才的控制台后： 这里询问，你的插槽是从哪里移动过来的？ all：代表全部，也就是三个节点各转移一部分 具体的id：目标节点的id done：没有了 这里我们要从7001获取，因此填写7001的id： 填完后，点击done，这样插槽转移就准备好了： 确认要转移吗？输入yes： 然后，通过命令查看结果： 可以看到： 目的达成。 故障转移集群初识状态是这样的： 其中7001、7002、7003都是master，我们计划让7002宕机。 自动故障转移当集群中有一个master宕机会发生什么呢？ 直接停止一个redis实例，例如7002： 1redis-cli -p 7002 shutdown 1）首先是该实例与其它实例失去连接 2）然后是疑似宕机： 3）最后是确定下线，自动提升一个slave为新的master： 4）当7002再次启动，就会变为一个slave节点了： 手动故障转移利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下： 这种failover命令可以指定三种模式： 缺省：默认的流程，如图1~6歩 force：省略了对offset的一致性校验 takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见 案例需求：在7002这个slave节点执行手动故障转移，重新夺回master地位 步骤如下： 1）利用redis-cli连接7002这个节点 2）执行cluster failover命令 如图： 效果： RedisTemplate访问分片集群RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致： 1）引入redis的starter依赖 2）配置分片集群地址 3）配置读写分离 与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下： 12345678910spring: redis: cluster: nodes: - 192.168.150.101:7001 - 192.168.150.101:7002 - 192.168.150.101:7003 - 192.168.150.101:8001 - 192.168.150.101:8002 - 192.168.150.101:8003","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"分布式缓存 持久化&主从","slug":"笔记/技术2/分布式缓存1","date":"2022-11-14T07:46:45.324Z","updated":"2022-11-28T06:32:10.904Z","comments":true,"path":"2022/11/14/笔记/技术2/分布式缓存1/","link":"","permalink":"http://example.com/2022/11/14/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%981/","excerpt":"","text":"分布式缓存 持久化&amp;主从– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题： Redis持久化Redis有两种持久化方案： RDB持久化 AOF持久化 RDB持久化RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。 执行时机RDB持久化在四种情况下会执行： 执行save命令 执行bgsave命令 Redis停机时 触发RDB条件时 1）save命令 执行下面的命令，可以立即执行一次RDB： save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。 2）bgsave命令 下面的命令可以异步执行RDB： 这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。 3）停机时 Redis停机时会执行一次save命令，实现RDB持久化。 4）触发RDB条件 Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下： 1234# 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save \"\" 则表示禁用RDBsave 900 1 save 300 10 save 60 10000 RDB的其它配置也可以在redis.conf文件中设置： 12345678# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱rdbcompression yes# RDB文件名称dbfilename dump.rdb # 文件保存的路径目录dir ./ RDB原理bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。 fork采用的是copy-on-write技术： 当主进程执行读操作时，访问共享内存； 当主进程执行写操作时，则会拷贝一份数据，执行写操作。 小结RDB方式bgsave的基本流程？ fork主进程得到一个子进程，共享内存空间 子进程读取内存数据并写入新的RDB文件 用新RDB文件替换旧的RDB文件 RDB会在什么时候执行？save 60 1000代表什么含义？ 默认是服务停止时 代表60秒内至少执行1000次修改则触发RDB RDB的缺点？ RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险 fork子进程、压缩、写出RDB文件都比较耗时 AOF持久化AOF原理AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。 AOF配置AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF： 1234# 是否开启AOF功能，默认是noappendonly yes# AOF文件的名称appendfilename \"appendonly.aof\" AOF的命令记录的频率也可以通过redis.conf文件来配： 123456# 表示每执行一次写命令，立即记录到AOF文件appendfsync always # 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案appendfsync everysec # 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘appendfsync no 三种策略对比： AOF文件重写因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。 如图，AOF原本有三个命令，但是set num 123 和 set num 666都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。 所以重写命令后，AOF文件内容就是：mset name jack num 666 Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置： 1234# AOF文件比上次文件 增长超过多少百分比则触发重写auto-aof-rewrite-percentage 100# AOF文件体积最小多大以上才触发重写 auto-aof-rewrite-min-size 64mb RDB与AOF对比RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会结合两者来使用。 Redis主从搭建主从架构单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。 主从数据同步原理全量同步主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点，流程： 这里有一个问题，master如何得知salve是第一次来连接呢？？ 有几个概念，可以作为判断依据： Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。 因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。 因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。 master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。 master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。 因此，master判断一个节点是否是第一次同步的依据，就是看replid是否一致。 如图： 完整流程描述： slave节点请求增量同步 master节点判断replid，发现不一致，拒绝增量同步 master将完整内存数据生成RDB，发送RDB到slave slave清空本地数据，加载master的RDB master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave slave执行接收到的命令，保持与master之间的同步 增量同步全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做增量同步。 什么是增量同步？就是只更新slave与master存在差异的部分数据。如图： 那么master怎么知道slave与自己的数据差异在哪里呢? repl_backlog原理master怎么知道slave与自己的数据差异在哪里呢? 这就要说到全量同步时的repl_baklog文件了。 这个文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾后，会再次从0开始读写，这样数组头部的数据就会被覆盖。 repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset： slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。 随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset： 直到数组被填满： 此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。 但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset： 如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖： 棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。 主从同步优化主从同步可以保证主从数据的一致性，非常重要。 可以从以下几个方面来优化Redis主从就集群： 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。 Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力 主从从架构图： 小结简述全量同步和增量同步区别？ 全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave 什么时候执行全量同步？ slave节点第一次连接master节点时 slave节点断开时间太久，repl_baklog中的offset已经被覆盖时 什么时候执行增量同步？ slave节点断开又恢复，并且在repl_baklog中能找到offset时","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"seata的部署和集成","slug":"笔记/安装部署/seata的部署和集成","date":"2022-11-13T05:21:58.663Z","updated":"2022-11-28T06:32:10.915Z","comments":true,"path":"2022/11/13/笔记/安装部署/seata的部署和集成/","link":"","permalink":"http://example.com/2022/11/13/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/seata%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E9%9B%86%E6%88%90/","excerpt":"","text":"seata的部署和集成部署Seata的tc-server下载首先我们要下载seata-server包，地址在http://seata.io/zh-cn/blog/download.html 解压在非中文目录解压缩这个zip包，其目录结构如下： 修改配置修改conf目录下的application.yml文件： 内容如下： 12345678910111213141516171819202122seata: config: # support: nacos, consul, apollo, zk, etcd3 type: nacos nacos: server-addr: 127.0.0.1:8848 namespace: \"\" #修改 group: SEATA_GROUP #修改 username: nacos password: nacos data-id: seataServer.properties #修改 registry: # support: nacos, eureka, redis, zk, consul, etcd3, sofa type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 group: SEATA_GROUP #修改 namespace: \"\" #修改 cluster: \"SH\" username: nacos #默认 password: nacos #默认 在nacos添加配置特别注意，为了让tc服务的集群可以共享配置，我们选择了nacos作为统一配置中心。因此服务端配置文件seataServer.properties文件需要在nacos中配好。 格式如下： 配置内容如下： 12345678910111213141516171819202122232425262728293031323334# 数据存储方式，db代表数据库store.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;rewriteBatchedStatements=truestore.db.user=rootstore.db.password=111111store.db.minConn=5store.db.maxConn=30store.db.globalTable=global_tablestore.db.branchTable=branch_tablestore.db.queryLimit=100store.db.lockTable=lock_tablestore.db.maxWait=5000# 事务、日志等配置server.recovery.committingRetryPeriod=1000server.recovery.asynCommittingRetryPeriod=1000server.recovery.rollbackingRetryPeriod=1000server.recovery.timeoutRetryPeriod=1000server.maxCommitRetryTimeout=-1server.maxRollbackRetryTimeout=-1server.rollbackRetryTimeoutUnlockEnable=falseserver.undo.logSaveDays=7server.undo.logDeletePeriod=86400000# 客户端与服务端传输方式transport.serialization=seatatransport.compressor=none# 关闭metrics功能，提高性能metrics.enabled=falsemetrics.registryType=compactmetrics.exporterList=prometheusmetrics.exporterPrometheusPort=9898 ==其中的数据库地址、用户名、密码都需要修改成你自己的数据库信息。== 创建数据库表特别注意：tc服务在管理分布式事务时，需要记录事务相关数据到数据库中，你需要提前创建好这些表。 启动TC服务进入bin目录，运行其中的seata-server.bat即可： 启动成功后，seata-server应该已经注册到nacos注册中心了。 打开浏览器，访问nacos地址：http://localhost:8848，然后进入服务列表页面，可以看到seata-tc-server的信息： 微服务集成seata引入依赖首先，我们需要在微服务中引入seata依赖： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--seata starter 采用1.4.2版本--&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${seata.version}&lt;/version&gt;&lt;/dependency&gt; 修改配置文件需要修改application.yml文件，添加一些配置： 1234567891011121314seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 # 参考tc服务自己的registry.conf中的配置 type: nacos nacos: # tc server-addr: 127.0.0.1:8848 namespace: \"\" group: DEFAULT_GROUP application: seata-tc-server # tc服务在nacos中的服务名称 cluster: SH tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称 service: vgroup-mapping: # 事务组与TC服务cluster的映射关系 seata-demo: SH TC服务的高可用和异地容灾模拟异地容灾的TC集群计划启动两台seata的tc服务节点： 节点名称 ip地址 端口号 集群名称 seata 127.0.0.1 8091 SH seata2 127.0.0.1 8092 HZ 之前我们已经启动了一台seata服务，端口是8091，集群名为SH。 现在，将seata目录复制一份，起名为seata2 修改seata2/conf/registry.conf内容如下： 12345678910111213141516171819202122seata: config: # support: nacos, consul, apollo, zk, etcd3 type: nacos nacos: server-addr: 127.0.0.1:8848 namespace: \"\" #修改 group: SEATA_GROUP #修改 username: nacos password: nacos data-id: seataServer.properties #修改 registry: # support: nacos, eureka, redis, zk, consul, etcd3, sofa type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 group: SEATA_GROUP #修改 namespace: \"\" #修改 cluster: \"HZ\" username: nacos #默认 password: nacos #默认 进入seata2/bin目录，然后运行命令： 1seata-server.bat -p 8092 打开nacos控制台，查看服务列表： 点进详情查看： 将事务组映射配置到nacos接下来，我们需要将tx-service-group与cluster的映射关系都配置到nacos配置中心。 新建一个配置： 配置的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 事务组映射关系service.vgroupMapping.seata-demo=SHservice.enableDegrade=falseservice.disableGlobalTransaction=false# 与TC服务的通信配置transport.type=TCPtransport.server=NIOtransport.heartbeat=truetransport.enableClientBatchSendRequest=falsetransport.threadFactory.bossThreadPrefix=NettyBosstransport.threadFactory.workerThreadPrefix=NettyServerNIOWorkertransport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandlertransport.threadFactory.shareBossWorker=falsetransport.threadFactory.clientSelectorThreadPrefix=NettyClientSelectortransport.threadFactory.clientSelectorThreadSize=1transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThreadtransport.threadFactory.bossThreadSize=1transport.threadFactory.workerThreadSize=defaulttransport.shutdown.wait=3# RM配置client.rm.asyncCommitBufferLimit=10000client.rm.lock.retryInterval=10client.rm.lock.retryTimes=30client.rm.lock.retryPolicyBranchRollbackOnConflict=trueclient.rm.reportRetryCount=5client.rm.tableMetaCheckEnable=falseclient.rm.tableMetaCheckerInterval=60000client.rm.sqlParserType=druidclient.rm.reportSuccessEnable=falseclient.rm.sagaBranchRegisterEnable=false# TM配置client.tm.commitRetryCount=5client.tm.rollbackRetryCount=5client.tm.defaultGlobalTransactionTimeout=60000client.tm.degradeCheck=falseclient.tm.degradeCheckAllowTimes=10client.tm.degradeCheckPeriod=2000# undo日志配置client.undo.dataValidation=trueclient.undo.logSerialization=jacksonclient.undo.onlyCareUpdateColumns=trueclient.undo.logTable=undo_logclient.undo.compress.enable=trueclient.undo.compress.type=zipclient.undo.compress.threshold=64kclient.log.exceptionRate=100 微服务读取nacos配置接下来，需要修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件： 123456789seata: config: type: nacos nacos: server-addr: 127.0.0.1:8848 username: nacos password: nacos group: SEATA_GROUP data-id: client.properties 重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"分布式事务","slug":"笔记/技术2/分布式事务","date":"2022-11-13T05:10:51.200Z","updated":"2022-11-28T06:32:10.901Z","comments":true,"path":"2022/11/13/笔记/技术2/分布式事务/","link":"","permalink":"http://example.com/2022/11/13/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"分布式事务分布式事务问题本地事务本地事务，也就是传统的单机事务。在传统数据库事务中，必须要满足四个原则： 分布式事务分布式事务，就是指不是在单个服务或单个数据库架构下，产生的事务，例如： 跨数据源的分布式事务 跨服务的分布式事务 综合情况 在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。例如电商行业中比较常见的下单付款案例，包括下面几个行为： 创建新订单 扣减商品库存 从用户账户余额扣除金额 完成上面的操作需要访问三个不同的微服务和三个不同的数据库。 订单的创建、库存的扣减、账户扣款在每一个服务和数据库内是一个本地事务，可以保证ACID原则。 但是当我们把三件事情看做一个”业务”，要满足保证“业务”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是分布式系统下的事务了。 此时ACID难以满足，这是分布式事务要解决的问题 演示分布式事务问题我们通过一个案例来演示分布式事务的问题： 1）提供的微服务： 微服务结构如下： 其中： seata-demo：父工程，负责管理项目依赖 account-service：账户服务，负责管理用户的资金账户。提供扣减余额的接口 storage-service：库存服务，负责管理商品库存。提供扣减库存的接口 order-service：订单服务，负责管理订单。创建订单时，需要调用account-service和storage-service 2）启动nacos、所有微服务 3）测试下单功能，发出Post请求： 请求如下： 1curl --location --request POST 'http://localhost:8082/order?userId=user202103032042012&amp;commodityCode=100202003032041&amp;count=20&amp;money=200' 如图： 测试发现，当库存不足时，如果余额已经扣减，并不会回滚，出现了分布式事务问题。 理论基础解决分布式事务问题，需要一些分布式系统的基础知识作为理论指导。 CAP定理1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。 Consistency（一致性） Availability（可用性） Partition tolerance （分区容错性） 它们的第一个字母分别是 C、A、P。 Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 一致性Consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。 比如现在包含两个节点，其中的初始数据是一致的： 当我们修改其中一个节点的数据时，两者的数据产生了差异： 要想保住一致性，就必须实现node01 到 node02的数据 同步： 可用性Availability （可用性）：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝。 如图，有三个节点的集群，访问任何一个都可以及时得到响应： 当有部分节点因为网络故障或其它原因无法访问时，代表节点不可用： 分区容错Partition（分区）：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。 Tolerance（容错）：在集群出现分区时，整个系统也要持续对外提供服务 矛盾在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance不可避免。 当节点接收到新的数据变更时，就会出现问题了： 如果此时要保证一致性，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用。 如果此时要保证可用性，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致。 也就是说，在P一定会出现的情况下，A和C之间只能实现一个。 BASE理论BASE理论是对CAP的一种解决思路，包含三个思想： Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。 Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。 Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。 解决分布式事务的思路分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路： AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。 CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。 但不管是哪一种模式，都需要在子系统事务之间互相通讯，协调事务状态，也就是需要一个**事务协调者(TC)**： 这里的子系统事务，称为分支事务；有关联的各个分支事务在一起称为全局事务。 初识SeataSeata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。 官网地址：http://seata.io/其中的文档、播客中提供了大量的使用说明、源码分析。 Seata的架构Seata事务管理中有三个重要的角色： TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 整体的架构如图： Seata基于上述架构提供了四种不同的分布式事务解决方案： XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入 TCC模式：最终一致的分阶段事务模式，有业务侵入 AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式 SAGA模式：长事务模式，有业务侵入 无论哪种方案，都离不开TC，也就是事务的协调者。 微服务集成Seata我们以order-service为例来演示。 引入依赖首先，在order-service中引入依赖： 123456789101112131415161718&lt;!--seata--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;!--seata starter 采用1.4.2版本--&gt; &lt;version&gt;${seata.version}&lt;/version&gt;&lt;/dependency&gt; 配置TC地址在order-service中的application.yml中，配置TC服务信息，通过注册中心nacos，结合服务名称获取TC地址： 1234567891011121314seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 127.0.0.1:8848 # nacos地址 namespace: \"\" # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-tc-server # seata服务名称 username: nacos password: nacos tx-service-group: seata-demo # 事务组名称 service: vgroup-mapping: # 事务组与cluster的映射关系 seata-demo: SH 微服务如何根据这些配置寻找TC的地址呢？ 我们知道注册到Nacos中的微服务，确定一个具体实例需要四个信息： namespace：命名空间 group：分组 application：服务名 cluster：集群名 以上四个信息，在刚才的yaml文件中都能找到： namespace为空，就是默认的public 结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@SH，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。 其它服务其它两个微服务也都参考order-service的步骤来做，完全一样。 四种不同的事务模式下面我们就一起学习下Seata中的四种不同的事务模式。 XA模式XA 规范 是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准，XA 规范 描述了全局的TM与局部的RM之间的接口，几乎所有主流的数据库都对 XA 规范 提供了支持。 两阶段提交XA是规范，目前主流数据库都实现了这种规范，实现的原理都是基于两阶段提交。 正常情况： 异常情况： 一阶段： 事务协调者通知每个事物参与者执行本地事务 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁 二阶段： 事务协调者基于一阶段的报告来判断下一步操作 如果一阶段都成功，则通知所有事务参与者，提交事务 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务 Seata的XA模型Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型，基本架构如图： RM一阶段的工作： ​ ① 注册分支事务到TC ​ ② 执行分支业务sql但不提交 ​ ③ 报告执行状态到TC TC二阶段的工作： TC检测各分支事务执行状态 a.如果都成功，通知所有RM提交事务 b.如果有失败，通知所有RM回滚事务 RM二阶段的工作： 接收TC指令，提交或回滚事务 优缺点XA模式的优点是什么？ 事务的强一致性，满足ACID原则。 常用数据库都支持，实现简单，并且没有代码侵入 XA模式的缺点是什么？ 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差 依赖关系型数据库实现事务 实现XA模式Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下： 1）修改application.yml文件（每个参与事务的微服务），开启XA模式： 12seata: data-source-proxy-mode: XA 2）给发起全局事务的入口方法添加@GlobalTransactional注解: 本例中是OrderServiceImpl中的create方法. 3）重启服务并测试 重启order-service，再次测试，发现无论怎样，三个微服务都能成功回滚。 AT模式AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。 Seata的AT模型基本流程图： 阶段一RM的工作： 注册分支事务 记录undo-log（数据快照） 执行业务sql并提交 报告事务状态 阶段二提交时RM的工作： 删除undo-log即可 阶段二回滚时RM的工作： 根据undo-log恢复数据到更新前 流程梳理我们用一个真实的业务来梳理下AT模式的原理。 比如，现在又一个数据库表，记录用户余额： id money 1 100 其中一个分支业务要执行的SQL为： 1update tb_account set money = money - 10 where id = 1 AT模式下，当前分支事务执行流程如下： 一阶段： 1）TM发起并注册全局事务到TC 2）TM调用分支事务 3）分支事务准备执行业务SQL 4）RM拦截业务SQL，根据where条件查询原始数据，形成快照。 123{ \"id\": 1, \"money\": 100} 5）RM执行业务SQL，提交本地事务，释放数据库锁。此时 money = 90 6）RM报告本地事务状态给TC 二阶段： 1）TM通知TC事务结束 2）TC检查分支事务状态 ​ a）如果都成功，则立即删除快照 ​ b）如果有分支事务失败，需要回滚。读取快照数据（{\"id\": 1, \"money\": 100}），将快照恢复到数据库。此时数据库再次恢复为100 流程图： AT与XA的区别简述AT模式与XA模式最大的区别是什么？ XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。 XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。 XA模式强一致；AT模式最终一致 脏写问题在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图： 解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。 优缺点AT模式的优点： 一阶段完成直接提交事务，释放数据库资源，性能比较好 利用全局锁实现读写隔离 没有代码侵入，框架自动完成回滚和提交 AT模式的缺点： 两阶段之间属于软状态，属于最终一致 框架的快照功能会影响性能，但比XA模式要好很多 实现AT模式AT模式中的快照生成、回滚等动作都是由框架自动完成，没有任何代码侵入，因此实现非常简单。 只不过，AT模式需要一个表来记录全局锁、另一张表来记录数据快照undo_log。 1）导入数据库表，记录全局锁 2）修改application.yml文件，将事务模式修改为AT模式即可： 12seata: data-source-proxy-mode: AT # 默认就是AT 3）重启服务并测试 TCC模式TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法： Try：资源的检测和预留； Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。 Cancel：预留资源释放，可以理解为try的反向操作。 流程分析举例，一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。 阶段一（ Try ）：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30 初识余额： 余额充足，可以冻结： 此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。 **阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30 确认可以提交，不过之前可用金额已经扣减过了，这里只要清除冻结金额就好了： 此时，总金额 = 冻结金额 + 可用金额 = 0 + 70 = 70元 **阶段二(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30 需要回滚，那么就要释放冻结金额，恢复可用金额： Seata的TCC模型Seata中的TCC模型依然延续之前的事务架构，如图： 优缺点TCC模式的每个阶段是做什么的？ Try：资源检查和预留 Confirm：业务执行和提交 Cancel：预留资源的释放 TCC的优点是什么？ 一阶段完成直接提交事务，释放数据库资源，性能好 相比AT模型，无需生成快照，无需使用全局锁，性能最强 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库 TCC的缺点是什么？ 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦 软状态，事务是最终一致 需要考虑Confirm和Cancel的失败情况，做好幂等处理 事务悬挂和空回滚1）空回滚当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。 如图： 执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。 2）业务悬挂对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。 执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂 实现TCC模式解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在try、还是cancel？ 1）思路分析这里我们定义一张表： 12345678CREATE&nbsp;TABLE&nbsp;`account_freeze_tbl`&nbsp;(&nbsp;&nbsp;`xid`&nbsp;varchar(128)&nbsp;NOT&nbsp;NULL,&nbsp;&nbsp;`user_id`&nbsp;varchar(255)&nbsp;DEFAULT&nbsp;NULL&nbsp;COMMENT&nbsp;'用户id',&nbsp;&nbsp;`freeze_money`&nbsp;int(11)&nbsp;unsigned&nbsp;DEFAULT&nbsp;'0'&nbsp;COMMENT&nbsp;'冻结金额',&nbsp;&nbsp;`state`&nbsp;int(1)&nbsp;DEFAULT&nbsp;NULL&nbsp;COMMENT&nbsp;'事务状态，0:try，1:confirm，2:cancel',&nbsp;&nbsp;PRIMARY&nbsp;KEY&nbsp;(`xid`)&nbsp;USING&nbsp;BTREE)&nbsp;ENGINE=InnoDB&nbsp;DEFAULT&nbsp;CHARSET=utf8&nbsp;ROW_FORMAT=COMPACT; 其中： xid：是全局事务id freeze_money：用来记录用户冻结金额 state：用来记录事务状态 那此时，我们的业务开怎么做呢？ Try业务： 记录冻结金额和事务状态到account_freeze表 扣减account表可用金额 Confirm业务 根据xid删除account_freeze表的冻结记录 Cancel业务 修改account_freeze表，冻结金额为0，state为2 修改account表，恢复可用金额 如何判断是否空回滚？ cancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚 如何避免业务悬挂？ try业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务 接下来，我们改造account-service，利用TCC实现余额扣减功能。 2）声明TCC接口TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明， 我们在account-service项目中的cn.itcast.account.service包中新建一个接口，声明TCC三个接口： 123456789101112131415161718package cn.itcast.account.service;import io.seata.rm.tcc.api.BusinessActionContext;import io.seata.rm.tcc.api.BusinessActionContextParameter;import io.seata.rm.tcc.api.LocalTCC;import io.seata.rm.tcc.api.TwoPhaseBusinessAction;@LocalTCCpublic interface AccountTCCService { @TwoPhaseBusinessAction(name = \"deduct\", commitMethod = \"confirm\", rollbackMethod = \"cancel\") void deduct(@BusinessActionContextParameter(paramName = \"userId\") String userId, @BusinessActionContextParameter(paramName = \"money\")int money); boolean confirm(BusinessActionContext ctx); boolean cancel(BusinessActionContext ctx);} 3）编写实现类在account-service服务中的cn.itcast.account.service.impl包下新建一个类，实现TCC业务： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.itcast.account.service.impl;import cn.itcast.account.entity.AccountFreeze;import cn.itcast.account.mapper.AccountFreezeMapper;import cn.itcast.account.mapper.AccountMapper;import cn.itcast.account.service.AccountTCCService;import io.seata.core.context.RootContext;import io.seata.rm.tcc.api.BusinessActionContext;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@Service@Slf4jpublic class AccountTCCServiceImpl implements AccountTCCService { @Autowired private AccountMapper accountMapper; @Autowired private AccountFreezeMapper freezeMapper; @Override @Transactional public void deduct(String userId, int money) { // 0.获取事务id String xid = RootContext.getXID(); // 1.扣减可用余额 accountMapper.deduct(userId, money); // 2.记录冻结金额，事务状态 AccountFreeze freeze = new AccountFreeze(); freeze.setUserId(userId); freeze.setFreezeMoney(money); freeze.setState(AccountFreeze.State.TRY); freeze.setXid(xid); freezeMapper.insert(freeze); } @Override public boolean confirm(BusinessActionContext ctx) { // 1.获取事务id String xid = ctx.getXid(); // 2.根据id删除冻结记录 int count = freezeMapper.deleteById(xid); return count == 1; } @Override public boolean cancel(BusinessActionContext ctx) { // 0.查询冻结记录 String xid = ctx.getXid(); AccountFreeze freeze = freezeMapper.selectById(xid); // 1.恢复可用余额 accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney()); // 2.将冻结金额清零，状态改为CANCEL freeze.setFreezeMoney(0); freeze.setState(AccountFreeze.State.CANCEL); int count = freezeMapper.updateById(freeze); return count == 1; }} SAGA模式Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。 其理论基础是Hector &amp; Kenneth 在1987年发表的论文Sagas。 Seata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html 原理在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。 分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。 Saga也分为两个阶段： 一阶段：直接提交本地事务 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚 优缺点优点： 事务参与者可以基于事件驱动实现异步调用，吞吐高 一阶段直接提交事务，无锁，性能好 不用编写TCC中的三个阶段，实现简单 缺点： 软状态持续时间不确定，时效性差 没有锁，没有事务隔离，会有脏写 四种模式对比我们从以下几个方面来对比四种实现： 一致性：能否保证事务的一致性？强一致还是最终一致？ 隔离性：事务之间的隔离性如何？ 代码侵入：是否需要对业务代码改造？ 性能：有无性能损耗？ 场景：常见的业务场景 如图： 高可用Seata的TC服务作为分布式事务核心，一定要保证集群的高可用性。 高可用架构模型搭建TC服务集群非常简单，启动多个TC服务，注册到nacos即可。 但集群并不能确保100%安全，万一集群所在机房故障怎么办？所以如果要求较高，一般都会做异地多机房容灾。 比如一个TC集群在上海，另一个TC集群在杭州： 微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"微服务保护2","slug":"笔记/技术2/微服务保护2","date":"2022-11-10T05:47:56.026Z","updated":"2022-11-28T06:32:10.908Z","comments":true,"path":"2022/11/10/笔记/技术2/微服务保护2/","link":"","permalink":"http://example.com/2022/11/10/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A42/","excerpt":"","text":"微服务保护隔离和降级限流是一种预防措施，虽然限流可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。 而要将这些故障控制在一定范围，避免雪崩，就要靠线程隔离（舱壁模式）和熔断降级手段了。 线程隔离之前讲到过：调用者在调用服务提供者时，给每个调用的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽。 熔断降级：是在调用方这边加入断路器，统计对服务提供者的调用，如果调用的失败比例过高，则熔断该业务，不允许访问该服务的提供者了。 可以看到，不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方 发起远程调用时做线程隔离、或者服务熔断。 而我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。 FeignClient整合SentinelSpringCloud中，微服务调用都是通过Feign来实现的，因此做客户端保护必须整合Feign和Sentinel。 修改配置，开启sentinel功能修改OrderService的application.yml文件，开启Feign的Sentinel功能： 123feign: sentinel: enabled: true # 开启feign对sentinel的支持 编写失败降级逻辑业务失败后，不能直接报错，而应该返回用户一个友好提示或者默认结果，这个就是失败降级逻辑。 给FeignClient编写失败后的降级逻辑 ①方式一：FallbackClass，无法对远程调用的异常做处理 ②方式二：FallbackFactory，可以对远程调用的异常做处理，我们选择这种 这里我们演示方式二的失败降级处理。 步骤一：在feing-api项目中定义类，实现FallbackFactory： 代码： 123456789101112131415161718192021package cn.itcast.feign.clients.fallback;import cn.itcast.feign.clients.UserClient;import cn.itcast.feign.pojo.User;import feign.hystrix.FallbackFactory;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class UserClientFallbackFactory implements FallbackFactory&lt;UserClient&gt; { @Override public UserClient create(Throwable throwable) { return new UserClient() { @Override public User findById(Long id) { log.error(\"查询用户异常\", throwable); return new User(); } }; }} 步骤二：在feing-api项目中的DefaultFeignConfiguration类中将UserClientFallbackFactory注册为一个Bean： 1234@Beanpublic UserClientFallbackFactory userClientFallbackFactory(){ return new UserClientFallbackFactory();} 步骤三：在feing-api项目中的UserClient接口中使用UserClientFallbackFactory： 123456789101112import cn.itcast.feign.clients.fallback.UserClientFallbackFactory;import cn.itcast.feign.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"userservice\", fallbackFactory = UserClientFallbackFactory.class)public interface UserClient { @GetMapping(\"/user/{id}\") User findById(@PathVariable(\"id\") Long id);} 重启后，访问一次订单查询业务，然后查看sentinel控制台，可以看到新的簇点链路： 总结Sentinel支持的雪崩解决方案： 线程隔离（仓壁模式） 降级熔断 Feign整合Sentinel的步骤： 在application.yml中配置：feign.sentienl.enable=true 给FeignClient编写FallbackFactory并注册为Bean 将FallbackFactory配置到FeignClient 线程隔离（舱壁模式）线程隔离的实现方式线程隔离有两种方式实现： 线程池隔离 信号量隔离（Sentinel默认采用） 如图： 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果 信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。 两者的优缺点： sentinel的线程隔离用法说明： 在添加限流规则时，可以选择两种阈值类型： QPS：就是每秒的请求数，在快速入门中已经演示过 线程数：是该资源能使用用的tomcat线程数的最大值。也就是通过限制线程数量，实现线程隔离（舱壁模式）。 案例需求：给 order-service服务中的UserClient的查询用户接口设置流控规则，线程数不能超过 2。然后利用jemeter测试。 1）配置隔离规则选择feign接口后面的流控按钮： 填写表单： 2）Jmeter测试选择《阈值类型-线程数&lt;2》： 一次发生10个请求，有较大概率并发线程数超过2，而超出的请求会走之前定义的失败降级逻辑。 查看运行结果： 发现虽然结果都是通过了，不过部分请求得到的响应是降级返回的null信息。 总结线程隔离的两种手段是？ 信号量隔离 线程池隔离 信号量隔离的特点是？ 基于计数器模式，简单，开销小 线程池隔离的特点是？ 基于线程池模式，有额外开销，但隔离控制更强 熔断降级熔断降级是解决雪崩问题的重要手段。其思路是由断路器统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。 断路器控制熔断和放行是通过状态机来完成的： 状态机包括三个状态： closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态 open：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态 half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。 请求成功：则切换到closed状态 请求失败：则切换到open状态 断路器熔断策略有三种：慢调用、异常比例、异常数 慢调用慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。 例如： 解读：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。 案例 需求：给 UserClient的查询用户接口设置降级规则，慢调用的RT阈值为50ms，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5 1）设置慢调用修改user-service中的/user/{id}这个接口的业务。通过休眠模拟一个延迟时间： 此时，orderId=101的订单，关联的是id为1的用户，调用时长为60ms： orderId=102的订单，关联的是id为2的用户，调用时长为非常短； 2）设置熔断规则下面，给feign接口设置降级规则： 规则： 超过50ms的请求都会被认为是慢请求 3）测试在浏览器访问：http://localhost:8088/order/101，快速刷新5次，可以发现： 触发了熔断，请求时长缩短至5ms，快速失败了，并且走降级逻辑，返回的null 在浏览器访问：http://localhost:8088/order/102，竟然也被熔断了： 异常比例、异常数异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断。 例如，一个异常比例设置： 解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.4，则触发熔断。 一个异常数设置： 解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于2次，则触发熔断。 案例 需求：给 UserClient的查询用户接口设置降级规则，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5s 1）设置异常请求首先，修改user-service中的/user/{id}这个接口的业务。手动抛出异常，以触发异常比例的熔断： 也就是说，id 为 2时，就会触发异常 2）设置熔断规则下面，给feign接口设置降级规则： 规则： 在5次请求中，只要异常比例超过0.4，也就是有2次以上的异常，就会触发熔断。 3）测试在浏览器快速访问：http://localhost:8088/order/102，快速刷新5次，触发熔断： 此时，我们去访问本来应该正常的103： 授权规则授权规则可以对请求方来源做判断和控制。 授权规则基本规则授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。 白名单：来源（origin）在白名单内的调用者允许访问 黑名单：来源（origin）在黑名单内的调用者不允许访问 点击左侧菜单的授权，可以看到授权规则： 资源名：就是受保护的资源，例如/order/{orderId} 流控应用：是来源者的名单， 如果是勾选白名单，则名单中的来源被许可访问。 如果是勾选黑名单，则名单中的来源被禁止访问。 比如： 我们允许请求从gateway到order-service，不允许浏览器访问order-service，那么白名单中就要填写网关的来源名称（origin）。 如何获取originSentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。 123456public interface RequestOriginParser { /** * 从请求request对象中获取origin，获取方式自定义 */ String parseOrigin(HttpServletRequest request);} 这个方法的作用就是从request对象中，获取请求者的origin值并返回。 默认情况下，sentinel不管请求者从哪里来，返回值永远是default，也就是说一切请求的来源都被认为是一样的值default。 因此，我们需要自定义这个接口的实现，让不同的请求，返回不同的origin。 例如order-service服务中，我们定义一个RequestOriginParser的实现类： 123456789101112131415161718192021package cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import javax.servlet.http.HttpServletRequest;@Componentpublic class HeaderOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { // 1.获取请求头 String origin = request.getHeader(\"origin\"); // 2.非空判断 if (StringUtils.isEmpty(origin)) { origin = \"blank\"; } return origin; }} 我们会尝试从request-header中获取origin值。 给网关添加请求头既然获取请求origin的方式是从reques-header中获取origin值，我们必须让所有从gateway路由到微服务的请求都带上origin头。 这个需要利用之前学习的一个GatewayFilter来实现，AddRequestHeaderGatewayFilter。 修改gateway服务中的application.yml，添加一个defaultFilter： 1234567spring: cloud: gateway: default-filters: - AddRequestHeader=origin,gateway routes: # ...略 这样，从gateway路由的所有请求都会带上origin头，值为gateway。而从其它地方到达微服务的请求则没有这个头。 配置授权规则接下来，我们添加一个授权规则，放行origin值为gateway的请求。 配置如下： 现在，我们直接跳过网关，访问order-service服务： 通过网关访问： 自定义异常结果默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。 异常类型而如果要自定义异常时的返回结果，需要实现BlockExceptionHandler接口： 123456public interface BlockExceptionHandler { /** * 处理请求被限流、降级、授权拦截时抛出的异常：BlockException */ void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception;} 这个方法有三个参数： HttpServletRequest request：request对象 HttpServletResponse response：response对象 BlockException e：被sentinel拦截时抛出的异常 这里的BlockException包含多个不同的子类： 异常 说明 FlowException 限流异常 ParamFlowException 热点参数限流的异常 DegradeException 降级异常 AuthorityException 授权规则异常 SystemBlockException 系统规则异常 自定义异常处理下面，我们就在order-service定义一个自定义异常处理类： 123456789101112131415161718192021222324252627282930313233343536package cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.alibaba.csp.sentinel.slots.block.authority.AuthorityException;import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException;import com.alibaba.csp.sentinel.slots.block.flow.FlowException;import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException;import org.springframework.stereotype.Component;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Componentpublic class SentinelExceptionHandler implements BlockExceptionHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { String msg = \"未知异常\"; int status = 429; if (e instanceof FlowException) { msg = \"请求被限流了\"; } else if (e instanceof ParamFlowException) { msg = \"请求被热点参数限流\"; } else if (e instanceof DegradeException) { msg = \"请求被降级了\"; } else if (e instanceof AuthorityException) { msg = \"没有权限访问\"; status = 401; } response.setContentType(\"application/json;charset=utf-8\"); response.setStatus(status); response.getWriter().println(\"{\\\"msg\\\": \" + msg + \", \\\"status\\\": \" + status + \"}\"); }} 重启测试，在不同场景下，会返回不同的异常消息. 限流： 授权拦截时： 规则持久化现在，sentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，我们必须确保这些规则的持久化，避免丢失。 规则管理模式规则是否能持久化，取决于规则管理模式，sentinel支持三种规则管理模式： 原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。 pull模式 push模式 pull模式pull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则。 push模式push模式：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"微服务保护1","slug":"笔记/技术2/微服务保护1","date":"2022-11-10T05:34:43.193Z","updated":"2022-11-28T06:32:10.907Z","comments":true,"path":"2022/11/10/笔记/技术2/微服务保护1/","link":"","permalink":"http://example.com/2022/11/10/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF2/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A41/","excerpt":"","text":"微服务保护雪崩问题及解决方案雪崩问题微服务中，服务间调用关系错综复杂，一个微服务往往依赖于多个其它微服务。 如果服务提供者I发生了故障，当前的应用的部分业务因为依赖于服务I，因此也会被阻塞。此时，其它不依赖于服务I的业务似乎不受影响。 但是，依赖服务I的业务请求被阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞： 服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，那么当前服务也就不可用了。 那么，依赖于当前服务的其它服务随着时间的推移，最终也都会变的不可用，形成级联失败，雪崩就发生了： 超时处理解决雪崩问题的常见方式有四种： •超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待 仓壁模式方案2：仓壁模式 仓壁模式来源于船舱的设计： 船舱都会被隔板分离为多个独立空间，当船体破损时，只会导致部分空间进入，将故障控制在一定范围内，避免整个船体都被淹没。 于此类似，我们可以限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离。 断路器断路器模式：由断路器统计业务执行的异常比例，如果超出阈值则会熔断该业务，拦截访问该业务的一切请求。 断路器会统计访问某个服务的请求数量，异常比例： 当发现访问服务D的请求异常比例过高时，认为服务D有导致雪崩的风险，会拦截访问服务D的一切请求，形成熔断： 限流流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。 总结什么是雪崩问题？ 微服务之间相互调用，因为调用链中的一个服务故障，引起整个链路都无法访问的情况。 可以认为： 限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。 超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。 流量控制雪崩问题虽然有四种方案，但是限流是避免服务因突发的流量而发生故障，是对微服务雪崩问题的预防。我们先学习这种模式。 簇点链路当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。 默认情况下sentinel会监控SpringMVC的每一个端点（Endpoint，也就是controller中的方法），因此SpringMVC的每一个端点（Endpoint）就是调用链路中的一个资源。 例如，我们刚才访问的order-service中的OrderController中的端点：/order/{orderId} 流控、熔断等都是针对簇点链路中的资源来设置的，因此我们可以点击对应资源后面的按钮来设置规则： 流控：流量控制 降级：降级熔断 热点：热点参数限流，是限流的一种 授权：请求的权限控制 快速入门示例点击资源/order/{orderId}后面的流控按钮，就可以弹出表单。 表单中可以填写限流规则，如下： 其含义是限制 /order/{orderId}这个资源的单机QPS为1，即每秒只允许1次请求，超出的请求会被拦截并报错。 练习：需求：给 /order/{orderId}这个资源设置流控规则，QPS不能超过 5，然后测试。 1）首先在sentinel控制台添加限流规则 2）利用jmeter测试 选择： 20个用户，2秒内运行完，QPS是10，超过了5. 选中流控入门，QPS&lt;5右键运行： 注意，不要点击菜单中的执行按钮来运行。 结果： 可以看到，成功的请求每次只有5个 流控模式在添加限流规则时，点击高级选项，可以选择三种流控模式： 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流 快速入门测试的就是直接模式。 关联模式关联模式：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 配置规则： 语法说明：当/write资源访问量触发阈值时，就会对/read资源限流，避免影响/write资源。 使用场景：比如用户支付时需要修改订单状态，同时用户要查询订单。查询和修改操作会争抢数据库锁，产生竞争。业务需求是优先支付和更新订单的业务，因此当修改订单业务触发阈值时，需要对查询订单业务限流。 需求说明： 在OrderController新建两个端点：/order/query和/order/update，无需实现业务 配置流控规则，当/order/ update资源被访问的QPS超过5时，对/order/query请求限流 1）定义/order/query端点，模拟订单查询 1234@GetMapping(\"/query\")public String queryOrder() { return \"查询订单成功\";} 2）定义/order/update端点，模拟订单更新 1234@GetMapping(\"/update\")public String updateOrder() { return \"更新订单成功\";} 重启服务，查看sentinel控制台的簇点链路： 3）配置流控规则 对哪个端点限流，就点击哪个端点后面的按钮。我们是对订单查询/order/query限流，因此点击它后面的按钮： 在表单中填写流控规则： 4）在Jmeter测试 选择《流控模式-关联》： 可以看到1000个用户，100秒，因此QPS为10，超过了我们设定的阈值：5 查看http请求： 请求的目标是/order/update，这样这个断点就会触发阈值。 但限流的目标是/order/query，我们在浏览器访问，可以发现： 确实被限流了。 5）总结 链路模式链路模式：只针对从指定链路访问到本资源的请求做统计，判断是否超过阈值。 配置示例： 例如有两条请求链路： /test1 –&gt; /common /test2 –&gt; /common 如果只希望统计从/test2进入到/common的请求，则可以这样配置： 实战案例 需求：有查询订单和创建订单业务，两者都需要查询商品。针对从查询订单进入到查询商品的请求统计，并设置限流。 步骤： 在OrderService中添加一个queryGoods方法，不用实现业务 在OrderController中，改造/order/query端点，调用OrderService中的queryGoods方法 在OrderController中添加一个/order/save的端点，调用OrderService的queryGoods方法 给queryGoods设置限流规则，从/order/query进入queryGoods的方法限制QPS必须小于2 实现： 1）添加查询商品方法在order-service服务中，给OrderService类添加一个queryGoods方法： 123public void queryGoods(){ System.err.println(\"查询商品\");} 2）查询订单时，查询商品在order-service的OrderController中，修改/order/query端点的业务逻辑： 12345678@GetMapping(\"/query\")public String queryOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.out.println(\"查询订单\"); return \"查询订单成功\";} 3）新增订单，查询商品在order-service的OrderController中，修改/order/save端点，模拟新增订单： 12345678@GetMapping(\"/save\")public String saveOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.err.println(\"新增订单\"); return \"新增订单成功\";} 4）给查询商品添加资源标记默认情况下，OrderService中的方法是不被Sentinel监控的，需要我们自己通过注解来标记要监控的方法。 给OrderService的queryGoods方法添加@SentinelResource注解： 1234@SentinelResource(\"goods\")public void queryGoods(){ System.err.println(\"查询商品\");} 链路模式中，是对不同来源的两个链路做监控。但是sentinel默认会给进入SpringMVC的所有请求设置同一个root资源，会导致链路模式失效。 我们需要关闭这种对SpringMVC的资源聚合，修改order-service服务的application.yml文件： 1234spring: cloud: sentinel: web-context-unify: false # 关闭context整合 重启服务，访问/order/query和/order/save，可以查看到sentinel的簇点链路规则中，出现了新的资源： 5）添加流控规则点击goods资源后面的流控按钮，在弹出的表单中填写下面信息： 只统计从/order/query进入/goods的资源，QPS阈值为2，超出则被限流。 6）Jmeter测试选择《流控模式-链路》： 可以看到这里200个用户，50秒内发完，QPS为4，超过了我们设定的阈值2 一个http请求是访问/order/save： 运行的结果： 完全不受影响。 另一个是访问/order/query： 运行结果： 每次只有2个通过。 总结流控模式有哪些？ •直接：对当前资源限流 •关联：高优先级资源触发阈值，对低优先级资源限流。 •链路：阈值统计时，只统计从指定资源进入当前资源的请求，是对请求来源的限流 流控效果在流控的高级选项中，还有一个流控效果选项： 流控效果是指请求达到流控阈值时应该采取的措施，包括三种： 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。 warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长 warm up阈值一般是一个微服务能承担的最大QPS，但是一个服务刚刚启动时，一切资源尚未初始化（冷启动），如果直接将QPS跑到最大值，可能导致服务瞬间宕机。 warm up也叫预热模式，是应对服务冷启动的一种方案。请求阈值初始值是 maxThreshold / coldFactor，持续指定时长后，逐渐提高到maxThreshold值。而coldFactor的默认值是3. 例如，我设置QPS的maxThreshold为10，预热时间为5秒，那么初始阈值就是 10 / 3 ，也就是3，然后在5秒后逐渐增长到10. 案例 需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用warm up效果，预热时长为5秒 1）配置流控规则： 2）Jmeter测试选择《流控效果，warm up》： QPS为10. 刚刚启动时，大部分请求失败，成功的只有3个，说明QPS被限定在3： 随着时间推移，成功比例越来越高： 到Sentinel控制台查看实时监控： 一段时间后： 排队等待当请求超过QPS阈值时，快速失败和warm up 会拒绝新的请求并抛出异常。 而排队等待则是让所有请求进入一个队列中，然后按照阈值允许的时间间隔依次执行。后来的请求必须等待前面执行完成，如果请求预期的等待时间超出最大时长，则会被拒绝。 工作原理 例如：QPS = 5，意味着每200ms处理一个队列中的请求；timeout = 2000，意味着预期等待时长超过2000ms的请求会被拒绝并抛出异常。 那什么叫做预期等待时长呢？ 比如现在一下子来了12 个请求，因为每200ms执行一个请求，那么： 第6个请求的预期等待时长 = 200 * （6 - 1） = 1000ms 第12个请求的预期等待时长 = 200 * （12-1） = 2200ms 现在，第1秒同时接收到10个请求，但第2秒只有1个请求，此时QPS的曲线这样的： 如果使用队列模式做流控，所有进入的请求都要排队，以固定的200ms的间隔执行，QPS会变的很平滑： 平滑的QPS曲线，对于服务器来说是更友好的。 案例 需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用排队的流控效果，超时时长设置为5s 1）添加流控规则 2）Jmeter测试选择《流控效果，队列》： QPS为15，已经超过了我们设定的10。 如果是之前的 快速失败、warmup模式，超出的请求应该会直接报错。 但是我们看看队列模式的运行结果： 全部都通过了。 再去sentinel查看实时监控的QPS曲线： QPS非常平滑，一致保持在10，但是超出的请求没有被拒绝，而是放入队列。因此响应时间（等待时间）会越来越长。 当队列满了以后，才会有部分请求失败： 总结流控效果有哪些？ 快速失败：QPS超过阈值时，拒绝新的请求 warm up： QPS超过阈值时，拒绝新的请求；QPS阈值是逐渐提升的，可以避免冷启动时高并发导致服务宕机。 排队等待：请求会进入队列，按照阈值允许的时间间隔依次执行请求；如果请求预期等待时长大于超时时间，直接拒绝 热点参数限流之前的限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是分别统计参数值相同的请求，判断是否超过QPS阈值。 全局参数限流例如，一个根据id查询商品的接口： 访问/goods/{id}的请求中，id参数值会有变化，热点参数限流会根据参数值分别统计QPS，统计结果： 当id=1的请求触发阈值被限流时，id值不为1的请求不受影响。 配置示例： 代表的含义是：对hot这个资源的0号参数（第一个参数）做统计，每1秒相同参数值的请求数不能超过5 热点参数限流刚才的配置中，对查询商品这个接口的所有商品一视同仁，QPS都限定为5. 而在实际开发中，可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的QPS限制与其它商品不一样，高一些。那就需要配置热点参数限流的高级选项了： 结合上一个配置，这里的含义是对0号的long类型参数限流，每1秒相同参数的QPS不能超过5，有两个例外： •如果参数值是100，则每1秒允许的QPS为10 •如果参数值是101，则每1秒允许的QPS为15 案例案例需求：给/order/{orderId}这个资源添加热点参数限流，规则如下： •默认的热点参数规则是每1秒请求量不超过2 •给102这个参数设置例外：每1秒请求量不超过4 •给103这个参数设置例外：每1秒请求量不超过10 注意事项：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource注解标记资源 1）标记资源给order-service中的OrderController中的/order/{orderId}资源添加注解： 2）热点参数限流规则访问该接口，可以看到我们标记的hot资源出现了： 这里不要点击hot后面的按钮，页面有BUG 点击左侧菜单中热点规则菜单： 点击新增，填写表单： 3）Jmeter测试选择《热点参数限流 QPS1》： 这里发起请求的QPS为5. 包含3个http请求： 普通参数，QPS阈值为2 运行结果： 例外项，QPS阈值为4 运行结果： 例外项，QPS阈值为10 运行结果：","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"Sentinel介绍和安装","slug":"笔记/安装部署/sentinel","date":"2022-11-08T09:04:09.208Z","updated":"2022-11-28T06:32:10.916Z","comments":true,"path":"2022/11/08/笔记/安装部署/sentinel/","link":"","permalink":"http://example.com/2022/11/08/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/sentinel/","excerpt":"","text":"服务保护技术对比在SpringCloud当中支持多种服务保护技术： Netfix Hystrix Sentinel Resilience4J 早期比较流行的是Hystrix框架，但目前国内实用最广泛的还是阿里巴巴的Sentinel框架，这里我们做下对比： Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于慢调用比例或异常比例 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 流量整形 支持慢启动、匀速排队模式 不支持 系统自适应保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix Sentinel介绍和安装初识SentinelSentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：https://sentinelguard.io/zh-cn/index.html Sentinel 具有以下特征: •丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 •完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 •广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 •完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 安装Sentinel1）下载 sentinel官方提供了UI控制台，方便我们对系统做限流设置。大家可以在GitHub下载。 课前资料也提供了下载好的jar包： 2）运行 将jar包放到任意非中文目录，执行命令： 1java -jar sentinel-dashboard-1.8.1.jar 如果要修改Sentinel的默认端口、账户、密码，可以通过下列配置： 配置项 默认值 说明 server.port 8080 服务端口 sentinel.dashboard.auth.username sentinel 默认用户名 sentinel.dashboard.auth.password sentinel 默认密码 例如，修改端口： 1java -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar 3）访问 访问http://localhost:8080页面，就可以看到sentinel的控制台了： 需要输入账号和密码，默认都是：sentinel 登录后，发现一片空白，什么都没有： 这是因为我们还没有与微服务整合。 微服务整合Sentinel我们在order-service中整合sentinel，并连接sentinel的控制台，步骤如下： 1）引入sentinel依赖 12345&lt;!--sentinel--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置控制台 修改application.yaml文件，添加下面内容： 1234567server: port: 8088spring: cloud: sentinel: transport: dashboard: localhost:8080 3）访问order-service的任意端点 打开浏览器，访问http://localhost:8088/order/101，这样才能触发sentinel的监控。 然后再访问sentinel的控制台，查看效果：","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"Jmeter快速入门","slug":"笔记/技术/Jmeter快速入门","date":"2022-07-31T22:22:08.000Z","updated":"2022-11-28T06:32:10.890Z","comments":true,"path":"2022/08/01/笔记/技术/Jmeter快速入门/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Jmeter%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"","text":"Jmeter快速入门安装JmeterJmeter依赖于JDK，所以必须确保当前计算机上已经安装了JDK，并且配置了环境变量。 下载可以Apache Jmeter官网下载，地址：http://jmeter.apache.org/download_jmeter.cgi 解压因为下载的是zip包，解压缩即可使用，目录结构如下： 其中的bin目录就是执行的脚本，其中包含启动脚本： 运行双击即可运行，但是有两点注意： 启动速度比较慢，要耐心等待 启动后黑窗口不能关闭，否则Jmeter也跟着关闭了 快速入门设置中文语言默认Jmeter的语言是英文，需要设置： 效果： 注意：上面的配置只能保证本次运行是中文，如果要永久中文，需要修改Jmeter的配置文件 打开jmeter文件夹，在bin目录中找到 jmeter.properties，添加下面配置： 1language=zh_CN 注意：前面不要出现#，#代表注释，另外这里是下划线，不是中划线 基本用法在测试计划上点鼠标右键，选择添加 &gt; 线程（用户） &gt; 线程组： 在新增的线程组中，填写线程信息： 给线程组点鼠标右键，添加http取样器： 编写取样器内容： 添加监听报告： 添加监听结果树： 汇总报告结果： 结果树：","categories":[{"name":"小技术","slug":"小技术","permalink":"http://example.com/categories/%E5%B0%8F%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"SpringCloud实用篇","slug":"笔记/技术/SpringCloud实用篇","date":"2022-07-31T22:20:09.000Z","updated":"2022-11-28T06:32:10.900Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud实用篇/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%AE%9E%E7%94%A8%E7%AF%87/","excerpt":"","text":"SpringCloud实用篇Nacos配置管理Nacos除了可以做注册中心，同样可以做配置管理来使用。 统一配置管理当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。 Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。 在nacos中添加配置文件如何在nacos中管理配置呢？ 然后在弹出的表单中，填写配置信息： 注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。 从微服务拉取配置微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。 但如果尚未读取application.yml，又如何得知nacos地址呢？ 因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下： 1）引入nacos-config依赖 首先，在user-service服务中，引入nacos-config的客户端依赖： 12345&lt;!--nacos配置管理依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 2）添加bootstrap.yaml 然后，在user-service中添加一个bootstrap.yaml文件，内容如下： 12345678910spring: application: name: userservice # 服务名称 profiles: active: dev #开发环境，这里是dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据 ${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}作为文件id，来读取配置。 本例中，就是去读取userservice-dev.yaml： 3）读取nacos配置 在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置： 完整代码： 1234567891011121314151617181920212223242526272829package cn.itcast.user.web;import cn.itcast.user.pojo.User;import cn.itcast.user.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;@Slf4j@RestController@RequestMapping(\"/user\")public class UserController { @Autowired private UserService userService; @Value(\"${pattern.dateformat}\") private String dateformat; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } // ...略} 在页面访问，可以看到效果： 配置热更新我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。 要实现配置热更新，可以使用两种方式： 方式一在@Value注入的变量所在类上添加注解@RefreshScope： 方式二使用@ConfigurationProperties注解代替@Value注解。 在user-service服务中，添加一个类，读取patterrn.dateformat属性： 123456789101112package cn.itcast.user.config;import lombok.Data;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@Data@ConfigurationProperties(prefix = \"pattern\")public class PatternProperties { private String dateformat;} 在UserController中使用这个类代替@Value： 完整代码： 123456789101112131415161718192021222324252627282930313233package cn.itcast.user.web;import cn.itcast.user.config.PatternProperties;import cn.itcast.user.pojo.User;import cn.itcast.user.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;@Slf4j@RestController@RequestMapping(\"/user\")public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\"now\") public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } // 略} 配置共享其实微服务启动时，会去nacos读取多个配置文件，例如： [spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml [spring.application.name].yaml，例如：userservice.yaml 而[spring.application.name].yaml不包含环境，因此可以被多个环境共享。 下面我们通过案例来测试配置共享 1）添加一个环境共享配置我们在nacos中添加一个userservice.yaml文件： 2）在user-service中读取共享配置在user-service服务中，修改PatternProperties类，读取新添加的属性： 在user-service服务中，修改UserController，添加一个方法： 3）运行两个UserApplication，使用不同的profile修改UserApplication2这个启动项，改变其profile值： 这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。 启动UserApplication和UserApplication2 访问http://localhost:8081/user/prop，结果： 访问http://localhost:8082/user/prop，结果： 可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。 4）配置共享的优先级当nacos、服务本地同时出现相同属性时，优先级有高低之分： Feign远程调用先来看我们以前利用RestTemplate发起远程调用的代码： 存在下面的问题： •代码可读性差，编程体验不统一 •参数复杂URL难以维护 Feign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign 其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。 Feign替代RestTemplateFegin的使用步骤如下： 1）引入依赖我们在order-service服务的pom文件中引入feign的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 2）添加注解在order-service的启动类添加注解开启Feign的功能： 3）编写Feign的客户端在order-service中新建一个接口，内容如下： 123456789101112package cn.itcast.order.client;import cn.itcast.order.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(\"userservice\")public interface UserClient { @GetMapping(\"/user/{id}\") User findById(@PathVariable(\"id\") Long id);} 这个客户端主要是基于SpringMVC的注解来声明远程调用的信息，比如： 服务名称：userservice 请求方式：GET 请求路径：/user/{id} 请求参数：Long id 返回值类型：User 这样，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate来发送了。 4）测试修改order-service中的OrderService类中的queryOrderById方法，使用Feign客户端代替RestTemplate： 是不是看起来优雅多了。 5）总结使用Feign的步骤： ① 引入依赖 ② 添加@EnableFeignClients注解 ③ 编写FeignClient接口 ④ 使用FeignClient中定义的方法代替RestTemplate 自定义配置Feign可以支持很多的自定义配置，如下表所示： 类型 作用 说明 feign.Logger.Level 修改日志级别 包含四种不同的级别：NONE、BASIC、HEADERS、FULL feign.codec.Decoder 响应结果的解析器 http远程调用的结果做解析，例如解析json字符串为java对象 feign.codec.Encoder 请求参数编码 将请求参数编码，便于通过http请求发送 feign. Contract 支持的注解格式 默认是SpringMVC的注解 feign. Retryer 失败重试机制 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。 下面以日志为例来演示如何自定义配置。 配置文件方式基于配置文件修改feign的日志级别可以针对单个服务： 12345feign: client: config: userservice: # 针对某个微服务的配置 loggerLevel: FULL # 日志级别 也可以针对所有服务： 12345feign: client: config: default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置 loggerLevel: FULL # 日志级别 而日志的级别分为四种： NONE：不记录任何日志信息，这是默认值。 BASIC：仅记录请求的方法，URL以及响应状态码和执行时间 HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息 FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。 Java代码方式也可以基于Java代码来修改日志级别，先声明一个类，然后声明一个Logger.Level的对象： 123456public class DefaultFeignConfiguration { @Bean public Logger.Level feignLogLevel(){ return Logger.Level.BASIC; // 日志级别为BASIC }} 如果要全局生效，将其放到启动类的@EnableFeignClients这个注解中： 1@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 如果是局部生效，则把它放到对应的@FeignClient这个注解中： 1@FeignClient(value = \"userservice\", configuration = DefaultFeignConfiguration .class) Feign使用优化Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括： •URLConnection：默认实现，不支持连接池 •Apache HttpClient ：支持连接池 •OKHttp：支持连接池 因此提高Feign的性能主要手段就是使用连接池代替默认的URLConnection。 这里我们用Apache的HttpClient来演示。 1）引入依赖 在order-service的pom文件中引入Apache的HttpClient依赖： 12345&lt;!--httpClient的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置连接池 在order-service的application.yml中添加配置： 123456789feign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 接下来，在FeignClientFactoryBean中的loadBalance方法中打断点： Debug方式启动order-service服务，可以看到这里的client，底层就是Apache HttpClient： 总结，Feign的优化： 1.日志级别尽量用basic 2.使用HttpClient或OKHttp代替URLConnection ① 引入feign-httpClient依赖 ② 配置文件开启httpClient功能，设置连接池参数 最佳实践所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。 自习观察可以发现，Feign的客户端与服务提供者的controller代码非常相似： feign客户端： UserController： 有没有一种办法简化这种重复的代码编写呢？ 继承方式一样的代码可以通过继承来共享： 1）定义一个API接口，利用定义方法，并基于SpringMVC注解做声明。 2）Feign客户端和Controller都集成改接口 优点： 简单 实现了代码共享 缺点： 服务提供方、服务消费方紧耦合 参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表、注解 抽取方式将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。 例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。 实现基于抽取的最佳实践1）抽取首先创建一个module，命名为feign-api： 项目结构： 在feign-api中然后引入feign的starter依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 然后，order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中 2）在order-service中使用feign-api首先，删除order-service中的UserClient、User、DefaultFeignConfiguration等类或接口。 在order-service的pom文件中中引入feign-api的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;cn.itcast.demo&lt;/groupId&gt; &lt;artifactId&gt;feign-api&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 修改order-service中的所有与上述三个组件有关的导包部分，改成导入feign-api中的包 3）重启测试重启后，发现服务报错了： 这是因为UserClient现在在cn.itcast.feign.clients包下， 而order-service的@EnableFeignClients注解是在cn.itcast.order包下，不在同一个包，无法扫描到UserClient。 4）解决扫描包问题方式一： 指定Feign应该扫描的包： 1@EnableFeignClients(basePackages = \"cn.itcast.feign.clients\") 方式二： 指定需要加载的Client接口： 1@EnableFeignClients(clients = {UserClient.class}) Gateway服务网关Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。 为什么需要网关Gateway网关是我们服务的守门神，所有微服务的统一入口。 网关的核心功能特性： 请求路由 权限控制 限流 架构图： 权限控制：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。 路由和负载均衡：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。 限流：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。 在SpringCloud中网关的实现包括两种： gateway zuul Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。 gateway快速入门下面，我们就演示下网关的基本路由功能。基本步骤如下： 创建SpringBoot工程gateway，引入网关依赖 编写启动类 编写基础配置和路由规则 启动网关服务进行测试 1）创建gateway服务，引入依赖创建服务： 引入依赖： 12345678910&lt;!--网关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--nacos服务发现依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 2）编写启动类123456789101112package cn.itcast.gateway;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} 3）编写基础配置和路由规则创建application.yml文件，内容如下： 123456789101112131415server: port: 10010 # 网关端口spring: application: name: gateway # 服务名称 cloud: nacos: server-addr: localhost:8848 # nacos地址 gateway: routes: # 网关路由配置 - id: user-service # 路由id，自定义，只要唯一即可 # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址 uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称 predicates: # 路由断言，也就是判断请求是否符合路由规则的条件 - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求 我们将符合Path 规则的一切请求，都代理到 uri参数指定的地址。 本例中，我们将 /user/**开头的请求，代理到lb://userservice，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。 4）重启测试重启网关，访问http://localhost:10010/user/1时，符合`/user/**`规则，请求转发到uri：http://userservice/user/1，得到了结果： 5）网关路由的流程图整个访问的流程如下： 总结： 网关搭建步骤： 创建项目，引入nacos服务发现和gateway依赖 配置application.yml，包括服务基本信息、nacos地址、路由 路由配置包括： 路由id：路由的唯一标示 路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡 路由断言（predicates）：判断路由的规则， 路由过滤器（filters）：对请求或响应做处理 接下来，就重点来学习路由断言和路由过滤器的详细知识 断言工厂我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件 例如Path=/user/**是按照路径匹配，这个规则是由 org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来 处理的，像这样的断言工厂在SpringCloudGateway还有十几个: 名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[America/Denver] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/** Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 我们只需要掌握Path这种路由工程就可以了。 过滤器工厂GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理： 路由过滤器的种类Spring提供了31种不同的路由过滤器工厂。例如： 名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 请求头过滤器下面我们以AddRequestHeader 为例来讲解。 需求：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome! 只需要修改gateway服务的application.yml文件，添加路由过滤即可： 12345678910spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** filters: # 过滤器 - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头 当前过滤器写在userservice路由下，因此仅仅对访问userservice的请求有效。 默认过滤器如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下： 12345678910spring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** default-filters: # 默认过滤项 - AddRequestHeader=Truth, Itcast is freaking awesome! 总结过滤器的作用是什么？ ① 对路由的请求或响应做加工处理，比如添加请求头 ② 配置在路由下的过滤器只对当前路由的请求生效 defaultFilters的作用是什么？ ① 对所有路由都生效的过滤器 全局过滤器上一节学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。 全局过滤器作用全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。 定义方式是实现GlobalFilter接口。 12345678910public interface GlobalFilter { /** * 处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理 * * @param exchange 请求上下文，里面可以获取Request、Response等信息 * @param chain 用来把请求委托给下一个过滤器 * @return {@code Mono&lt;Void&gt;} 返回标示当前过滤器业务结束 */ Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);} 在filter中编写自定义逻辑，可以实现下列功能： 登录状态判断 权限校验 请求限流等 自定义全局过滤器需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件： 参数中是否有authorization， authorization参数值是否为admin 如果同时满足则放行，否则拦截 实现： 在gateway中定义一个过滤器： 12345678910111213141516171819202122232425262728293031package cn.itcast.gateway.filters;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.annotation.Order;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;@Order(-1)@Componentpublic class AuthorizeFilter implements GlobalFilter { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求参数 MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams(); // 2.获取authorization参数 String auth = params.getFirst(\"authorization\"); // 3.校验 if (\"admin\".equals(auth)) { // 放行 return chain.filter(exchange); } // 4.拦截 // 4.1.禁止访问，设置状态码 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN); // 4.2.结束处理 return exchange.getResponse().setComplete(); }} 过滤器执行顺序请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter 请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器： 排序的规则是什么呢？ 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前。 GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。 当过滤器的order值一样时，会按照 defaultFilter &gt; 路由过滤器 &gt; GlobalFilter的顺序执行。 详细内容，可以查看源码： org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。 org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链 跨域问题什么是跨域问题跨域：域名不一致就是跨域，主要包括： 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com 域名相同，端口不同：localhost:8080和localhost8081 跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题 解决方案：CORS，这个以前应该学习过，这里不再赘述了。不知道的小伙伴可以查看https://www.ruanyifeng.com/blog/2016/04/cors.html 模拟跨域问题找到页面文件： 放入tomcat或者nginx这样的web服务器中，启动并访问。 可以在浏览器控制台看到下面的错误： 从localhost:8090访问localhost:10010，端口不同，显然是跨域的请求。 解决跨域问题在gateway服务的application.yml文件中，添加下面的配置： 12345678910111213141516171819spring: cloud: gateway: # 。。。 globalcors: # 全局的跨域处理 add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题 corsConfigurations: '[/**]': allowedOrigins: # 允许哪些网站的跨域请求 - \"http://localhost:8090\" allowedMethods: # 允许的跨域ajax的请求方式 - \"GET\" - \"POST\" - \"DELETE\" - \"PUT\" - \"OPTIONS\" allowedHeaders: \"*\" # 允许在请求中携带的头信息 allowCredentials: true # 是否允许携带cookie maxAge: 360000 # 这次跨域检测的有效期","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"hexo发生error：spawn failed错误","slug":"报错日常/hexo错误","date":"2022-07-31T22:16:06.000Z","updated":"2022-11-28T06:32:10.883Z","comments":true,"path":"2022/08/01/报错日常/hexo错误/","link":"","permalink":"http://example.com/2022/08/01/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/hexo%E9%94%99%E8%AF%AF/","excerpt":"","text":"hexo发生error：spawn failed错误例如: 123456789FATAL { err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (/usr/local/src/hexo/cairbin/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:376:20) at Process.ChildProcess._handle.onexit (internal/child_process.js:277:12) { code: 128 }} Something's wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 网上的解决方案基本上是一种 进行以下处理 1234567##进入博客根目录cd /usr/local/src/hexo/blog/##删除git提交文件夹rm -rf .deploy_git/git config --global core.autocrlf false 最后重新生成提交 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 还有一些是对于网络的处理,我在自己的电脑上试了很多种解决方案,都没有作用,后来我进入.deploy_git/目录下,输入cmd,然后运行 1git config --global core.autocrlf false 最后重新生成提交,就解决了 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d","categories":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}]},{"title":"运行docker-compose up -d 报错","slug":"报错日常/docker报错","date":"2022-07-31T22:15:06.000Z","updated":"2022-11-28T06:34:02.179Z","comments":true,"path":"2022/08/01/报错日常/docker报错/","link":"","permalink":"http://example.com/2022/08/01/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/docker%E6%8A%A5%E9%94%99/","excerpt":"","text":"运行docker-compose up -d 报错123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657ubuntu@ip-10-0-2-13:~/myapp/src$ docker-compose downWARNING: The VERSION_TAG variable is not set. Defaulting to a blank string.Traceback (most recent call last): File \"urllib3/connectionpool.py\", line 677, in urlopen File \"urllib3/connectionpool.py\", line 392, in _make_request File \"http/client.py\", line 1252, in request File \"http/client.py\", line 1298, in _send_request File \"http/client.py\", line 1247, in endheaders File \"http/client.py\", line 1026, in _send_output File \"http/client.py\", line 966, in send File \"docker/transport/unixconn.py\", line 43, in connectPermissionError: [Errno 13] Permission deniedDuring handling of the above exception, another exception occurred:Traceback (most recent call last): File \"requests/adapters.py\", line 449, in send File \"urllib3/connectionpool.py\", line 727, in urlopen File \"urllib3/util/retry.py\", line 403, in increment File \"urllib3/packages/six.py\", line 734, in reraise File \"urllib3/connectionpool.py\", line 677, in urlopen File \"urllib3/connectionpool.py\", line 392, in _make_request File \"http/client.py\", line 1252, in request File \"http/client.py\", line 1298, in _send_request File \"http/client.py\", line 1247, in endheaders File \"http/client.py\", line 1026, in _send_output File \"http/client.py\", line 966, in send File \"docker/transport/unixconn.py\", line 43, in connecturllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"docker/api/client.py\", line 205, in _retrieve_server_version File \"docker/api/daemon.py\", line 181, in version File \"docker/utils/decorators.py\", line 46, in inner File \"docker/api/client.py\", line 228, in _get File \"requests/sessions.py\", line 543, in get File \"requests/sessions.py\", line 530, in request File \"requests/sessions.py\", line 643, in send File \"requests/adapters.py\", line 498, in sendrequests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"bin/docker-compose\", line 3, in &lt;module&gt; File \"compose/cli/main.py\", line 67, in main File \"compose/cli/main.py\", line 123, in perform_command File \"compose/cli/command.py\", line 69, in project_from_options File \"compose/cli/command.py\", line 132, in get_project File \"compose/cli/docker_client.py\", line 43, in get_client File \"compose/cli/docker_client.py\", line 170, in docker_client File \"docker/api/client.py\", line 188, in __init__ File \"docker/api/client.py\", line 213, in _retrieve_server_versiondocker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))[19602] Failed to execute script docker-compose 解决方案 使用sudo usermod -aG docker $USER将您的用户添加到docker组，然后重启docker服务器 12sudo usermod -aG docker $USERsudo systemctl start docker","categories":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"SpringCloud基础02","slug":"笔记/技术/SpringCloud基础02","date":"2022-07-31T22:13:09.000Z","updated":"2022-11-28T06:32:10.899Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud基础02/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%9F%BA%E7%A1%8002/","excerpt":"","text":"SpringCloudEureka注册中心假如我们的服务提供者user-service部署了多个实例，如图： 大家思考几个问题： order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？ 有多个user-service实例地址，order-service调用时该如何选择？ order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ Eureka的结构和作用这些问题都需要利用SpringCloud中的注册中心来解决，其中最广为人知的注册中心就是Eureka，其结构如下： 回答之前的各个问题。 问题1：order-service如何得知user-service实例地址？ 获取地址信息的流程如下： user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。这个叫服务注册 eureka-server保存服务名称到服务实例地址列表的映射关系 order-service根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取 问题2：order-service如何从多个user-service实例中选择具体的实例？ order-service从实例列表中利用负载均衡算法选中一个实例地址 向该实例地址发起远程调用 问题3：order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？ user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态，称为心跳 当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除 order-service拉取服务时，就能将故障实例排除了 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端 因此，接下来我们动手实践的步骤包括： 搭建eureka-server首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务 创建eureka-server服务在cloud-demo父工程下，创建一个子模块： 填写模块信息： 然后填写服务信息： 引入eureka依赖引入SpringCloud为eureka提供的starter依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 编写启动类给eureka-server服务编写一个启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能： 12345678910111213package cn.itcast.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication { public static void main(String[] args) { SpringApplication.run(EurekaApplication.class, args); }} 编写配置文件编写一个application.yml文件，内容如下： 123456789server: port: 10086spring: application: name: eureka-servereureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 启动服务启动微服务，然后在浏览器访问：http://127.0.0.1:10086 看到下面结果应该是成功了： 服务注册下面，我们将user-service注册到eureka-server中去。 1）引入依赖在user-service的pom文件中，引入下面的eureka-client依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置文件在user-service中，修改application.yml文件，添加服务名称、eureka地址： 1234567spring: application: name: userserviceeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）启动多个user-service实例为了演示一个服务有多个实例的场景，我们添加一个SpringBoot的启动配置，再启动一个user-service。 首先，复制原来的user-service启动配置： 然后，在弹出的窗口中，填写信息： 现在，SpringBoot窗口会出现两个user-service启动配置： 不过，第一个是8081端口，第二个是8082端口。 启动两个user-service实例： 查看eureka-server管理页面： 服务发现下面，我们将order-service的逻辑修改：向eureka-server拉取user-service的信息，实现服务发现。 1）引入依赖之前说过，服务发现、服务注册统一都封装在eureka-client依赖，因此这一步与服务注册时一致。 在order-service的pom文件中，引入下面的eureka-client依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置文件服务发现也需要知道eureka地址，因此第二步与服务注册一致，都是配置eureka信息： 在order-service中，修改application.yml文件，添加服务名称、eureka地址： 1234567spring: application: name: orderserviceeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 3）服务拉取和负载均衡最后，我们要去eureka-server中拉取user-service服务的实例列表，并且实现负载均衡。 不过这些动作不用我们去做，只需要添加一些注解即可。 在order-service的OrderApplication中，给RestTemplate这个Bean添加一个@LoadBalanced注解： 修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法。修改访问的url路径，用服务名代替ip、端口： spring会自动帮助我们从eureka-server端，根据userservice这个服务名称，获取实例列表，而后完成负载均衡。 Ribbon负载均衡上一节中，我们添加了@LoadBalanced注解，即可实现负载均衡功能，这是什么原理呢？ 负载均衡原理SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。 那么我们发出的请求明明是http://userservice/user/1，怎么变成了http://localhost:8081的呢？ 源码跟踪为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。 显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是LoadBalancerInterceptor，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。 我们进行源码跟踪： 1）LoadBalancerIntercepor 可以看到这里的intercept方法，拦截了用户的HttpRequest请求，然后做了几件事： request.getURI()：获取请求uri，本例中就是 http://user-service/user/8 originalUri.getHost()：获取uri路径的主机名，其实就是服务id，user-service this.loadBalancer.execute()：处理服务id，和用户请求。 这里的this.loadBalancer是LoadBalancerClient类型，我们继续跟入。 2）LoadBalancerClient继续跟入execute方法： 代码是这样的： getLoadBalancer(serviceId)：根据服务id获取ILoadBalancer，而ILoadBalancer会拿着服务id去eureka中获取服务列表并保存起来。 getServer(loadBalancer)：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8082端口的服务 放行后，再次访问并跟踪，发现获取的是8081： 果然实现了负载均衡。 3）负载均衡策略IRule在刚才的代码中，可以看到获取服务使通过一个getServer方法来做负载均衡: 我们继续跟入： 继续跟踪源码chooseServer方法，发现这么一段代码： 我们看看这个rule是谁： 这里的rule默认值是一个RoundRobinRule，看类的介绍： 这不就是轮询的意思嘛。 到这里，整个负载均衡的流程我们就清楚了。 4）总结SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下： 基本流程如下： 拦截我们的RestTemplate请求http://userservice/user/1 RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表 eureka返回列表，localhost:8081、localhost:8082 IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081 RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求 负载均衡策略负载均衡策略负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类： 不同规则的含义如下： 内置负载均衡规则类 规则描述 RoundRobinRule 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 AvailabilityFilteringRule 对以下两种服务器进行忽略： （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。 （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 WeightedResponseTimeRule 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 ZoneAvoidanceRule 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 BestAvailableRule 忽略那些短路的服务器，并选择并发数较低的服务器。 RandomRule 随机选择一个可用的服务器。 RetryRule 重试机制的选择逻辑 默认的实现就是ZoneAvoidanceRule，是一种轮询方案 自定义负载均衡策略通过定义IRule实现可以修改负载均衡规则，有两种方式： 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule： 1234@Beanpublic IRule randomRule(){ return new RandomRule();} 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则： 123userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 注意，一般用默认的负载均衡规则，不做修改。 饥饿加载Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。 而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载： 1234ribbon: eager-load: enabled: true clients: userservice Nacos注册中心国内公司一般都推崇阿里巴巴的技术，比如注册中心，SpringCloudAlibaba也推出了一个名为Nacos的注册中心。 认识和安装NacosNacos是阿里巴巴的产品，现在是SpringCloud中的一个组件。相比Eureka功能更加丰富，在国内受欢迎程度较高。 服务注册到nacosNacos是SpringCloudAlibaba的组件，而SpringCloudAlibaba也遵循SpringCloud中定义的服务注册、服务发现规范。因此使用Nacos和使用Eureka对于微服务来说，并没有太大区别。 主要差异在于： 依赖不同 服务地址不同 1）引入依赖在cloud-demo父工程的pom文件中的&lt;dependencyManagement&gt;中引入SpringCloudAlibaba的依赖： 1234567&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 然后在user-service和order-service中的pom文件中引入nacos-discovery依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 注意：不要忘了注释掉eureka的依赖。 2）配置nacos地址在user-service和order-service的application.yml中添加nacos地址： 1234spring: cloud: nacos: server-addr: localhost:8848 注意：不要忘了注释掉eureka的地址 3）重启重启微服务后，登录nacos管理页面，可以看到微服务信息： 服务分级存储模型一个服务可以有多个实例，例如我们的user-service，可以有: 127.0.0.1:8081 127.0.0.1:8082 127.0.0.1:8083 假如这些实例分布于全国各地的不同机房，例如： 127.0.0.1:8081，在上海机房 127.0.0.1:8082，在上海机房 127.0.0.1:8083，在杭州机房 Nacos就将同一机房内的实例 划分为一个集群。 也就是说，user-service是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图： 微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如： 杭州机房内的order-service应该优先访问同机房的user-service。 给user-service配置集群修改user-service的application.yml文件，添加集群配置： 123456spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 重启两个user-service实例后，我们可以在nacos控制台看到下面结果： 我们再次复制一个user-service启动配置，添加属性： 1-Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH 配置如图所示： 启动UserApplication3后再次查看nacos控制台： 同集群优先的负载均衡默认的ZoneAvoidanceRule并不能实现根据同集群优先来实现负载均衡。 因此Nacos中提供了一个NacosRule的实现，可以优先从同集群中挑选实例。 1）给order-service配置集群信息 修改order-service的application.yml文件，添加集群配置： 123456spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ # 集群名称 2）修改负载均衡规则 修改order-service的application.yml文件，修改负载均衡规则： 123userservice: ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 权重配置实际部署中会出现这样的场景： 服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。 但默认情况下NacosRule是同集群内随机挑选，不会考虑机器的性能问题。 因此，Nacos提供了权重配置来控制访问频率，权重越大则访问频率越高。 在nacos控制台，找到user-service的实例列表，点击编辑，即可修改权重： 在弹出的编辑窗口，修改权重： 注意：如果权重修改为0，则该实例永远不会被访问 环境隔离Nacos提供了namespace来实现环境隔离功能。 nacos中可以有多个namespace namespace下可以有group、service等 不同namespace之间相互隔离，例如不同namespace的服务互相不可见 创建namespace默认情况下，所有service、data、group都在同一个namespace，名为public： 我们可以点击页面新增按钮，添加一个namespace： 然后，填写表单： 就能在页面看到一个新的namespace： 给微服务配置namespace给微服务配置namespace只能通过修改配置来实现。 例如，修改order-service的application.yml文件： 1234567spring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: HZ namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID 重启order-service后，访问控制台，可以看到下面的结果： 此时访问order-service，因为namespace不同，会导致找不到userservice，控制台会报错： Nacos与Eureka的区别Nacos的服务实例分为两种l类型： 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。 配置一个服务实例为永久实例： 12345spring: cloud: nacos: discovery: ephemeral: false # 设置为非临时实例 Nacos和Eureka整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异： Nacos与eureka的共同点 都支持服务注册和服务拉取 都支持服务提供者心跳方式做健康检测 Nacos与Eureka的区别 Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式 临时实例心跳不正常会被剔除，非临时实例则不会被剔除 Nacos支持服务列表变更的消息推送模式，服务列表更新更及时 Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"SpringCloud基础01","slug":"笔记/技术/SpringCloud基础01","date":"2022-07-31T22:12:09.000Z","updated":"2022-11-28T06:32:10.891Z","comments":true,"path":"2022/08/01/笔记/技术/SpringCloud基础01/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/SpringCloud%E5%9F%BA%E7%A1%8001/","excerpt":"","text":"SpringCloud认识微服务随着互联网行业的发展，对服务的要求也越来越高，服务架构也从单体架构逐渐演变为现在流行的微服务架构。这些架构之间有怎样的差别呢？ 单体架构单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。 单体架构的优缺点如下： 优点： 架构简单 部署成本低 缺点： 耦合度高（维护困难、升级困难） 分布式架构分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。 分布式架构的优缺点： 优点： 降低服务耦合 有利于服务升级和拓展 缺点： 服务调用关系错综复杂 分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考： 服务拆分的粒度如何界定？ 服务之间如何调用？ 服务的调用关系如何管理？ 人们需要制定一套行之有效的标准来约束分布式架构。 微服务微服务的架构特征： 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责 自治：团队独立、技术独立、数据独立，独立部署和交付 面向服务：服务提供统一标准的接口，与语言和技术无关 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题 微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。 因此，可以认为微服务是一种经过良好架构设计的分布式架构方案 。 但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。 其中在Java领域最引人注目的就是SpringCloud提供的方案了。 SpringCloudSpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。 SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。 其中常见的组件包括： 另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下： Hoxton.SR10对应的SpringBoot版本是2.3.x版本。 总结 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝 微服务：一种良好的分布式架构方案 ①优点：拆分粒度更小、服务更独立、耦合度更低 ②缺点：架构非常复杂，运维、监控、部署难度提高 SpringCloud是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件 服务拆分和远程调用任何分布式架构都离不开服务的拆分，微服务也是一样。 服务拆分原则这里我总结了微服务拆分时的几个原则： 不同微服务，不要重复开发相同业务 微服务数据独立，不要访问其它微服务的数据库 微服务可以将自己的业务暴露为接口，供其它微服务调用 服务拆分示例以课前资料中的微服务cloud-demo为例，其结构如下： cloud-demo：父工程，管理依赖 order-service：订单微服务，负责订单相关业务 user-service：用户微服务，负责用户相关业务 要求： 订单微服务和用户微服务都必须有各自的数据库，相互独立 订单服务和用户服务都对外暴露Restful的接口 订单服务如果需要查询用户信息，只能调用用户服务的Restful接口，不能查询用户数据库 导入Sql语句首先，将课前资料提供的cloud-order.sql和cloud-user.sql导入到mysql中： cloud-user表中初始数据如下： cloud-order表中初始数据如下： cloud-order表中持有cloud-user表中的id字段。 导入demo工程用IDEA导入课前资料提供的Demo： 项目结构如下： 导入后，会在IDEA右下角出现弹窗： 点击弹窗，然后按下图选择： 会出现这样的菜单： 配置下项目使用的JDK： 实现远程调用案例在order-service服务中，有一个根据id查询订单的接口： 根据id查询订单，返回值是Order对象，如图： 其中的user为null 在user-service中有一个根据id查询用户的接口： 查询的结果如图： 案例需求：修改order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。 因此，我们需要在order-service中 向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口。 大概的步骤是这样的： 注册一个RestTemplate的实例到Spring容器 修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User 将查询的User填充到Order对象，一起返回 注册RestTemplate首先，我们在order-service服务中的OrderApplication启动类中，注册RestTemplate实例： 123456789101112131415161718192021package cn.itcast.order;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@MapperScan(\"cn.itcast.order.mapper\")@SpringBootApplicationpublic class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); }} 实现远程调用修改order-service服务中的cn.itcast.order.service包下的OrderService类中的queryOrderById方法： 提供者与消费者在服务调用关系中，会有两个不同的角色： 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务） 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口） 但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。 如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？ 对于A调用B的业务而言：A是服务消费者，B是服务提供者 对于B调用C的业务而言：B是服务消费者，C是服务提供者 因此，服务B既可以是服务提供者，也可以是服务消费者。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"MyBatisPlus基础","slug":"笔记/技术/MyBatisPlus基础","date":"2022-07-31T22:11:09.000Z","updated":"2022-11-28T06:32:10.889Z","comments":true,"path":"2022/08/01/笔记/技术/MyBatisPlus基础/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/MyBatisPlus%E5%9F%BA%E7%A1%80/","excerpt":"","text":"MyBatisPlus简介入门案例问题导入MyBatisPlus环境搭建的步骤？ SpringBoot整合MyBatisPlus入门程序①：创建新模块，选择Spring初始化，并配置模块相关基础信息 ②：选择当前模块需要使用的技术集（仅保留JDBC） ③：手动添加MyBatisPlus起步依赖12345678910&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 注意事项1：由于mp并未被收录到idea的系统内置配置，无法直接选择加入 注意事项2：如果使用Druid数据源，需要导入对应坐标 注意事项3：mybatis的jar包和springboot整合mybatis的jar包已经导进去了 ④：制作实体类与表结构（类名与表名对应，属性名与字段名对应） 12345678910111213141516create database if not exists mybatisplus_db character set utf8;use mybatisplus_db;CREATE TABLE user ( id bigint(20) primary key auto_increment, name varchar(32) not null, password varchar(32) not null, age int(3) not null , tel varchar(32) not null);insert into user values(null,'tom','123456',12,'12345678910');insert into user values(null,'jack','123456',8,'12345678910');insert into user values(null,'jerry','123456',15,'12345678910');insert into user values(null,'tom','123456',9,'12345678910');insert into user values(null,'snake','123456',28,'12345678910');insert into user values(null,'张益达','123456',22,'12345678910');insert into user values(null,'张大炮','123456',16,'12345678910'); 12345678public class User { private Long id; private String name; private String password; private Integer age; private String tel; //自行添加getter、setter、toString()等方法} ⑤：设置Jdbc参数（application.yml）1234567spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root ⑥：定义数据接口，继承BaseMapper12345678910package com.itheima.dao;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.itheima.domain.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserDao extends BaseMapper&lt;User&gt; {} ⑦：测试类中注入dao接口，测试功能12345678910111213141516171819202122package com.itheima;import com.itheima.dao.UserDao;import com.itheima.domain.User;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.List;@SpringBootTestpublic class Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); }} MyBatisPlus概述问题导入通过入门案例制作，MyBatisPlus的优点有哪些？ MyBatis介绍 MyBatisPlus（简称MP）是基于MyBatis框架基础上开发的增强型工具，旨在简化开发、提高效率 官网：https://mybatis.plus/ https://mp.baomidou.com/ MyBatisPlus特性 无侵入：只做增强不做改变，不会对现有工程产生影响 强大的 CRUD 操作：内置通用 Mapper，少量配置即可实现单表CRUD 操作 支持 Lambda：编写查询条件无需担心字段写错 支持主键自动生成 内置分页插件 …… 标准数据层开发MyBatisPlus的CRUD操作 注意事项1：update提供哪些字段就修改哪些字段 注意事项2：对齐 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.itheima;import com.itheima.dao.UserDao;import com.itheima.domain.User;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.util.List;@SpringBootTestclass Mybatisplus01QuickstartApplicationTests { @Autowired private UserDao userDao; @Test void testSave() { User user = new User(); user.setName(\"黑马程序员\"); user.setPassword(\"itheima\"); user.setAge(12); user.setTel(\"4006184000\"); userDao.insert(user); } @Test void testDelete() { userDao.deleteById(1401856123725713409L); } @Test void testUpdate() { User user = new User(); user.setId(1L); user.setName(\"Tom888\"); user.setPassword(\"tom888\"); userDao.updateById(user); } @Test void testGetById() { User user = userDao.selectById(2L); System.out.println(user); } @Test void testGetAll() { List&lt;User&gt; userList = userDao.selectList(null); System.out.println(userList); }} Lombok插件介绍问题导入有什么简单的办法可以自动生成实体类的GET、SET方法？ Lombok，一个Java类库，提供了一组注解，简化POJO实体类开发。 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt;&lt;/dependency&gt; 常用注解：==@Data==，为当前实体类在编译期设置对应的get/set方法，无参/无参构造方法，toString方法，hashCode方法，equals方法等 123456789101112131415161718192021222324package com.itheima.domain;import lombok.*;/* 1 生成getter和setter方法：@Getter、@Setter 生成toString方法：@ToString 生成equals和hashcode方法：@EqualsAndHashCode 2 统一成以上所有：@Data 3 生成空参构造： @NoArgsConstructor 生成全参构造： @AllArgsConstructor 4 lombok还给我们提供了builder的方式创建对象,好处就是可以链式编程。 @Builder【扩展】 */@Datapublic class User { private Long id; private String name; private String password; private Integer age; private String tel;} MyBatisPlus分页功能问题导入思考一下Mybatis分页插件是如何用的？ 分页功能接口 MyBatisPlus分页使用①：设置分页拦截器作为Spring管理的bean 12345678910111213141516171819package com.itheima.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ //1 创建MybatisPlusInterceptor拦截器对象 MybatisPlusInterceptor mpInterceptor=new MybatisPlusInterceptor(); //2 添加分页拦截器 mpInterceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return mpInterceptor; }} ②：执行分页查询 1234567891011121314//分页查询@Testvoid testSelectPage(){ //1 创建IPage分页对象,设置分页参数 IPage&lt;User&gt; page=new Page&lt;&gt;(1,3); //2 执行分页查询 userDao.selectPage(page,null); //3 获取分页结果 System.out.println(\"当前页码值：\"+page.getCurrent()); System.out.println(\"每页显示数：\"+page.getSize()); System.out.println(\"总页数：\"+page.getPages()); System.out.println(\"总条数：\"+page.getTotal()); System.out.println(\"当前页数据：\"+page.getRecords());} 开启MyBatisPlus日志1234567891011spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC username: root password: root# 开启mp的日志（输出到控制台）mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 解决日志打印过多问题取消初始化spring日志打印 做法：在resources下新建一个logback.xml文件，名称固定，内容如下： 1234&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt;&lt;/configuration&gt; 关于logback参考播客：https://www.jianshu.com/p/75f9d11ae011 取消SpringBoot启动banner图标 123spring: main: banner-mode: off # 关闭SpringBoot启动图标(banner) 取消MybatisPlus启动banner图标 123456# mybatis-plus日志控制台输出mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: banner: off # 关闭mybatisplus启动图标 DQL编程控制条件查询方式 MyBatisPlus将书写复杂的SQL查询条件进行了封装，使用编程的形式完成查询条件的组合 条件查询方式一：按条件查询12345//方式一：按条件查询QueryWrapper&lt;User&gt; qw=new QueryWrapper&lt;&gt;();qw.lt(\"age\", 18);List&lt;User&gt; userList = userDao.selectList(qw);System.out.println(userList); 方式二：lambda格式按条件查询12345//方式二：lambda格式按条件查询QueryWrapper&lt;User&gt; qw = new QueryWrapper&lt;User&gt;();qw.lambda().lt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(qw);System.out.println(userList); 方式三：lambda格式按条件查询（推荐）12345//方式三：lambda格式按条件查询LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();lqw.lt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 组合条件并且关系（and）123456//并且关系LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//并且关系：10到30岁之间lqw.lt(User::getAge, 30).gt(User::getAge, 10);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 或者关系（or）123456//或者关系LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//或者关系：小于10岁或者大于30岁lqw.lt(User::getAge, 10).or().gt(User::getAge, 30);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); NULL值处理问题导入如下搜索场景，在多条件查询中，有条件的值为空应该怎么解决？ if语句控制条件追加1234567891011Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();if(minAge!=null){ lqw.gt(User::getAge, minAge);}if(maxAge!=null){ lqw.lt(User::getAge, maxAge);}List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 条件参数控制12345678Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//参数1：如果表达式为true，那么查询才使用该条件lqw.gt(minAge!=null,User::getAge, minAge);lqw.lt(maxAge!=null,User::getAge, maxAge);List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 条件参数控制（链式编程）12345678Integer minAge=10; //将来有用户传递进来,此处简化成直接定义变量了Integer maxAge=null; //将来有用户传递进来,此处简化成直接定义变量了LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//参数1：如果表达式为true，那么查询才使用该条件lqw.gt(minAge!=null,User::getAge, minAge) .lt(maxAge!=null,User::getAge, maxAge);List&lt;User&gt; userList = userDao.selectList(lqw);userList.forEach(System.out::println); 查询投影-设置【查询字段、分组、分页】查询结果包含模型类中部分属性1234567/*LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();lqw.select(User::getId, User::getName, User::getAge);*///或者QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;();lqw.select(\"id\", \"name\", \"age\", \"tel\");List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 查询结果包含模型类中未定义的属性12345QueryWrapper&lt;User&gt; lqw = new QueryWrapper&lt;User&gt;();lqw.select(\"count(*) as count, tel\");lqw.groupBy(\"tel\");List&lt;Map&lt;String, Object&gt;&gt; userList = userDao.selectMaps(lqw);System.out.println(userList); 查询条件设定问题导入多条件查询有哪些组合？ 范围匹配（&gt; 、 = 、between） 模糊匹配（like） 空判定（null） 包含性匹配（in） 分组（group） 排序（order） …… 查询条件 用户登录（eq匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//等同于=lqw.eq(User::getName, \"Jerry\").eq(User::getPassword, \"jerry\");User loginUser = userDao.selectOne(lqw);System.out.println(loginUser); 购物设定价格区间、户籍设定年龄区间（le ge匹配 或 between匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//范围查询 lt le gt ge eq betweenlqw.between(User::getAge, 10, 30);List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 查信息，搜索新闻（非全文检索版：like匹配） 12345LambdaQueryWrapper&lt;User&gt; lqw = new LambdaQueryWrapper&lt;User&gt;();//模糊匹配 likelqw.likeLeft(User::getName, \"J\");List&lt;User&gt; userList = userDao.selectList(lqw);System.out.println(userList); 统计报表（分组查询聚合函数） 12345QueryWrapper&lt;User&gt; qw = new QueryWrapper&lt;User&gt;();qw.select(\"gender\",\"count(*) as nums\");qw.groupBy(\"gender\");List&lt;Map&lt;String, Object&gt;&gt; maps = userDao.selectMaps(qw);System.out.println(maps); 查询API 更多查询条件设置参看 https://mybatis.plus/guide/wrapper.html#abstractwrapper 字段映射与表名映射问题导入思考表的字段和实体类的属性不对应，查询会怎么样？ 问题一：表字段与编码属性设计不同步 在模型类属性上方，使用**@TableField**属性注解，通过==value==属性，设置当前属性对应的数据库表中的字段关系。 问题二：编码中添加了数据库中未定义的属性 在模型类属性上方，使用**@TableField注解，通过==exist==**属性，设置属性在数据库表字段中是否存在，默认为true。此属性无法与value合并使用。 问题三：采用默认查询开放了更多的字段查看权限 在模型类属性上方，使用**@TableField注解，通过==select==**属性：设置该属性是否参与查询。此属性与select()映射配置不冲突。 问题四：表名与编码开发设计不同步 在模型类上方，使用**@TableName注解，通过==value==**属性，设置当前类对应的数据库表名称。 12345678910111213141516@Data@TableName(\"tbl_user\")public class User { /* id为Long类型，因为数据库中id为bigint类型， 并且mybatis有自己的一套id生成方案，生成出来的id必须是Long类型 */ private Long id; private String name; @TableField(value = \"pwd\",select = false) private String password; private Integer age; private String tel; @TableField(exist = false) //表示online字段不参与CRUD操作 private Boolean online;} DML编程控制id生成策略控制（Insert）问题导入主键生成的策略有哪几种方式？ 不同的表应用不同的id生成策略 日志：自增（1,2,3,4，……） 购物订单：特殊规则（FQ23948AK3843） 外卖单：关联地区日期等信息（10 04 20200314 34 91） 关系表：可省略id …… id生成策略控制（@TableId注解） 名称：@TableId 类型：属性注解 位置：模型类中用于表示主键的属性定义上方 作用：设置当前类中主键属性的生成策略 相关属性 ​ type：设置主键属性的生成策略，值参照IdType枚举值 全局策略配置12345mybatis-plus: global-config: db-config: id-type: assign_id table-prefix: tbl_ id生成策略全局配置 表名前缀全局配置 多记录操作（批量Delete/Select）问题导入MyBatisPlus是否支持批量操作？ 按照主键删除多条记录1234567//删除指定多条数据List&lt;Long&gt; list = new ArrayList&lt;&gt;();list.add(1402551342481838081L);list.add(1402553134049501186L);list.add(1402553619611430913L);userDao.deleteBatchIds(list); 根据主键查询多条记录123456//查询指定多条数据List&lt;Long&gt; list = new ArrayList&lt;&gt;();list.add(1L);list.add(3L);list.add(4L);userDao.selectBatchIds(list); 逻辑删除（Delete/Update）问题导入在实际环境中，如果想删除一条数据，是否会真的从数据库中删除该条数据？ 删除操作业务问题：业务数据从数据库中丢弃 逻辑删除：为数据设置是否可用状态字段，删除时设置状态字段为不可用状态，数据保留在数据库中 逻辑删除案例①：数据库表中添加逻辑删除标记字段 ②：实体类中添加对应字段，并设定当前字段为逻辑删除标记字段12345678910111213141516package com.itheima.domain;import com.baomidou.mybatisplus.annotation.*;import lombok.Data;@Datapublic class User { private Long id; //逻辑删除字段，标记当前记录是否被删除 @TableLogic private Integer deleted; } ③：配置逻辑删除字面值12345678910mybatis-plus: global-config: db-config: table-prefix: tbl_ # 逻辑删除字段名 logic-delete-field: deleted # 逻辑删除字面值：未删除为0 logic-not-delete-value: 0 # 逻辑删除字面值：删除为1 logic-delete-value: 1 逻辑删除本质：逻辑删除的本质其实是修改操作。如果加了逻辑删除字段，查询数据时也会自动带上逻辑删除字段。 乐观锁（Update）问题导入乐观锁主张的思想是什么？ 业务并发现象带来的问题：秒杀 乐观锁案例①：数据库表中添加锁标记字段 ②：实体类中添加对应字段，并设定当前字段为逻辑删除标记字段12345678910111213141516package com.itheima.domain;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableLogic;import com.baomidou.mybatisplus.annotation.Version;import lombok.Data;@Datapublic class User { private Long id; @Version private Integer version;} ③：配置乐观锁拦截器实现锁机制对应的动态SQL语句拼装12345678910111213141516171819202122package com.itheima.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MpConfig { @Bean public MybatisPlusInterceptor mpInterceptor() { //1.定义Mp拦截器 MybatisPlusInterceptor mpInterceptor = new MybatisPlusInterceptor(); //2.添加乐观锁拦截器 mpInterceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return mpInterceptor; }} ④：使用乐观锁机制在修改前必须先获取到对应数据的verion方可正常进行12345678910111213141516171819202122@Testpublic void testUpdate() { /*User user = new User(); user.setId(3L); user.setName(\"Jock666\"); user.setVersion(1); userDao.updateById(user);*/ //1.先通过要修改的数据id将当前数据查询出来 //User user = userDao.selectById(3L); //2.将要修改的属性逐一设置进去 //user.setName(\"Jock888\"); //userDao.updateById(user); //1.先通过要修改的数据id将当前数据查询出来 User user = userDao.selectById(3L); //version=3 User user2 = userDao.selectById(3L); //version=3 user2.setName(\"Jock aaa\"); userDao.updateById(user2); //version=&gt;4 user.setName(\"Jock bbb\"); userDao.updateById(user); //verion=3?条件还成立吗？} 快速开发-代码生成器问题导入如果只给一张表的字段信息，能够推演出Domain、Dao层的代码？ MyBatisPlus提供模板 Mapper接口模板 实体对象类模板 工程搭建和基本代码编写 第一步：创建SpringBoot工程，添加代码生成器相关依赖，其他依赖自行添加 12345678910111213&lt;!--代码生成器--&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--velocity模板引擎--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt; 第二步：编写代码生成器类 1234567891011121314151617181920212223package com.itheima;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.config.DataSourceConfig;public class Generator { public static void main(String[] args) { //1. 创建代码生成器对象，执行生成代码操作 AutoGenerator autoGenerator = new AutoGenerator(); //2. 数据源相关配置：读取数据库中的信息，根据数据库表结构生成代码 DataSourceConfig dataSource = new DataSourceConfig(); dataSource.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost:3306/mybatisplus_db?serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"root\"); autoGenerator.setDataSource(dataSource); //3. 执行生成操作 autoGenerator.execute(); }} 开发者自定义配置 设置全局配置 123456789//设置全局配置GlobalConfig globalConfig = new GlobalConfig();globalConfig.setOutputDir(System.getProperty(\"user.dir\")+\"/mybatisplus_04_generator/src/main/java\"); //设置代码生成位置globalConfig.setOpen(false); //设置生成完毕后是否打开生成代码所在的目录globalConfig.setAuthor(\"黑马程序员\"); //设置作者globalConfig.setFileOverride(true); //设置是否覆盖原始生成的文件globalConfig.setMapperName(\"%sDao\"); //设置数据层接口名，%s为占位符，指代模块名称globalConfig.setIdType(IdType.ASSIGN_ID); //设置Id生成策略autoGenerator.setGlobalConfig(globalConfig); 设置包名相关配置 123456//设置包名相关配置PackageConfig packageInfo = new PackageConfig();packageInfo.setParent(\"com.aaa\"); //设置生成的包名，与代码所在位置不冲突，二者叠加组成完整路径packageInfo.setEntity(\"domain\"); //设置实体类包名packageInfo.setMapper(\"dao\"); //设置数据层包名autoGenerator.setPackageInfo(packageInfo); 策略设置 123456789//策略设置StrategyConfig strategyConfig = new StrategyConfig();strategyConfig.setInclude(\"tbl_user\"); //设置当前参与生成的表名，参数为可变参数strategyConfig.setTablePrefix(\"tbl_\"); //设置数据库表的前缀名称，模块名 = 数据库表名 - 前缀名 例如： User = tbl_user - tbl_strategyConfig.setRestControllerStyle(true); //设置是否启用Rest风格strategyConfig.setVersionFieldName(\"version\"); //设置乐观锁字段名strategyConfig.setLogicDeleteFieldName(\"deleted\"); //设置逻辑删除字段名strategyConfig.setEntityLombokModel(true); //设置是否启用lombokautoGenerator.setStrategy(strategyConfig); 说明：在资料中也提供了CodeGenerator代码生成器类，根据实际情况修改后可以直接使用。","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"MyBatisPlus","slug":"MyBatisPlus","permalink":"http://example.com/tags/MyBatisPlus/"}]},{"title":"Redis基础","slug":"笔记/技术/Redis基础","date":"2022-07-31T22:10:09.000Z","updated":"2022-11-28T06:32:10.896Z","comments":true,"path":"2022/08/01/笔记/技术/Redis基础/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Redis%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Redis基础前言什么是RedisRedis是一个基于内存的key-value结构数据库。Redis 是互联网技术领域使用最为广泛的存储中间件，它是「Remote Dictionary Service」的首字母缩写，也就是「远程字典服务」。 基于内存存储，读写性能高 适合存储热点数据（热点商品、资讯、新闻） 企业应用广泛 使用Redis能做什么 数据缓存 消息队列 注册中心 发布订阅 Redis入门Redis简介Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker. 翻译为：Redis是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。 官网：https://redis.io Redis是用C语言开发的一个开源的高性能键值对(key-value)数据库，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。它存储的value类型比较丰富，也被称为结构化的NoSql数据库。 NoSql（Not Only SQL），不仅仅是SQL，泛指非关系型数据库。NoSql数据库并不是要取代关系型数据库，而是关系型数据库的补充。 关系型数据库(RDBMS)： Mysql Oracle DB2 SQLServer 非关系型数据库(NoSql)： Redis Mongo db MemCached Redis数据类型介绍Redis存储的是key-value结构的数据，其中key是字符串类型，value有5种常用的数据类型： 字符串 string 哈希 hash 列表 list 集合 set 有序集合 sorted set / zset Redis 5种常用数据类型 解释说明： 字符串(string)：普通字符串，常用 哈希(hash)：适合存储对象 列表(list)：按照插入顺序排序，可以有重复元素 集合(set)：无序集合，没有重复元素 有序集合(sorted set / zset)：集合中每个元素关联一个分数（score），根据分数升序排序，没有重复元素 Redis常用命令字符串string操作命令Redis 中字符串类型常用命令： SET key value 设置指定key的值 GET key 获取指定key的值 SETEX key seconds value 设置指定key的值，并将 key 的过期时间设为 seconds 秒 SETNX key value 只有在 key 不存在时设置 key 的值 更多命令可以参考Redis中文网：https://www.redis.net.cn 哈希hash操作命令Redis hash 是一个string类型的 field 和 value 的映射表，hash特别适合用于存储对象，常用命令： HSET key field value 将哈希表 key 中的字段 field 的值设为 value HGET key field 获取存储在哈希表中指定字段的值 HDEL key field 删除存储在哈希表中的指定字段 HKEYS key 获取哈希表中所有字段 HVALS key 获取哈希表中所有值 HGETALL key 获取在哈希表中指定 key 的所有字段和值 列表list操作命令Redis 列表是简单的字符串列表，按照插入顺序排序，常用命令： LPUSH key value1 [value2] 将一个或多个值插入到列表头部 LRANGE key start stop 获取列表指定范围内的元素 RPOP key 移除并获取列表最后一个元素 LLEN key 获取列表长度 BRPOP key1 [key2 ] timeout 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超 时或发现可弹出元素为止 集合set操作命令Redis set 是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据，常用命令： SADD key member1 [member2] 向集合添加一个或多个成员 SMEMBERS key 返回集合中的所有成员 SCARD key 获取集合的成员数 SINTER key1 [key2] 返回给定所有集合的交集 SUNION key1 [key2] 返回所有给定集合的并集 SDIFF key1 [key2] 返回给定所有集合的差集 SREM key member1 [member2] 移除集合中一个或多个成员 有序集合sorted set操作命令Redis sorted set 有序集合是 string 类型元素的集合，且不允许重复的成员。每个元素都会关联一个double类型的分数(score) 。redis正是通过分数来为集合中的成员进行从小到大排序。有序集合的成员是唯一的，但分数却可以重复。 常用命令： ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的 分数 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合中指定区间内的成员 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量 increment ZREM key member [member …] 移除有序集合中的一个或多个成员 通用命令Redis中的通用命令，主要是针对key进行操作的相关命令： KEYS pattern 查找所有符合给定模式( pattern)的 key EXISTS key 检查给定 key 是否存在 TYPE key 返回 key 所储存的值的类型 TTL key 返回给定 key 的剩余生存时间(TTL, time to live)，以秒为单位 DEL key 该命令用于在 key 存在是删除 key 在Java中操作Redis介绍前面我们讲解了Redis的常用命令，这些命令是我们操作Redis的基础，那么我们在java程序中应该如何操作Redis呢？这就需要使用Redis的Java客户端，就如同我们使用JDBC操作MySQL数据库一样。 Redis 的 Java 客户端很多，官方推荐的有三种： Jedis Lettuce Redisson Spring 对 Redis 客户端进行了整合，提供了 Spring Data Redis，在Spring Boot项目中还提供了对应的Starter，即 spring-boot-starter-data-redis。 JedisJedis 是 Redis 的 Java 版本的客户端实现。 maven坐标： 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 使用 Jedis 操作 Redis 的步骤： 获取连接 执行操作 关闭连接 示例代码： 12345678910111213141516171819202122232425262728293031323334353637package com.itheima.test;import org.junit.Test;import redis.clients.jedis.Jedis;import java.util.Set;/** * 使用Jedis操作Redis */public class JedisTest { @Test public void testRedis(){ //1 获取连接 Jedis jedis = new Jedis(\"localhost\",6379); //2 执行具体的操作 jedis.set(\"username\",\"xiaoming\"); String value = jedis.get(\"username\"); System.out.println(value); //jedis.del(\"username\"); jedis.hset(\"myhash\",\"addr\",\"bj\"); String hValue = jedis.hget(\"myhash\", \"addr\"); System.out.println(hValue); Set&lt;String&gt; keys = jedis.keys(\"*\"); for (String key : keys) { System.out.println(key); } //3 关闭连接 jedis.close(); }} Spring Data Redis介绍Spring Data Redis 是 Spring 的一部分，提供了在 Spring 应用中通过简单的配置就可以访问 Redis 服务，对 Redis 底层开发包进行了高度封装。在 Spring 项目中，可以使用Spring Data Redis来简化 Redis 操作。 网址：https://spring.io/projects/spring-data-redis maven坐标： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.4.8&lt;/version&gt;&lt;/dependency&gt; Spring Boot提供了对应的Starter，maven坐标： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Spring Data Redis中提供了一个高度封装的类：RedisTemplate，针对 Jedis 客户端中大量api进行了归类封装,将同一类型操作封装为operation接口，具体分类如下： ValueOperations：简单K-V操作 SetOperations：set类型数据操作 ZSetOperations：zset类型数据操作 HashOperations：针对hash类型的数据操作 ListOperations：针对list类型的数据操作 使用方式环境搭建第一步：创建maven项目springdataredis_demo，配置pom.xml文件 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;com.itheima&lt;/groupId&gt; &lt;artifactId&gt;springdataredis_demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 第二步：编写启动类 12345678910111213package com.itheima;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class App { public static void main(String[] args) { SpringApplication.run(App.class,args); }} 第三步：配置application.yml 12345678910111213141516spring: application: name: springdataredis_demo #Redis相关配置 redis: host: localhost port: 6379 #password: 123456 database: 0 #操作的是0号数据库 jedis: #Redis连接池配置 pool: max-active: 8 #最大连接数 max-wait: 1ms #连接池最大阻塞等待时间 max-idle: 4 #连接池中的最大空闲连接 min-idle: 0 #连接池中的最小空闲连接 解释说明： spring.redis.database：指定使用Redis的哪个数据库，Redis服务启动后默认有16个数据库，编号分别是从0到15。 可以通过修改Redis配置文件来指定数据库的数量。 第四步：提供配置类 123456789101112131415161718192021222324252627282930package com.itheima.config;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * Redis配置类 */@Configurationpublic class RedisConfig extends CachingConfigurerSupport { @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) { RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); //默认的Key序列化器为：JdkSerializationRedisSerializer redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; }} 解释说明： 当前配置类不是必须的，因为 Spring Boot 框架会自动装配 RedisTemplate 对象，但是默认的key序列化器为JdkSerializationRedisSerializer，导致我们存到Redis中后的数据和原始数据有差别 第五步：提供测试类 123456789101112131415package com.itheima.test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@SpringBootTest@RunWith(SpringRunner.class)public class SpringDataRedisTest { @Autowired private RedisTemplate redisTemplate; } 操作字符串类型数据12345678910111213141516171819/** * 操作String类型数据*/@Testpublic void testString(){ //存值 redisTemplate.opsForValue().set(\"city123\",\"beijing\"); //取值 String value = (String) redisTemplate.opsForValue().get(\"city123\"); System.out.println(value); //存值，同时设置过期时间 redisTemplate.opsForValue().set(\"key1\",\"value1\",10l, TimeUnit.SECONDS); //存值，如果存在则不执行任何操作 Boolean aBoolean = redisTemplate.opsForValue().setIfAbsent(\"city1234\", \"nanjing\"); System.out.println(aBoolean);} 操作哈希类型数据12345678910111213141516171819202122232425262728/** * 操作Hash类型数据*/@Testpublic void testHash(){ HashOperations hashOperations = redisTemplate.opsForHash(); //存值 hashOperations.put(\"002\",\"name\",\"xiaoming\"); hashOperations.put(\"002\",\"age\",\"20\"); hashOperations.put(\"002\",\"address\",\"bj\"); //取值 String age = (String) hashOperations.get(\"002\", \"age\"); System.out.println(age); //获得hash结构中的所有字段 Set keys = hashOperations.keys(\"002\"); for (Object key : keys) { System.out.println(key); } //获得hash结构中的所有值 List values = hashOperations.values(\"002\"); for (Object value : values) { System.out.println(value); }} 操作列表类型数据1234567891011121314151617181920212223242526/** * 操作List类型的数据*/@Testpublic void testList(){ ListOperations listOperations = redisTemplate.opsForList(); //存值 listOperations.leftPush(\"mylist\",\"a\"); listOperations.leftPushAll(\"mylist\",\"b\",\"c\",\"d\"); //取值 List&lt;String&gt; mylist = listOperations.range(\"mylist\", 0, -1); for (String value : mylist) { System.out.println(value); } //获得列表长度 llen Long size = listOperations.size(\"mylist\"); int lSize = size.intValue(); for (int i = 0; i &lt; lSize; i++) { //出队列 String element = (String) listOperations.rightPop(\"mylist\"); System.out.println(element); }} 操作集合类型数据1234567891011121314151617181920212223242526/** * 操作Set类型的数据*/@Testpublic void testSet(){ SetOperations setOperations = redisTemplate.opsForSet(); //存值 setOperations.add(\"myset\",\"a\",\"b\",\"c\",\"a\"); //取值 Set&lt;String&gt; myset = setOperations.members(\"myset\"); for (String o : myset) { System.out.println(o); } //删除成员 setOperations.remove(\"myset\",\"a\",\"b\"); //取值 myset = setOperations.members(\"myset\"); for (String o : myset) { System.out.println(o); }} 操作有序集合类型数据12345678910111213141516171819202122232425262728293031323334353637/** * 操作ZSet类型的数据*/@Testpublic void testZset(){ ZSetOperations zSetOperations = redisTemplate.opsForZSet(); //存值 zSetOperations.add(\"myZset\",\"a\",10.0); zSetOperations.add(\"myZset\",\"b\",11.0); zSetOperations.add(\"myZset\",\"c\",12.0); zSetOperations.add(\"myZset\",\"a\",13.0); //取值 Set&lt;String&gt; myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); } //修改分数 zSetOperations.incrementScore(\"myZset\",\"b\",20.0); //取值 myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); } //删除成员 zSetOperations.remove(\"myZset\",\"a\",\"b\"); //取值 myZset = zSetOperations.range(\"myZset\", 0, -1); for (String s : myZset) { System.out.println(s); }} 通用操作1234567891011121314151617181920212223/** * 通用操作，针对不同的数据类型都可以操作*/@Testpublic void testCommon(){ //获取Redis中所有的key Set&lt;String&gt; keys = redisTemplate.keys(\"*\"); for (String key : keys) { System.out.println(key); } //判断某个key是否存在 Boolean itcast = redisTemplate.hasKey(\"itcast\"); System.out.println(itcast); //删除指定key redisTemplate.delete(\"myZset\"); //获取指定key对应的value的数据类型 DataType dataType = redisTemplate.type(\"myset\"); System.out.println(dataType.name());}","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"docker基础使用","slug":"笔记/技术/Docker实用篇","date":"2022-07-31T22:07:08.000Z","updated":"2022-11-28T06:32:10.887Z","comments":true,"path":"2022/08/01/笔记/技术/Docker实用篇/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/","excerpt":"","text":"Docker实用篇学习目标初识Docker什么是Docker微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。 分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。 在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题 应用部署的环境问题大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题： 依赖关系复杂，容易出现兼容性问题 开发、测试、生产环境有差异 例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。 Docker解决依赖兼容问题而Docker确巧妙的解决了这些问题，Docker是如何实现的呢？ Docker为了解决依赖的兼容问题的，采用了两个手段： 将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包 将每个应用放到一个隔离容器去运行，避免互相干扰 这样打包好的应用包中，既包含应用本身，也保护应用所需要的Libs、Deps，无需再操作系统上安装这些，自然就不存在不同应用之间的兼容问题了。 虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？ Docker解决操作系统环境差异要解决不同操作系统环境差异问题，必须先了解操作系统结构。以一个Ubuntu操作系统为例，结构如下： 结构包括： 计算机硬件：例如CPU、内存、磁盘等 系统内核：所有Linux发行版的内核都是Linux，例如CentOS、Ubuntu、Fedora等。内核可以与计算机硬件交互，对外提供内核指令，用于操作计算机硬件。 系统应用：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。 应用于计算机交互的流程如下： 1）应用调用操作系统应用（函数库），实现各种功能 2）系统函数库是对内核指令集的封装，会调用内核指令 3）内核指令操作计算机硬件 Ubuntu和CentOSpringBoot都是基于Linux内核，无非是系统应用不同，提供的函数库有差异： 此时，如果将一个Ubuntu版本的MySQL应用安装到CentOS系统，MySQL在调用Ubuntu函数库时，会发现找不到或者不匹配，就会报错了： Docker如何解决不同系统环境的问题？ Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包 Docker运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的Linux内核来运行 如图： 小结Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？ Docker允许开发中将应用、依赖、函数库、配置一起打包，形成可移植镜像 Docker应用运行在容器中，使用沙箱机制，相互隔离 Docker如何解决开发、测试、生产环境有差异的问题？ Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行 Docker是一个快速交付应用、运行应用的技术，具备下列优势： 可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统 运行时利用沙箱机制形成隔离容器，各个应用互不干扰 启动、移除都可以通过一行命令完成，方便快捷 Docker和虚拟机的区别Docker可以让一个应用在任何操作系统中非常方便的运行。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。 两者有什么差异呢？ 虚拟机（virtual machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。 Docker仅仅是封装函数库，并没有模拟完整的操作系统，如图： 对比来看： 小结： Docker和虚拟机的差异： docker是一个系统进程；虚拟机是在操作系统中的操作系统 docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般 Docker架构镜像和容器Docker中有几个重要的概念： 镜像（Image）：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。 容器（Container）：镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器进程做隔离，对外不可见。 一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的文件。只有运行时，才会加载到内存，形成进程。 而镜像，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。 容器呢，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。因此一个镜像可以启动多次，形成多个容器进程。 例如你下载了一个QQ，如果我们将QQ在磁盘上的运行文件及其运行的操作系统依赖打包，形成QQ镜像。然后你可以启动多次，双开、甚至三开QQ，跟多个妹子聊天。 DockerHub开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。 DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。 国内也有类似于DockerHub 的公开服务，比如 网易云镜像服务、阿里云镜像库等。 我们一方面可以将自己的镜像共享到DockerHub，另一方面也可以从DockerHub拉取镜像： Docker架构我们要使用Docker来操作镜像、容器，就必须要安装Docker。 Docker是一个CS架构的程序，由两部分组成： 服务端(server)：Docker守护进程，负责处理Docker指令，管理镜像、容器等 客户端(client)：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。 如图： 小结镜像： 将应用程序及其依赖、环境、配置打包在一起 容器： 镜像运行起来就是容器，一个镜像可以运行多个容器 Docker结构： 服务端：接收命令或远程请求，操作镜像或容器 客户端：发送命令或者请求到Docker服务端 DockerHub： 一个镜像托管的服务器，类似的还有阿里云镜像服务，统称为DockerRegistry Docker的基本操作镜像操作镜像名称首先来看下镜像的名称组成： 镜名称一般分两部分组成：[repository]:[tag]。 在没有指定tag时，默认是latest，代表最新版本的镜像 如图： 这里的mysql就是repository，5.7就是tag，合一起就是镜像名称，代表5.7版本的MySQL镜像。 镜像命令常见的镜像操作命令如图： 案例1-拉取、查看镜像需求：从DockerHub中拉取一个nginx镜像并查看 1）首先去镜像仓库搜索nginx镜像，比如DockerHub: 2）根据查看到的镜像名称，拉取自己需要的镜像，通过命令：docker pull nginx 3）通过命令：docker images 查看拉取到的镜像 案例2-保存、导入镜像需求：利用docker save将nginx镜像导出磁盘，然后再通过load加载回来 1）利用docker xx –help命令查看docker save和docker load的语法 例如，查看save命令用法，可以输入命令： 1docker save --help 结果： 命令格式： 1docker save -o [保存的目标文件名称] [镜像名称] 2）使用docker save导出镜像到磁盘 运行命令： 1docker save -o nginx.tar nginx:latest 结果如图： 3）使用docker load加载镜像 先删除本地的nginx镜像： 1docker rmi nginx:latest 然后运行命令，加载本地文件： 1docker load -i nginx.tar 结果： 容器操作容器相关命令容器操作的命令如图： 容器保护三个状态： 运行：进程正常运行 暂停：进程暂停，CPU不再运行，并不释放内存 停止：进程终止，回收进程占用的内存、CPU等资源 其中： docker run：创建并运行一个容器，处于运行状态 docker pause：让一个运行的容器暂停 docker unpause：让一个容器从暂停状态恢复运行 docker stop：停止一个运行的容器 docker start：让一个停止的容器再次运行 docker rm：删除一个容器 案例-创建并运行一个容器创建并运行nginx容器的命令： 1docker run --name containerName -p 80:80 -d nginx 命令解读： docker run ：创建并运行一个容器 –name : 给容器起一个名字，比如叫做mn -p ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口 -d：后台运行容器 nginx：镜像名称，例如nginx 这里的-p参数，是将容器端口映射到宿主机端口。 默认情况下，容器是隔离环境，我们直接访问宿主机的80端口，肯定访问不到容器中的nginx。 现在，将容器的80与宿主机的80关联起来，当我们访问宿主机的80端口时，就会被映射到容器的80，这样就能访问到nginx了： 案例-进入容器，修改文件需求：进入Nginx容器，修改HTML文件内容，添加“传智教育欢迎您” 提示：进入容器要用到docker exec命令。 步骤： 1）进入容器。进入我们刚刚创建的nginx容器的命令为： 1docker exec -it mn bash 命令解读： docker exec ：进入容器内部，执行一个命令 -it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互 mn ：要进入的容器的名称 bash：进入容器后执行的命令，bash是一个linux终端交互命令 2）进入nginx的HTML所在目录 /usr/share/nginx/html 容器内部会模拟一个独立的Linux文件系统，看起来如同一个linux服务器一样： nginx的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的html文件。 查看DockerHub网站中的nginx页面，可以知道nginx的html目录位置在/usr/share/nginx/html 我们执行命令，进入该目录： 1cd /usr/share/nginx/html 查看目录下文件： 3）修改index.html的内容 容器内没有vi命令，无法直接修改，我们用下面的命令来修改： 1sed -i -e 's#Welcome to nginx#传智教育欢迎您#g' -e 's#&lt;head&gt;#&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;#g' index.html 在浏览器访问自己的虚拟机地址，例如我的是：http://192.168.150.101，即可看到结果： 小结docker run命令的常见参数有哪些？ –name：指定容器名称 -p：指定端口映射 -d：让容器后台运行 查看容器日志的命令： docker logs 添加 -f 参数可以持续查看日志 查看容器状态： docker ps docker ps -a 查看所有容器，包括已经停止的 数据卷（容器数据管理）在之前的nginx案例中，修改nginx的html页面时，需要进入nginx内部。并且因为没有编辑器，修改文件也很麻烦。 这就是因为容器与数据（容器内文件）耦合带来的后果。 要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。 什么是数据卷数据卷（volume）是一个虚拟目录，指向宿主机文件系统中的某个目录。 一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。 这样，我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了 数据集操作命令数据卷操作的基本语法如下： 1docker volume [COMMAND] docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作： create 创建一个volume inspect 显示一个或多个volume的信息 ls 列出所有的volume prune 删除未使用的volume rm 删除一个或多个指定的volume 创建和查看数据卷需求：创建一个数据卷，并查看数据卷在宿主机的目录位置 ① 创建数据卷 1docker volume create html ② 查看所有数据 1docker volume ls 结果： ③ 查看数据卷详细信息卷 1docker volume inspect html 结果： 可以看到，我们创建的html这个数据卷关联的宿主机目录为/var/lib/docker/volumes/html/_data目录。 小结： 数据卷的作用： 将容器与数据分离，解耦合，方便操作容器内数据，保证数据安全 数据卷操作： docker volume create：创建数据卷 docker volume ls：查看所有数据卷 docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置 docker volume rm：删除指定数据卷 docker volume prune：删除所有未使用的数据卷 挂载数据卷我们在创建容器时，可以通过 -v 参数来挂载一个数据卷到某个容器内目录，命令格式如下： 12345docker run \\ --name mn \\ -v html:/root/html \\ -p 82:80 nginx \\ 这里的-v就是挂载数据卷的命令： -v html:/root/htm ：把html数据卷挂载到容器内的/root/html这个目录中 案例-给nginx挂载数据卷需求：创建一个nginx容器，修改容器内的html目录内的index.html内容 分析：上个案例中，我们进入nginx容器内部，已经知道nginx的html目录所在位置/usr/share/nginx/html ，我们需要把这个目录挂载到html这个数据卷上，方便操作其中的内容。 提示：运行容器时使用 -v 参数挂载数据卷 步骤： ① 创建容器并挂载数据卷到容器内的HTML目录 1docker run --name mn -v html:/usr/share/nginx/html -p 80:80 -d nginx ② 进入html数据卷所在位置，并修改HTML内容 123456# 查看html数据卷的位置docker volume inspect html# 进入该目录cd /var/lib/docker/volumes/html/_data# 修改文件vi index.html 案例-给MySQL挂载本地目录容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下： 带数据卷模式：宿主机目录 –&gt; 数据卷 —&gt; 容器内目录 直接挂载模式：宿主机目录 —&gt; 容器内目录 如图： 语法： 目录挂载与数据卷挂载的语法是类似的： -v [宿主机目录]:[容器内目录] -v [宿主机文件]:[容器内文件] 需求：创建并运行一个MySQL容器，将宿主机目录直接挂载到容器 实现思路如下： 1）在将课前资料中的mysql.tar文件上传到虚拟机，通过load命令加载为镜像 2）创建目录/tmp/mysql/data 3）创建目录/tmp/mysql/conf，将课前资料提供的hmy.cnf文件上传到/tmp/mysql/conf 4）去DockerHub查阅资料，创建并运行MySQL容器，要求： ① 挂载/tmp/mysql/data到mysql容器内数据存储目录 ② 挂载/tmp/mysql/conf/hmy.cnf到mysql容器的配置文件 ③ 设置MySQL密码 小结docker run的命令中通过 -v 参数挂载文件或目录到容器中： -v volume名称:容器内目录 -v 宿主机文件:容器内文 -v 宿主机目录:容器内目录 数据卷挂载与目录直接挂载的 数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找 目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看 Dockerfile自定义镜像常见的镜像在DockerHub就能找到，但是我们自己写的项目就必须自己构建镜像了。 而要自定义镜像，就必须先了解镜像的结构才行。 镜像结构镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。 我们以MySQL为例，来看看镜像的组成结构： 简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。 我们要构建镜像，其实就是实现上述打包的过程。 Dockerfile语法构建自定义的镜像时，并不需要一个个文件去拷贝，打包。 我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。 而描述上述信息的文件就是Dockerfile文件。 Dockerfile就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。 更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder 构建Java项目基于Ubuntu构建Java项目需求：基于Ubuntu镜像构建一个新镜像，运行一个java项目 步骤1：新建一个空文件夹docker-demo 步骤2：拷贝课前资料中的docker-demo.jar文件到docker-demo这个目录 步骤3：拷贝课前资料中的jdk8.tar.gz文件到docker-demo这个目录 步骤4：拷贝课前资料提供的Dockerfile到docker-demo这个目录 其中的内容如下： 12345678910111213141516171819202122# 指定基础镜像FROM ubuntu:16.04# 配置环境变量，JDK的安装目录ENV JAVA_DIR=/usr/local# 拷贝jdk和java项目的包COPY ./jdk8.tar.gz $JAVA_DIR/COPY ./docker-demo.jar /tmp/app.jar# 安装JDKRUN cd $JAVA_DIR \\ &amp;&amp; tar -xf ./jdk8.tar.gz \\ &amp;&amp; mv ./jdk1.8.0_144 ./java8# 配置环境变量ENV JAVA_HOME=$JAVA_DIR/java8ENV PATH=$PATH:$JAVA_HOME/bin# 暴露端口EXPOSE 8090# 入口，java项目的启动命令ENTRYPOINT java -jar /tmp/app.jar 步骤5：进入docker-demo 将准备好的docker-demo上传到虚拟机任意目录，然后进入docker-demo目录下 步骤6：运行命令： 1docker build -t javaweb:1.0 . 最后访问 http://192.168.150.101:8090/hello/count，其中的ip改成你的虚拟机ip 基于java8构建Java项目虽然我们可以基于Ubuntu基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。 例如，构建java项目的镜像，可以在已经准备了JDK的基础镜像基础上构建。 需求：基于java:8-alpine镜像，将一个Java项目构建为镜像 实现思路如下： ① 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile ② 拷贝课前资料提供的docker-demo.jar到这个目录中 ③ 编写Dockerfile文件： a ）基于java:8-alpine作为基础镜像 b ）将app.jar拷贝到镜像中 c ）暴露端口 d ）编写入口ENTRYPOINT 内容如下： 1234FROM java:8-alpineCOPY ./app.jar /tmp/app.jarEXPOSE 8090ENTRYPOINT java -jar /tmp/app.jar ④ 使用docker build命令构建镜像 ⑤ 使用docker run创建容器并运行 小结小结： Dockerfile的本质是一个文件，通过指令描述镜像的构建过程 Dockerfile的第一行必须是FROM，从一个基础镜像来构建 基础镜像可以是基本操作系统，如Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine Docker-ComposeDocker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！ 初识DockerComposeCompose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下： 1234567891011121314version:&nbsp;\"3.8\" services:&nbsp;&nbsp;mysql:&nbsp;&nbsp;&nbsp;&nbsp;image:&nbsp;mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 &nbsp;&nbsp;&nbsp;&nbsp;volumes:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;\"/tmp/mysql/data:/var/lib/mysql\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;\"/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf\"&nbsp;&nbsp;web:&nbsp;&nbsp;&nbsp;&nbsp;build:&nbsp;.&nbsp;&nbsp;&nbsp;&nbsp;ports:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- \"8090:8090\" 上面的Compose文件就描述一个项目，其中包含两个容器： mysql：一个基于mysql:5.7.25镜像构建的容器，并且挂载了两个目录 web：一个基于docker build临时构建的镜像容器，映射端口时8090 DockerCompose的详细语法参考官网：https://docs.docker.com/compose/compose-file/ 其实DockerCompose文件可以看做是将多个docker run命令写到一个文件，只是语法稍有差异。 安装DockerComposecompose文件查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录： 内容如下： 123456789101112131415161718192021222324version: \"3.2\"services: nacos: image: nacos/nacos-server environment: MODE: standalone ports: - \"8848:8848\" mysql: image: mysql:5.7.25 environment: MYSQL_ROOT_PASSWORD: 123 volumes: - \"$PWD/mysql/data:/var/lib/mysql\" - \"$PWD/mysql/conf:/etc/mysql/conf.d/\" userservice: build: ./user-service orderservice: build: ./order-service gateway: build: ./gateway ports: - \"10010:10010\" 可以看到，其中包含5个service服务： nacos：作为注册中心和配置中心 image: nacos/nacos-server： 基于nacos/nacos-server镜像构建 environment：环境变量 MODE: standalone：单点模式启动 ports：端口映射，这里暴露了8848端口 mysql：数据库 image: mysql:5.7.25：镜像版本是mysql:5.7.25 environment：环境变量 MYSQL_ROOT_PASSWORD: 123：设置数据库root账户的密码为123 volumes：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据 userservice、orderservice、gateway：都是基于Dockerfile临时构建的 查看mysql目录，可以看到其中已经准备好了cloud_order、cloud_user表： 查看微服务目录，可以看到都包含Dockerfile文件： 内容如下： 123FROM java:8-alpineCOPY ./app.jar /tmp/app.jarENTRYPOINT java -jar /tmp/app.jar 修改微服务配置因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。 如下所示： 1234567891011spring: datasource: url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false username: root password: 123 driver-class-name: com.mysql.jdbc.Driver application: name: orderservice cloud: nacos: server-addr: nacos:8848 # nacos服务地址 打包接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。 可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改： 12345678910&lt;build&gt; &lt;!-- 服务打包的最终名称 --&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 打包后： 拷贝jar包到部署目录编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，别搞错了。 user-service： order-service： gateway： 部署最后，我们需要将文件整个cloud-demo文件夹上传到虚拟机中，理由DockerCompose部署。 上传到任意目录： 部署： 进入cloud-demo目录，然后运行下面的命令： 1docker-compose up -d Docker镜像仓库推送、拉取镜像推送镜像到私有镜像服务必须先tag，步骤如下： ① 重新tag本地镜像，名称前缀为私有仓库的地址：192.168.150.101:8080/ 1docker tag nginx:latest 192.168.147.129:8080/nginx:1.0 ② 推送镜像 1docker push 192.168.147.129:8080/nginx:1.0 ③ 拉取镜像 1docker pull 192.168.147.129:8080/nginx:1.0","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}]},{"title":"RabbitMQ入门","slug":"笔记/技术/RabbitMQ","date":"2022-07-31T22:06:09.000Z","updated":"2022-11-28T06:32:10.893Z","comments":true,"path":"2022/08/01/笔记/技术/RabbitMQ/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/RabbitMQ/","excerpt":"","text":"RabbitMQ初识MQ同步和异步通讯微服务间通讯有同步和异步两种方式： 同步通讯：就像打电话，需要实时响应。 异步通讯：就像发邮件，不需要马上回复。 两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。 同步通讯我们之前学习的Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题： 总结： 同步调用的优点： 时效性较强，可以立即得到结果 同步调用的问题： 耦合度高 性能和吞吐能力下降 有额外的资源消耗 有级联失败问题 异步通讯异步调用则可以避免上述问题： 我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。 在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。 订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。 为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。 Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。 好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。 技术对比：MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。 比较常见的MQ实现： ActiveMQ RabbitMQ RocketMQ Kafka 几种常见MQ的对比： RabbitMQ ActiveMQ RocketMQ Kafka 公司/社区 Rabbit Apache 阿里 Apache 开发语言 Erlang Java Java Scala&amp;Java 协议支持 AMQP，XMPP，SMTP，STOMP OpenWire,STOMP，REST,XMPP,AMQP 自定义协议 自定义协议 可用性 高 一般 高 高 单机吞吐量 一般 差 高 非常高 消息延迟 微秒级 毫秒级 毫秒级 毫秒以内 消息可靠性 高 一般 高 一般 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka 追求消息低延迟：RabbitMQ、Kafka 快速入门安装RabbitMQ安装RabbitMQ，参考课前资料： MQ的基本结构： RabbitMQ中的一些角色： publisher：生产者 consumer：消费者 exchange个：交换机，负责消息路由 queue：队列，存储消息 virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离 RabbitMQ消息模型RabbitMQ官方提供了5个不同的Demo示例，对应了不同的消息模型： 导入Demo工程课前资料提供了一个Demo工程，mq-demo: 导入后可以看到结构如下： 包括三部分： mq-demo：父工程，管理项目依赖 publisher：消息的发送者 consumer：消息的消费者 入门案例简单队列模式的模型图： 官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色： publisher：消息发布者，将消息发送到队列queue queue：消息队列，负责接受并缓存消息 consumer：订阅队列，处理队列中的消息 publisher实现思路： 建立连接 创建Channel 声明队列 发送消息 关闭连接和channel 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142package cn.itcast.mq.helloworld;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import org.junit.Test;import java.io.IOException;import java.util.concurrent.TimeoutException;public class PublisherTest { @Test public void testSendMessage() throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.150.101\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"itcast\"); factory.setPassword(\"123321\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.发送消息 String message = \"hello, rabbitmq!\"; channel.basicPublish(\"\", queueName, null, message.getBytes()); System.out.println(\"发送消息成功：【\" + message + \"】\"); // 5.关闭通道和连接 channel.close(); connection.close(); }} consumer实现代码思路： 建立连接 创建Channel 声明队列 订阅消息 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041package cn.itcast.mq.helloworld;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class ConsumerTest { public static void main(String[] args) throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\"192.168.150.101\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); factory.setUsername(\"itcast\"); factory.setPassword(\"123321\"); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \"simple.queue\"; channel.queueDeclare(queueName, false, false, false, null); // 4.订阅消息 channel.basicConsume(queueName, true, new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // 5.处理消息 String message = new String(body); System.out.println(\"接收到消息：【\" + message + \"】\"); } }); System.out.println(\"等待接收消息。。。。\"); }} 总结基本消息队列的消息发送流程： 建立connection 创建channel 利用channel声明队列 利用channel向队列发送消息 基本消息队列的消息接收流程： 建立connection 创建channel 利用channel声明队列 定义consumer的消费行为handleDelivery() 利用channel将消费者与队列绑定 SpringAMQPSpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。 SpringAmqp的官方地址：https://spring.io/projects/spring-amqp SpringAMQP提供了三个功能： 自动声明队列、交换机及其绑定关系 基于注解的监听器模式，异步接收消息 封装了RabbitTemplate工具，用于发送消息 Basic Queue 简单队列模型在父工程mq-demo中引入依赖 12345&lt;!--AMQP依赖，包含RabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 消息发送首先配置MQ地址，在publisher服务的application.yml中添加配置： 1234567spring: rabbitmq: host: 192.168.147.129 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: admin # 用户名 password: 111111 # 密码 然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送： 1234567891011121314151617181920212223242526package cn.itcast.mq.spring;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringAmqpTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSimpleQueue() { // 队列名称 String queueName = \"simple.queue\"; // 消息 String message = \"hello, spring amqp!\"; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); }} 消息接收首先配置MQ地址，在consumer服务的application.yml中添加配置： 1234567spring: rabbitmq: host: 192.168.147.129 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: admin # 用户名 password: 111111 # 密码 然后在consumer服务的cn.itcast.mq.listener包中新建一个类SpringRabbitListener，代码如下： 12345678910111213package cn.itcast.mq.listener;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;@Componentpublic class SpringRabbitListener { @RabbitListener(queues = \"simple.queue\") public void listenSimpleQueueMessage(String msg) throws InterruptedException { System.out.println(\"spring 消费者接收到消息：【\" + msg + \"】\"); }} 测试启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息 WorkQueueWork queues，也被称为（Task queues），任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息。 当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。 此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。 消息发送这次我们循环发送，模拟大量消息堆积现象。 在publisher服务中的SpringAmqpTest类中添加一个测试方法： 12345678910111213141516/** * workQueue * 向队列中不停发送消息，模拟消息堆积。 */@Testpublic void testWorkQueue() throws InterruptedException { // 队列名称 String queueName = \"simple.queue\"; // 消息 String message = \"hello, message_\"; for (int i = 0; i &lt; 50; i++) { // 发送消息 rabbitTemplate.convertAndSend(queueName, message + i); Thread.sleep(20); }} 消息接收要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法： 1234567891011@RabbitListener(queues = \"simple.queue\")public void listenWorkQueue1(String msg) throws InterruptedException { System.out.println(\"消费者1接收到消息：【\" + msg + \"】\" + LocalTime.now()); Thread.sleep(20);}@RabbitListener(queues = \"simple.queue\")public void listenWorkQueue2(String msg) throws InterruptedException { System.err.println(\"消费者2........接收到消息：【\" + msg + \"】\" + LocalTime.now()); Thread.sleep(200);} 注意到这个消费者sleep了1000秒，模拟任务耗时。 测试启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。 可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。 也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。 能者多劳在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置： 12345spring: rabbitmq: listener: simple: prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息 总结Work模型的使用： 多个消费者绑定到一个队列，同一条消息只会被一个消费者处理 通过设置prefetch来控制消费者预取的消息数量 发布/订阅发布订阅的模型如图： 可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化： Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Consumer：消费者，与以前一样，订阅队列，没有变化 Queue：消息队列也与以前一样，接收消息、缓存消息。 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！ FanoutFanout，英文翻译是扇出，我觉得在MQ中叫广播更合适。 在广播模式下，消息发送流程是这样的： 1） 可以有多个队列 2） 每个队列都要绑定到Exchange（交换机） 3） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定 4） 交换机把消息发送给绑定过的所有队列 5） 订阅队列的消费者都能拿到消息 我们的计划是这样的： 创建一个交换机 itcast.fanout，类型是Fanout 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout 声明队列和交换机Spring提供了一个接口Exchange，来表示所有不同类型的交换机： 在consumer中创建一个类，声明队列和交换机： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package cn.itcast.mq.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FanoutConfig { /** * 声明交换机 * @return Fanout类型交换机 */ @Bean public FanoutExchange fanoutExchange(){ return new FanoutExchange(\"itcast.fanout\"); } /** * 第1个队列 */ @Bean public Queue fanoutQueue1(){ return new Queue(\"fanout.queue1\"); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } /** * 第2个队列 */ @Bean public Queue fanoutQueue2(){ return new Queue(\"fanout.queue2\"); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); }} 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 12345678@Testpublic void testFanoutExchange() { // 队列名称 String exchangeName = \"itcast.fanout\"; // 消息 String message = \"hello, everyone!\"; rabbitTemplate.convertAndSend(exchangeName, \"\", message);} 消息接收在consumer服务的SpringRabbitListener中添加两个方法，作为消费者： 123456789@RabbitListener(queues = \"fanout.queue1\")public void listenFanoutQueue1(String msg) { System.out.println(\"消费者1接收到Fanout消息：【\" + msg + \"】\");}@RabbitListener(queues = \"fanout.queue2\")public void listenFanoutQueue2(String msg) { System.out.println(\"消费者2接收到Fanout消息：【\" + msg + \"】\");} 总结交换机的作用是什么？ 接收publisher发送的消息 将消息按照规则路由到与之绑定的队列 不能缓存消息，路由失败，消息丢失 FanoutExchange的会将消息路由到每个绑定的队列 声明队列、交换机、绑定关系的Bean是什么？ Queue FanoutExchange Binding Direct在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。 在Direct模型下： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 案例需求如下： 利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2 在publisher中编写测试方法，向itcast. direct发送消息 基于注解声明队列和交换机基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。 在consumer的SpringRabbitListener中添加两个消费者，同时基于注解来声明队列和交换机： 1234567891011121314151617@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"direct.queue1\"), exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT), key = {\"red\", \"blue\"}))public void listenDirectQueue1(String msg){ System.out.println(\"消费者接收到direct.queue1的消息：【\" + msg + \"】\");}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"direct.queue2\"), exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT), key = {\"red\", \"yellow\"}))public void listenDirectQueue2(String msg){ System.out.println(\"消费者接收到direct.queue2的消息：【\" + msg + \"】\");} 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 123456789@Testpublic void testSendDirectExchange() { // 交换机名称 String exchangeName = \"itcast.direct\"; // 消息 String message = \"红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！\"; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \"red\", message);} 总结描述下Direct交换机与Fanout交换机的差异？ Fanout交换机将消息路由给每一个与之绑定的队列 Direct交换机根据RoutingKey判断路由给哪个队列 如果多个队列具有相同的RoutingKey，则与Fanout功能类似 基于@RabbitListener注解声明队列和交换机有哪些常见注解？ @Queue @Exchange Topic说明Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： item.#：能够匹配item.spu.insert 或者 item.spu item.*：只能匹配item.spu ​ 图示： 解释： Queue1：绑定的是china.# ，因此凡是以 china.开头的routing key 都会被匹配到。包括china.news和china.weather Queue2：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配。包括china.news和japan.news 案例需求： 实现思路如下： 并利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2 在publisher中编写测试方法，向itcast. topic发送消息 消息发送在publisher服务的SpringAmqpTest类中添加测试方法： 123456789101112/** * topicExchange */@Testpublic void testSendTopicExchange() { // 交换机名称 String exchangeName = \"itcast.topic\"; // 消息 String message = \"喜报！孙悟空大战哥斯拉，胜!\"; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \"china.news\", message);} 消息接收在consumer服务的SpringRabbitListener中添加方法： 1234567891011121314151617@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"topic.queue1\"), exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC), key = \"china.#\"))public void listenTopicQueue1(String msg){ System.out.println(\"消费者接收到topic.queue1的消息：【\" + msg + \"】\");}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"topic.queue2\"), exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC), key = \"#.news\"))public void listenTopicQueue2(String msg){ System.out.println(\"消费者接收到topic.queue2的消息：【\" + msg + \"】\");} 总结描述下Direct交换机与Topic交换机的差异？ Topic交换机接收的消息RoutingKey必须是多个单词，以 **.** 分割 Topic交换机与队列绑定时的bindingKey可以指定通配符 #：代表0个或多个词 *：代表1个词 消息转换器之前说过，Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。 只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题： 数据体积过大 有安全漏洞 可读性差 我们来测试一下。 测试默认转换器我们修改消息发送的代码，发送一个Map对象： 123456789@Testpublic void testSendMap() throws InterruptedException { // 准备消息 Map&lt;String,Object&gt; msg = new HashMap&lt;&gt;(); msg.put(\"name\", \"Jack\"); msg.put(\"age\", 21); // 发送消息 rabbitTemplate.convertAndSend(\"simple.queue\",\"\", msg);} 停止consumer服务 发送消息后查看控制台： 配置JSON转换器显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。 在publisher和consumer两个服务中都引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt; &lt;version&gt;2.9.10&lt;/version&gt;&lt;/dependency&gt; 配置消息转换器。 在启动类中添加一个Bean即可： 1234@Beanpublic MessageConverter jsonMessageConverter(){ return new Jackson2JsonMessageConverter();}","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"}]},{"title":"RabbitMQ部署指南","slug":"笔记/安装部署/RabbitMQ部署指南","date":"2022-07-31T22:06:09.000Z","updated":"2022-11-28T06:32:10.912Z","comments":true,"path":"2022/08/01/笔记/安装部署/RabbitMQ部署指南/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/RabbitMQ%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/","excerpt":"","text":"RabbitMQ部署指南单机部署我们在Centos7虚拟机中使用Docker来安装。 下载镜像方式一：在线拉取 1docker pull rabbitmq:3.8-management 方式二：从本地加载 在课前资料已经提供了镜像包： 上传到虚拟机中后，使用命令加载镜像即可： 1docker load -i mq.tar 安装MQ执行下面的命令来运行MQ容器： 12345678910docker run \\ -e RABBITMQ_DEFAULT_USER=admin \\ -e RABBITMQ_DEFAULT_PASS=111111 \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3.8-management","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"Maven私服","slug":"笔记/技术/Maven私服","date":"2022-07-31T22:06:08.000Z","updated":"2022-11-28T06:32:10.894Z","comments":true,"path":"2022/08/01/笔记/技术/Maven私服/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E6%8A%80%E6%9C%AF/Maven%E7%A7%81%E6%9C%8D/","excerpt":"","text":"私服私服介绍问题导入这里的私服和平时我们听的国服、体验服、欧服等等有什么区别？ 介绍 团队开发现状分析 私服是一台独立的服务器，用于解决团队内部的资源共享与资源同步问题 Nexus Sonatype公司的一款maven私服产品 下载地址：https://help.sonatype.com/repomanager3/download Nexus安装与启动 启动服务器（命令行启动） nexus.exe /run nexus 访问服务器（默认端口：8081） http://localhost:8081 修改基础配置信息 安装路径下etc目录中nexus-default.properties文件保存有nexus基础配置信息，例如默认访问端口。 修改服务器运行配置信息 安装路径下bin目录中nexus.vmoptions文件保存有nexus服务器启动对应的配置信息，例如默认占用内存空间。 私服资源操作流程分析 私服仓库分类问题导入私服仓库分为哪几种？ 资源上传与下载问题导入往私服上传资源是否需要身份认证？在哪里设置认证信息？ 配置访问私服的权限 私服访问路径 从私服中下载依赖【第一步】在maven的settings.xml中&lt;mirrors&gt;标签中配置，此时就需要注释掉aliyun的配置。 12345&lt;mirror&gt; &lt;id&gt;nexus-heima&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt;&lt;/mirror&gt; 【第二步】在nexus中设置允许匿名下载，如果不允许将不会从私服中下载依赖 如果私服中没有对应的jar，会去中央仓库下载，速度很慢。可以配置让私服去阿里云中下载依赖。 http://maven.aliyun.com/nexus/content/groups/public 上传依赖到私服中【第一步】配置本地仓库访问私服的权限（在maven的settings.xml的servers标签中配置） 123456&lt;server&gt; &lt;!--id任意，多个server的id不重复就行，后面会用到--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt;&lt;!--填写自己nexus设定的登录秘密--&gt;&lt;/server&gt; 【第一步】配置当前项目访问私服上传资源的保存位置（项目的pom.xml文件中配置） 1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;!--如果jar的版本是release版本，那么就上传到这个仓库，根据自己情况修改--&gt; &lt;url&gt;http://localhost:8081/repository/heima-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;!--和maven/settings.xml中server中的id一致，表示使用该id对应的用户名和密码--&gt; &lt;id&gt;heima-nexus&lt;/id&gt; &lt;!--如果jar的版本是snapshot版本，那么就上传到这个仓库，根据自己情况修改--&gt; &lt;url&gt;http://localhost:8081/repository/heima-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; ==注意：要和maven的settings.xml中server中定义的&lt;id&gt;heima-nexus&lt;/id&gt;对应== 【第三步】发布资源到私服命令 1mvn deploy","categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Maven","slug":"Maven","permalink":"http://example.com/tags/Maven/"}]},{"title":"Redis安装说明","slug":"笔记/安装部署/Redis安装说明","date":"2022-07-31T22:06:07.000Z","updated":"2022-11-28T06:32:10.913Z","comments":true,"path":"2022/08/01/笔记/安装部署/Redis安装说明/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Redis%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E/","excerpt":"","text":"Redis安装说明大多数企业都是基于Linux服务器来部署项目，而且Redis官方也没有提供Windows版本的安装包。因此课程中我们会基于Linux系统来安装Redis. 此处选择的Linux版本为CentOS 7. Redis的官方网站地址：https://redis.io/ 1.单机安装Redis安装Redis依赖Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖： 1yum install -y gcc tcl 上传安装包并解压然后将课前资料提供的Redis安装包上传到虚拟机的任意目录： 例如，我放到了/usr/local/src 目录： 解压缩： 1tar -xzf redis-6.2.6.tar.gz 解压后： 进入redis目录： 1cd redis-6.2.6 运行编译命令： 1make &amp;&amp; make install 如果没有出错，应该就安装成功了。 默认的安装路径是在 /usr/local/bin目录下： 该目录以及默认配置到环境变量，因此可以在任意目录下运行这些命令。其中： redis-cli：是redis提供的命令行客户端 redis-server：是redis的服务端启动脚本 redis-sentinel：是redis的哨兵启动脚本 启动redis的启动方式有很多种，例如： 默认启动 指定配置启动 开机自启 默认启动安装完成后，在任意目录输入redis-server命令即可启动Redis： 1redis-server 如图： 这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。 指定配置启动如果要让Redis以后台方式启动，则必须修改Redis配置文件，就在我们之前解压的redis安装包下（/usr/local/src/redis-6.2.6），名字叫redis.conf： 我们先将这个配置文件备份一份： 1cp redis.conf redis.conf.bck 然后修改redis.conf文件中的一些配置： 123456# 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0bind 0.0.0.0# 守护进程，修改为yes后即可后台运行daemonize yes # 密码，设置后访问Redis必须输入密码requirepass 123321 Redis的其它常见配置： 12345678910# 监听的端口port 6379# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录dir .# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15databases 1# 设置redis能够使用的最大内存maxmemory 512mb# 日志文件，默认为空，不记录日志，可以指定日志文件名logfile \"redis.log\" 启动Redis： 1234# 进入redis安装目录 cd /usr/local/src/redis-6.2.6# 启动redis-server redis.conf 停止服务： 123# 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务，# 因为之前配置了密码，因此需要通过 -u 来指定密码redis-cli -u 123321 shutdown 开机自启我们也可以通过配置来实现开机自启。 首先，新建一个系统服务文件： 1vi /etc/systemd/system/redis.service 内容如下： 1234567891011[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/bin/redis-server /usr/local/src/redis-6.2.6/redis.confPrivateTmp=true[Install]WantedBy=multi-user.target 然后重载系统服务： 1systemctl daemon-reload 现在，我们可以用下面这组命令来操作redis了： 12345678# 启动systemctl start redis# 停止systemctl stop redis# 重启systemctl restart redis# 查看状态systemctl status redis 执行下面的命令，可以让redis开机自启： 1systemctl enable redis Redis客户端安装完成Redis，我们就可以操作Redis，实现数据的CRUD了。这需要用到Redis客户端，包括： 命令行客户端 图形化桌面客户端 编程客户端 Redis命令行客户端Redis安装完成后就自带了命令行客户端：redis-cli，使用方式如下： 1redis-cli [options] [commonds] 其中常见的options有： -h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1 -p 6379：指定要连接的redis节点的端口，默认是6379 -a 123321：指定redis的访问密码 其中的commonds就是Redis的操作命令，例如： ping：与redis服务端做心跳测试，服务端正常会返回pong 不指定commond时，会进入redis-cli的交互控制台： 图形化桌面客户端GitHub上的大神编写了Redis的图形化桌面客户端，地址：https://github.com/uglide/RedisDesktopManager 不过该仓库提供的是RedisDesktopManager的源码，并未提供windows安装包。 在下面这个仓库可以找到安装包：https://github.com/lework/RedisDesktopManager-Windows/releases 安装在课前资料中可以找到Redis的图形化桌面客户端： 解压缩后，运行安装程序即可安装： 此处略。 安装完成后，在安装目录下找到rdm.exe文件： 双击即可运行： 建立连接点击左上角的连接到Redis服务器按钮： 在弹出的窗口中填写Redis服务信息： 点击确定后，在左侧菜单会出现这个链接： 点击即可建立连接了： Redis默认有16个仓库，编号从0至15. 通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。 如果是基于redis-cli连接Redis服务，可以通过select命令来选择数据库： 12# 选择 0号库select 0","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}]},{"title":"Centos7安装Docker","slug":"笔记/安装部署/Centos7安装Docker","date":"2022-07-31T22:06:06.000Z","updated":"2022-11-28T06:32:10.909Z","comments":true,"path":"2022/08/01/笔记/安装部署/Centos7安装Docker/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Centos7%E5%AE%89%E8%A3%85Docker/","excerpt":"","text":"安装DockerDocker 分为 CE 和 EE 两大版本。CE 即社区版（免费，支持周期 7 个月），EE 即企业版，强调安全，付费使用，支持周期 24 个月。 Docker CE 分为 stable test 和 nightly 三个更新频道。 官方网站上有各种环境下的 安装指南，这里主要介绍 Docker CE 在 CentOS上的安装。 CentOS安装DockerDocker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10， CentOS 7 满足最低内核的要求，所以我们在CentOS 7安装Docker。 卸载（可选）如果之前安装过旧版本的Docker，可以使用下面命令卸载： 1234567891011yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 安装docker首先需要大家虚拟机联网，安装yum工具 123yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 --skip-broken 然后更新本地镜像源： 12345678# 设置docker镜像源yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repoyum makecache fast 然后输入命令： 1yum install -y docker-ce docker-ce为社区免费版本。稍等片刻，docker即可安装成功。 启动dockerDocker应用需要用到各种端口，逐一去修改防火墙设置。非常麻烦，因此建议大家直接关闭防火墙！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ 1234# 关闭systemctl stop firewalld# 禁止开机启动防火墙systemctl disable firewalld 通过命令启动docker： 12345systemctl start docker # 启动docker服务systemctl stop docker # 停止docker服务systemctl restart docker # 重启docker服务 然后输入命令，可以查看docker版本： 1docker -v 如图： 配置镜像加速docker官方镜像仓库网速较差，我们需要设置国内镜像服务： 参考阿里云的镜像加速文档：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors CentOS7安装DockerCompose下载Linux下需要通过命令下载： 12# 安装curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose 如果下载速度较慢，或者下载失败，可以使用课前资料提供的docker-compose文件： 上传到/usr/local/bin/目录也可以。 修改文件权限修改文件权限： 12# 修改权限chmod +x /usr/local/bin/docker-compose Base自动补全命令：12# 补全命令curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 如果这里出现错误，需要修改自己的hosts文件： 1echo \"199.232.68.133 raw.githubusercontent.com\" &gt;&gt; /etc/hosts Docker镜像仓库搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。 官网地址：https://hub.docker.com/_/registry 简化版镜像仓库Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。 搭建方式比较简单，命令如下： 123456docker run -d \\ --restart=always \\ --name registry \\ -p 5000:5000 \\ -v registry-data:/var/lib/registry \\ registry 命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。 访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像 带有图形化界面版本使用DockerCompose部署带有图象界面的DockerRegistry，命令如下： 123456789101112131415version: '3.0'services: registry: image: registry volumes: - ./registry-data:/var/lib/registry ui: image: joxit/docker-registry-ui:static ports: - 8080:80 environment: - REGISTRY_TITLE=传智教育私有仓库 - REGISTRY_URL=http://registry:5000 depends_on: - registry 1234mkdir registry-uicd registry-ui/touch docker-compose.ymldocker-compose up -d 配置Docker信任地址我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置： 12345678# 打开要修改的文件vi /etc/docker/daemon.json# 添加内容：\"insecure-registries\":[\"http://192.168.147.129:8080\"]# 重加载systemctl daemon-reload# 重启dockersystemctl restart docker","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Nacos安装指南","slug":"笔记/安装部署/Nacos安装指南","date":"2022-07-31T22:06:06.000Z","updated":"2022-11-28T06:32:10.911Z","comments":true,"path":"2022/08/01/笔记/安装部署/Nacos安装指南/","link":"","permalink":"http://example.com/2022/08/01/%E7%AC%94%E8%AE%B0/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/Nacos%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/","excerpt":"","text":"Nacos安装指南Windows安装开发阶段采用单机安装即可。 下载安装包在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码： GitHub主页：https://github.com/alibaba/nacos GitHub的Release下载页：https://github.com/alibaba/nacos/releases 如图： 本课程采用1.4.1.版本的Nacos，课前资料已经准备了安装包： windows版本使用nacos-server-1.4.1.zip包即可。 解压将这个包解压到任意非中文目录下，如图： 目录说明： bin：启动脚本 conf：配置文件 端口配置Nacos的默认端口是8848，如果你电脑上的其它进程占用了8848端口，请先尝试关闭该进程。 如果无法关闭占用8848端口的进程，也可以进入nacos的conf目录，修改配置文件中的端口： 修改其中的内容： 启动启动非常简单，进入bin目录，结构如下： 然后执行命令即可： windows命令： 1startup.cmd -m standalone 执行后的效果如图： 访问在浏览器输入地址：http://127.0.0.1:8848/nacos即可： 默认的账号和密码都是nacos，进入后： Linux安装Linux或者Mac安装方式与Windows类似。 安装JDKNacos依赖于JDK运行，索引Linux上也需要安装JDK才行。 上传jdk安装包： 上传到某个目录，例如：/usr/local/ 然后解压缩： 1tar -xvf jdk-8u144-linux-x64.tar.gz 然后重命名为java 配置环境变量： 12export JAVA_HOME=/usr/local/javaexport PATH=$PATH:$JAVA_HOME/bin 设置环境变量： 1source /etc/profile 上传安装包如图： 也可以直接使用课前资料中的tar.gz： 上传到Linux服务器的某个目录，例如/usr/local/src目录下： 解压命令解压缩安装包： 1tar -xvf nacos-server-1.4.1.tar.gz 然后删除安装包： 1rm -rf nacos-server-1.4.1.tar.gz 目录中最终样式： 目录内部： 端口配置与windows中类似 启动在nacos/bin目录中，输入命令启动Nacos： 1sh startup.sh -m standalone Nacos的依赖父工程： 1234567&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 客户端： 123456&lt;!-- nacos客户端依赖包 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"}]}],"categories":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/categories/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"小技术","slug":"小技术","permalink":"http://example.com/categories/%E5%B0%8F%E6%8A%80%E6%9C%AF/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/categories/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"技术框架","slug":"技术框架","permalink":"http://example.com/tags/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"},{"name":"安装部署","slug":"安装部署","permalink":"http://example.com/tags/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"报错日常","slug":"报错日常","permalink":"http://example.com/tags/%E6%8A%A5%E9%94%99%E6%97%A5%E5%B8%B8/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"MyBatisPlus","slug":"MyBatisPlus","permalink":"http://example.com/tags/MyBatisPlus/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"RabbitMq","slug":"RabbitMq","permalink":"http://example.com/tags/RabbitMq/"},{"name":"Maven","slug":"Maven","permalink":"http://example.com/tags/Maven/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"}]}